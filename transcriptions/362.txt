[00:00.000 --> 00:04.800]  The saying that's been in my head ever since you kindly agreed to be on the show today,
[00:04.800 --> 00:07.200]  and I was thinking about the stuff I wanted to talk about,
[00:08.400 --> 00:13.920]  is the famous Chinese blessing that is in fact a curse.
[00:15.120 --> 00:17.120]  May you live in interesting times.
[00:17.120 --> 00:18.480]  Got what you're wishing for, right?
[00:18.480 --> 00:25.200]  And if that does not in a single sentence summarize November 2022,
[00:25.200 --> 00:28.080]  I don't know what else does.
[00:28.080 --> 00:31.120]  I feel like I keep hearing that phrase, and I keep hearing
[00:31.120 --> 00:33.520]  the dog who caught the car it was chasing.
[00:33.520 --> 00:35.120]  That very much true.
[00:35.120 --> 00:41.200]  So if you don't mind, and I don't talk electoral politics often on this show,
[00:41.200 --> 00:46.480]  but it's been an eventful month, and I kind of feel it ties into the discussion of Twitter,
[00:46.480 --> 00:49.200]  which is going to be the main thrust of the show.
[00:49.200 --> 00:50.240]  I don't know if you've heard.
[00:52.240 --> 00:53.520]  I'm presuming.
[00:53.520 --> 00:54.020]  What?
[00:54.020 --> 00:58.420]  But I don't think that they are unrelated at all.
[00:58.420 --> 01:00.660]  No, they're inseparable.
[01:00.660 --> 01:01.300]  Right.
[01:01.300 --> 01:05.700]  Former TV game show host and New York real estate magnate Donald.
[01:05.700 --> 01:06.980]  Let me check the spelling here.
[01:06.980 --> 01:10.980]  Trump announced that he'd be running for president last night.
[01:10.980 --> 01:11.540]  Surprising.
[01:11.540 --> 01:12.580]  Absolutely nobody.
[01:12.580 --> 01:13.460]  Yeah, I can't believe it.
[01:13.460 --> 01:18.260]  But there is a weird thing going on where the good news for me and you,
[01:18.260 --> 01:20.020]  probably most people listening to the show.
[01:20.020 --> 01:22.660]  But I realized that because this is not a political show,
[01:22.660 --> 01:25.860]  there's certainly some people lean Republican who listen,
[01:25.860 --> 01:30.980]  and I'm not trying to turn this opening segment into a go blue power hour.
[01:30.980 --> 01:33.540]  But you know, the Democrats had a good election.
[01:34.420 --> 01:34.740]  Everybody.
[01:34.740 --> 01:35.940]  I don't know any good.
[01:35.940 --> 01:36.980]  Yeah, shockingly good.
[01:36.980 --> 01:42.820]  Historically, in the US, where we have elections on a very regular schedule,
[01:42.820 --> 01:44.900]  as opposed to like a parliamentary system,
[01:44.900 --> 01:47.060]  every four years, we have a presidential election.
[01:47.060 --> 01:49.620]  And in between, we have what we call the midterm.
[01:49.620 --> 01:53.780]  And historically, whichever party holds the White House,
[01:54.340 --> 01:57.140]  the midterms tend to go to the opposition party.
[01:57.140 --> 01:58.980]  And it makes it usually they get shellacked.
[01:58.980 --> 02:00.500]  It's like it's not a slight tilt.
[02:00.500 --> 02:02.580]  It's usually they get their butts handed to them.
[02:03.380 --> 02:03.700]  Right.
[02:03.700 --> 02:07.140]  And most recently, or among the most reasons,
[02:07.140 --> 02:10.900]  but the one that almost doesn't seem intuitive,
[02:10.900 --> 02:14.900]  given how we think of him and his presidency is Barack Obama,
[02:14.900 --> 02:19.860]  who finished two successful terms and left with very high ratings.
[02:19.860 --> 02:24.980]  And it's still, I would say universally acclaimed as the most popular political
[02:24.980 --> 02:27.060]  figure on the left in the United States.
[02:27.060 --> 02:30.260]  And I'd whoever is in second generations in generation,
[02:30.260 --> 02:31.540]  maybe since Kennedy or something.
[02:31.540 --> 02:32.040]  Yeah.
[02:32.740 --> 02:33.060]  Yeah.
[02:33.060 --> 02:36.900]  And Kennedy obviously left on on martyrs terms.
[02:36.900 --> 02:38.580]  So it's hard to compare.
[02:38.580 --> 02:42.660]  Whereas Bill Clinton, who left with very high approval ratings,
[02:42.660 --> 02:46.100]  was much more controversial because of his personal
[02:47.860 --> 02:50.820]  predilections, for lack of a better term, among other things.
[02:50.820 --> 02:54.580]  And I don't think the years have been kind to his legacy, even amongst his supporters.
[02:54.580 --> 02:54.900]  Right.
[02:54.900 --> 02:55.940]  But he did leave office.
[02:55.940 --> 02:59.700]  Let's just say, you know, he's very popular, but not in a way.
[02:59.700 --> 03:02.500]  So let's say, how long are we out of Obama?
[03:02.500 --> 03:04.500]  So we're six years post Obama, right?
[03:04.500 --> 03:05.060]  Is that right?
[03:05.060 --> 03:05.860]  That sounds right.
[03:05.860 --> 03:10.420]  So six years post Bill Clinton would be 2006.
[03:10.420 --> 03:13.780]  He felt more like, not history, but wasn't really relevant.
[03:13.780 --> 03:14.740]  Bit of a relic.
[03:14.740 --> 03:15.060]  Yeah.
[03:15.060 --> 03:16.660]  Already in 2006.
[03:16.660 --> 03:23.220]  And 9-11 was sort of a snap of the fingers change of the dynamics of everything anyway.
[03:23.220 --> 03:28.020]  And it had nothing to do with Bill Clinton, but Barack Obama, very popular.
[03:28.020 --> 03:32.820]  He got killed two years in the midterm elections, two years in.
[03:32.820 --> 03:33.140]  Yeah.
[03:33.140 --> 03:33.620]  Yeah.
[03:33.620 --> 03:35.140]  Again, almost at a historic level.
[03:35.140 --> 03:35.460]  Right.
[03:35.460 --> 03:42.900]  Like just devastating rejection of his policies or revert back to the center, whatever you
[03:42.900 --> 03:43.460]  want to call it.
[03:43.460 --> 03:46.260]  Democrats did very well this year for a midterm.
[03:47.220 --> 03:50.500]  There are two opposing explanations.
[03:50.500 --> 03:53.460]  I mean, I know all politics is very complicated and multilateral.
[03:53.460 --> 03:57.620]  I thought we were going to go straight to, and therefore it's time to fully socialize
[03:57.620 --> 03:57.940]  Twitter.
[03:59.060 --> 04:00.500]  Is that no, that's not okay.
[04:00.500 --> 04:00.740]  Sorry.
[04:00.740 --> 04:02.340]  I just full communism.
[04:02.340 --> 04:03.220]  We're taking it over.
[04:03.220 --> 04:08.100]  This is now the state media jump the gun.
[04:08.100 --> 04:08.500]  Sorry.
[04:08.500 --> 04:09.140]  Okay.
[04:09.140 --> 04:14.980]  One explanation is that Donald Trump is still obviously the leader of the Republican party.
[04:14.980 --> 04:24.500]  And he is so deeply unpopular that, and has insisted upon for fealty to, for his political
[04:24.500 --> 04:32.900]  followers to promulgate the big lie, a true capital B capital L big lie out of the big
[04:32.900 --> 04:41.700]  lie playbook of demagoguery, authoritarianism, whatever you want to call it, that he actually
[04:41.700 --> 04:49.780]  did not lose the election that he very clearly lost by not that he wasn't that close.
[04:49.780 --> 04:52.260]  It was closer than I would like it to be in various States.
[04:52.260 --> 04:54.820]  But when you overall look at it, it wasn't even that close.
[04:54.820 --> 04:55.300]  He lost.
[04:56.420 --> 05:03.700]  And again, I don't know if you recall, but before he left office, he attempted what I
[05:03.700 --> 05:09.380]  honestly believe was a coup to stay in the right historical term.
[05:09.380 --> 05:14.740]  So that's one explanation of why the Republicans lost in this midterm is that he's still a
[05:14.740 --> 05:15.620]  leading figure.
[05:15.620 --> 05:20.580]  His party still hasn't completely rejected this nonsense and said, no, you lost your
[05:20.580 --> 05:22.340]  big dummy, let's move on.
[05:22.340 --> 05:31.780]  The other is that earlier this year, the Supreme Court overturned Roe v. Wade, which had been
[05:31.780 --> 05:38.260]  50 years of legal precedent, making abortion, legalized abortion, the law of the land in
[05:38.260 --> 05:45.300]  all 50 coast to coast, 50 States, all US territories, and that this was so unpopular.
[05:45.300 --> 05:48.340]  And this is, I think, where you're going with the dog catching the car, right?
[05:48.340 --> 05:52.500]  That for you're in my lifetime and most of the lifetimes of most of the people who are
[05:52.500 --> 05:57.620]  going to be listening to us, if not their entire lifetimes, this has been a hot button
[05:57.620 --> 06:00.020]  issue in United States politics every year.
[06:00.020 --> 06:01.380]  It's never abated.
[06:01.380 --> 06:02.580]  It doesn't ebb and flow.
[06:02.580 --> 06:03.860]  It's always red hot.
[06:04.900 --> 06:12.740]  And it has been incredibly effective for Republicans because there is a certain portion
[06:12.740 --> 06:19.060]  of their base, the evangelical vote in particular, who is electrified by this issue, who truly
[06:19.060 --> 06:26.020]  believes that they want abortion to be illegal and that they could use that issue every single
[06:26.020 --> 06:32.180]  election to drum up a certain portion of the electorate who would vote on that.
[06:32.180 --> 06:36.180]  There's a substantial number of single issue voters who are galvanized by that to the exclusion
[06:36.180 --> 06:36.820]  of everything else.
[06:37.380 --> 06:39.300]  To the exclusion of everything else.
[06:39.300 --> 06:44.100]  And therefore, if what Republicans wanted to do in a state level or at a national level
[06:44.900 --> 06:49.460]  had nothing to do with abortion or even health care at all, just something to do, let's say,
[06:49.460 --> 06:56.660]  with the tax rates, which often comes up, but they could galvanize some portion, a significant
[06:56.660 --> 07:02.260]  portion of voters who care about nothing else, or at least while they might care about other
[07:02.260 --> 07:04.100]  things, compromise and everything else for this.
[07:04.100 --> 07:11.300]  Right. And so that strategically, the best thing that could happen to them, according
[07:11.300 --> 07:18.420]  to this theory of politics, would be for Roe v. Wade to remain the law of the land forever,
[07:19.780 --> 07:24.500]  but keep it out in front of the voters and keep saying, we'll keep nominating judges
[07:24.500 --> 07:26.820]  who are skeptical about it and we'll keep doing it.
[07:26.820 --> 07:27.860]  Always on the cusp.
[07:27.860 --> 07:28.900]  Always on the cusp.
[07:28.900 --> 07:31.140]  Like James Bond never dies.
[07:31.140 --> 07:32.420]  He's just always in danger.
[07:32.420 --> 07:38.420]  Cinematically, I think it's one of the great scenes of movie history is in Indiana Jones
[07:38.420 --> 07:41.620]  and the Last Crusade with, of course, Steven Spielberg as the director.
[07:41.620 --> 07:42.980]  And it's near the end.
[07:42.980 --> 07:44.980]  And there's the Holy Grail.
[07:44.980 --> 07:50.020]  And this temple is falling apart and Indiana Jones has fallen into this crevice.
[07:50.020 --> 07:52.580]  And there's his father is holding onto his hand.
[07:52.580 --> 07:53.220]  He's slipping.
[07:53.940 --> 07:57.300]  But he's got one finger on the Holy Grail and he can almost tilt it.
[07:57.300 --> 07:59.140]  And if he could just tilt it, maybe almost get it.
[07:59.140 --> 08:05.700]  That a quarter inch, just that and his dad is and his dad finally calls him by the name.
[08:05.700 --> 08:07.140]  He prefers Indiana.
[08:07.140 --> 08:07.700]  Let's go.
[08:07.700 --> 08:09.700]  Or I forget the exact line, but he gives it up.
[08:09.700 --> 08:10.100]  Let it.
[08:10.100 --> 08:11.460]  I think he says literally let it go.
[08:11.460 --> 08:12.180]  Let it go.
[08:12.180 --> 08:18.020]  And yeah, but that finger on the cusp of the whole, we're so close.
[08:18.020 --> 08:23.300]  We're so close has been now where those two theories and they both.
[08:23.300 --> 08:26.820]  And this is that one rare Spielberg movie where the dad's actually sticking around, right?
[08:26.820 --> 08:28.900]  So this is as deep as it gets.
[08:28.900 --> 08:29.780]  It truly is.
[08:30.420 --> 08:31.860]  I think it's a great movie.
[08:31.860 --> 08:33.220]  Yeah, it is a good one.
[08:33.220 --> 08:36.500]  And yeah, it's true that that's the one where the dad.
[08:36.500 --> 08:40.340]  Yeah, it's deep on that level in the Spielberg.
[08:40.340 --> 08:44.180]  And when we look back on his whole career, it'll stick out for that reason too.
[08:44.180 --> 08:46.260]  Of course, both of these things can be true.
[08:46.260 --> 08:53.620]  That Donald Trump's overall unpopularity with the overall electorate combined with the overwhelming
[08:53.620 --> 09:00.980]  majority of U.S. voters who favor some level of legalized abortion and including support
[09:00.980 --> 09:03.620]  for Roe v. Wade remaining the law of the land.
[09:03.620 --> 09:10.260]  And even while Roe was the law, there obviously have been, especially in recent years, state
[09:10.260 --> 09:11.780]  by state restrictions.
[09:11.780 --> 09:14.420]  Yeah, it's been effectively illegal for a lot of people for a long time.
[09:14.420 --> 09:14.980]  It has been.
[09:14.980 --> 09:16.740]  Or really difficult, which.
[09:16.740 --> 09:21.380]  Illegal by your and my perspective from Pennsylvania and New York, right?
[09:21.380 --> 09:24.500]  But from where we might be going was legal.
[09:25.060 --> 09:26.500]  So they're not in conflict there.
[09:26.500 --> 09:27.940]  It could both things could be true.
[09:27.940 --> 09:35.940]  But the interesting confluence of them is that Donald Trump personally was aghast when
[09:35.940 --> 09:40.980]  the Supreme Court Dobbs decision that overturned it leaked.
[09:40.980 --> 09:44.180]  The leaked version was other than pretty accurate.
[09:44.180 --> 09:47.860]  It was like a few bits of copy editing different.
[09:47.860 --> 09:51.860]  It's like the final draft, not final, final draft.
[09:51.860 --> 09:52.100]  Right.
[09:53.700 --> 09:56.900]  Well, the one thing every once in a while, it's not like I sit there and read Supreme
[09:56.900 --> 10:04.020]  Court decisions as a hobby, but it is interesting to me as a lay person to the law how well
[10:04.020 --> 10:04.900]  written they are.
[10:04.900 --> 10:05.780]  They're great writers.
[10:05.780 --> 10:06.740]  They're incredible writers.
[10:06.740 --> 10:07.380]  Right.
[10:07.380 --> 10:10.820]  And the journalists of Dahlia Lithwick, who is one of my favorite journalists, period,
[10:10.820 --> 10:13.380]  and she covers Supreme Court law for Slate.
[10:13.380 --> 10:18.100]  And you see in the way she quotes at that level of fluency they have where they know
[10:18.100 --> 10:20.740]  they're many times just literally writing history.
[10:21.620 --> 10:22.020]  Correct.
[10:22.020 --> 10:25.300]  And I and she's been at Slate for a long time.
[10:25.300 --> 10:26.500]  She hands each.
[10:26.500 --> 10:26.740]  Yeah.
[10:26.740 --> 10:31.620]  For all the turnover in the media world, Dahlia Lithwick at Slate covering the Supreme
[10:31.620 --> 10:33.220]  Court has been a mainstay.
[10:33.220 --> 10:34.100]  And you're correct.
[10:34.100 --> 10:34.740]  I will say this.
[10:34.740 --> 10:35.140]  I do.
[10:35.140 --> 10:39.860]  I, of course, did not agree with his politics almost at all.
[10:39.860 --> 10:47.300]  I also feel that he was quite a bit of a hypocrite in terms of his proclaimed adherence to certain
[10:47.300 --> 10:52.340]  principles and the way he voted in certain cases where it went against his way.
[10:52.340 --> 10:58.100]  But Antonin Scalia, with the standard of Supreme Court justices being good writers, was an
[10:58.100 --> 10:59.140]  exceptional writer.
[10:59.140 --> 11:05.620]  I mean, like, really, I mean, just read some Scalia decisions and it's like, oh, man, this
[11:05.620 --> 11:09.940]  guy had, like, a columnist's bones in him for, like, a turn of phrase.
[11:09.940 --> 11:13.540]  He's a good enough writer that it was exasperating that he was wrong about everything for me.
[11:15.540 --> 11:19.780]  Yeah, it'd be better if you sounded like a caveman while pushing all my buttons.
[11:20.660 --> 11:25.860]  But as soon as that decision leaked and it turned out the leak was going to be their
[11:25.860 --> 11:32.340]  decision, it also then leaked that sources close to President Trump down in Mar-a-Lago
[11:32.340 --> 11:37.620]  that he was aghast at this and thought this is going to be a disaster for Republicans
[11:37.620 --> 11:39.940]  with suburban women and young women.
[11:40.820 --> 11:43.220]  Yeah, yeah, and guess what?
[11:43.220 --> 11:45.140]  Yeah, it was.
[11:45.140 --> 11:49.780]  So in some ways, these two things, while they could both be true, they're sort of in conflict.
[11:49.780 --> 11:55.220]  And then there's a part of you that wants to say, my God, Trump, you're the one who
[11:55.220 --> 11:56.980]  nominated three of these fucknuts.
[11:56.980 --> 12:01.540]  So, yeah, I mean, I think there's a sort of, I'm very skeptical of, like, grand unifying
[12:01.540 --> 12:05.620]  theories and everything is 12-dimensional chess and everybody has a plan and understands
[12:05.620 --> 12:06.180]  what's going on.
[12:06.180 --> 12:10.580]  I think we ascribe historical narratives retrospectively and, like, this is why this
[12:10.580 --> 12:11.220]  happened, right?
[12:11.220 --> 12:15.700]  And it's like, you got to get at least 15, 20 years, maybe 50 years clear or something,
[12:15.700 --> 12:17.380]  and then that narrative forms.
[12:17.380 --> 12:21.140]  But this is one of those things where I think there is a common thread, and believe it or
[12:21.140 --> 12:25.140]  not, I think this actually even ties to the Twitter story, which is you have true believers,
[12:25.140 --> 12:25.540]  right?
[12:25.540 --> 12:26.900]  You have true believers, right?
[12:26.900 --> 12:29.540]  Obviously, there are people who are anti-abortion in America.
[12:29.540 --> 12:33.700]  And like I said, that's almost the animating principle of their political view, social
[12:33.700 --> 12:37.780]  view of the world, and also importantly, a big part of their identity, right?
[12:37.780 --> 12:41.780]  That's how they sort of form groups and make friends and navigate the world is this is
[12:41.780 --> 12:43.940]  their sense of who they are as a person.
[12:44.500 --> 12:51.380]  And then a much larger adjacent audience for whom some of that is there, some part of principle
[12:51.380 --> 12:54.100]  there, but also there's an animating force.
[12:54.100 --> 12:57.700]  And this is, again, one of the things where just objectively, it is much more common on
[12:57.700 --> 13:00.340]  the right, which is I want to own the libs.
[13:00.340 --> 13:03.860]  And it's a weird, I guess it's very intoxicating.
[13:03.860 --> 13:04.980]  It's a thing I actually struggle with.
[13:04.980 --> 13:07.620]  I'm saying I get mad at people I politically disagree with.
[13:07.620 --> 13:10.500]  But when I'm not thinking about that issue, I'm not thinking about them.
[13:10.500 --> 13:14.340]  I'm not sort of saying, how can I rub my hands together and find a way to make their
[13:14.340 --> 13:15.380]  life worse today?
[13:15.380 --> 13:18.420]  But it is almost like kind of a sport, right?
[13:18.420 --> 13:19.700]  It feels very much like that.
[13:19.700 --> 13:24.740]  Like it's fun, it is fun for people who hate the Yankees to hate Yankees fans, right?
[13:26.020 --> 13:28.100]  And so like, that's kind of the best analogy I can think of.
[13:28.100 --> 13:32.500]  And also there's been this sort of similar dynamic around popular culture, right?
[13:32.500 --> 13:37.380]  So people who are stands of a certain artist on social media, like they have to perform
[13:37.380 --> 13:40.980]  their fealty to the artist, even if it's kind of in like an opposition to something else.
[13:40.980 --> 13:45.380]  Like, I don't think as far as I know, there's no actual animosity between Beyonce and Taylor
[13:45.380 --> 13:49.620]  Swift, but their fans kind of have to hate each other because that's the way you play
[13:50.500 --> 13:51.460]  fandom right now.
[13:51.460 --> 13:53.700]  That is, that's how you perform fandom right now.
[13:53.700 --> 13:57.380]  And so that thing about the like on the libs piece, I think it's a big piece of where
[13:57.380 --> 14:01.700]  they're like the impact of the policy or even the substance of the policies are relevant
[14:01.700 --> 14:06.340]  compared to does it antagonize the right people in a way that I find satisfying and that
[14:06.340 --> 14:08.980]  performs in group sort of identification for us.
[14:09.780 --> 14:14.180]  And what's funny about this is, I mean, it's not funny at all, obviously, in terms of like
[14:14.180 --> 14:16.100]  real world policy and real world impact.
[14:16.100 --> 14:20.900]  But what's striking about this is this is kind of impacted the most powerful people
[14:20.900 --> 14:23.300]  in the tech industry, like the wealthiest people, some of the wealthiest people who
[14:23.300 --> 14:28.500]  have ever existed in the history of humanity are juicing themselves up on the same, like
[14:28.500 --> 14:33.380]  kind of own the libs energy and getting that far divorced from reality, even when they're
[14:33.380 --> 14:34.740]  going to face a backlash.
[14:34.740 --> 14:39.060]  And it's really striking because I don't think Trump and his people in his circle are
[14:39.060 --> 14:41.220]  under any delusions that they're going to be liked by people.
[14:41.220 --> 14:45.140]  I mean, they're like, we know who our audience is and we care about them and everybody else
[14:45.780 --> 14:47.300]  we explicitly don't care about.
[14:47.300 --> 14:48.500]  And that's the game, right?
[14:49.220 --> 14:52.820]  Striking thing, though, is like, Musk is in this bubble.
[14:52.820 --> 14:56.980]  And this is, there's Peter Thiel, there's sort of this cohort, these guys that have
[14:56.980 --> 15:01.220]  gotten high on their own supply as they've become incredibly wealthy and sort of detached
[15:01.220 --> 15:04.500]  in the real world where they've kind of lost the plot.
[15:04.500 --> 15:04.820]  Right.
[15:04.820 --> 15:09.700]  And I think about this sort of when Musk was building SpaceX rockets, he's not like, I
[15:09.700 --> 15:13.380]  care about your alignment with me more than I care about whether the rocket goes up and
[15:13.380 --> 15:19.220]  we've turned the corner fully into like rocket goes up as secondary to literally your fealty
[15:19.220 --> 15:23.620]  to me, as we record this, he was just sort of had a, he's like fifth consecutive day
[15:23.620 --> 15:24.660]  of loyalty pledges.
[15:24.660 --> 15:27.620]  He's demanding from engineers of all people, right?
[15:27.620 --> 15:32.580]  That sort of least inclined personality type to say, let me leave with fealty.
[15:32.580 --> 15:32.980]  Right.
[15:32.980 --> 15:34.900]  And so it's such a, it's such a striking thing.
[15:34.900 --> 15:39.780]  You're like, well, how did they get to this place that is obviously grand scale foot shooting?
[15:39.780 --> 15:46.100]  It's just an unbelievable misread of like cultural standards and norms around technical
[15:46.100 --> 15:46.500]  culture.
[15:46.500 --> 15:49.620]  And you realize it's because they've been sort of hyping themselves up and the folks
[15:49.620 --> 15:53.780]  you've got in the room, like a Jason Calcanis, who's fairly well known within the industry,
[15:53.780 --> 15:55.460]  but I think outside the industry is not known.
[15:55.460 --> 15:58.420]  He's a doofus and he's been a doofus for like 20 years.
[15:58.420 --> 16:00.420]  People have been like, ah, that guy's kind of a chucklehead.
[16:00.420 --> 16:04.100]  He's not dumb per se, but he's definitely a kiss ass.
[16:04.100 --> 16:04.740]  Right.
[16:04.740 --> 16:11.300]  Calla Calacanis for people who don't know or vaguely remember his name started web blogs,
[16:11.300 --> 16:13.300]  zinc, I believe was his endeavor.
[16:13.300 --> 16:13.860]  Right.
[16:13.860 --> 16:17.300]  Well, he really started with Silicon alley insider, which was sort of the trade mag
[16:17.300 --> 16:21.460]  for New York during the.com bubble, which is both true and damning with faint praise.
[16:22.580 --> 16:29.300]  But then web blogs, Inc was like when blogs first took off and blog became, it was like
[16:29.300 --> 16:31.540]  a fresh word in everybody's mouth.
[16:31.540 --> 16:33.620]  And it was trying to be the rival to the Gawker network.
[16:33.620 --> 16:37.780]  So you had Gizmodo and you had Engadget and this was a rifle, a meaningful rivalry.
[16:39.140 --> 16:45.060]  And more or less though, he would find anybody, any blog that had gotten any traction in some
[16:45.060 --> 16:48.900]  measure of success, then web blogs, Inc would come out with a clone of it.
[16:48.900 --> 16:50.020]  And yeah, yeah.
[16:50.020 --> 16:50.820]  Very explicitly.
[16:50.820 --> 16:53.220]  There was no, there was, I mean, it was very straightforward.
[16:53.220 --> 16:57.380]  It's like if Nick debt and then Gawker won in a category, then we're going to do that
[16:57.380 --> 17:01.620]  category too, with like a very obvious imitation of it.
[17:01.620 --> 17:04.180]  It was sort of the first generation Samsung phones.
[17:04.180 --> 17:06.180]  Like, boy, that looks a lot like an iPhone.
[17:06.180 --> 17:06.580]  Right.
[17:06.580 --> 17:08.020]  And it was like this.
[17:08.020 --> 17:10.260]  And again, everything eventually mixes together.
[17:10.260 --> 17:13.140]  And there were very talented people who worked at Gizmodo.
[17:13.140 --> 17:13.860]  Incredibly so.
[17:13.860 --> 17:16.180]  Which was the clone and Engadget.
[17:16.180 --> 17:17.700]  Gizmodo was the Gawker winning.
[17:17.700 --> 17:18.660]  Oh no, that's right.
[17:18.660 --> 17:20.900]  That's how confused I am.
[17:20.900 --> 17:21.540]  Yeah, exactly.
[17:22.180 --> 17:24.100]  Well, I have friends who had worked at both.
[17:24.100 --> 17:28.100]  They were both good, but that was basically the idea was you come up with one and then
[17:28.100 --> 17:32.980]  all of a sudden Nick Denton got like a car blog and now web blogs, Inc had a car blog.
[17:32.980 --> 17:37.940]  And then as soon as blogs became not really the hot thing anymore, he just lost interest
[17:37.940 --> 17:41.380]  in it and moved on, sold it to AOL and skip town.
[17:41.380 --> 17:41.700]  Yeah.
[17:41.700 --> 17:44.980]  And some now he's in Elon Musk's inner circle.
[17:44.980 --> 17:48.420]  Well, and the texts have come out and this is the kind of thing where like in the substance
[17:48.420 --> 17:51.780]  of it, it doesn't matter that much, but it's been telling because the texts that were
[17:51.780 --> 17:53.620]  subpoenaed for Musk for another trial.
[17:53.620 --> 17:58.420]  So they included these texts with Kalkanis and it was this very obvious kissing, right?
[17:58.420 --> 18:02.980]  And it was kind of striking because I was like, I would think, well, one, if you're
[18:02.980 --> 18:06.580]  the richest man in the world, I'm sure you're constantly getting peep kissing your butt
[18:06.580 --> 18:08.180]  because they want to get close to you.
[18:08.180 --> 18:11.860]  But I would think that would naturally put you off of it because it's very obvious.
[18:12.500 --> 18:13.700]  And yet here they are in there.
[18:13.700 --> 18:15.460]  And I was like, man, this guy doesn't have any friends.
[18:16.260 --> 18:21.140]  And that started the same thing as when Musk had done SNL because it was just brutally
[18:21.140 --> 18:24.100]  unfunny, right? It was just a really horrible misread.
[18:24.100 --> 18:27.780]  And it's the kind of thing where it's like, Oh, you don't have any friends because
[18:27.780 --> 18:30.180]  somebody's going to tell you like, this isn't working, man.
[18:30.180 --> 18:32.500]  Like this isn't, you don't, it's not winning.
[18:32.500 --> 18:34.900]  Like this isn't your lane or whatever the language is.
[18:34.900 --> 18:39.380]  But like, it was such a striking thing because I'm like, that's a rough place to be as
[18:39.380 --> 18:41.060]  if you don't have that backstop.
[18:41.060 --> 18:45.460]  And it is striking because you look at, there have been similarly powerful tycoons, right?
[18:45.460 --> 18:52.420]  And most pertinent for you, Steve jobs, right? And certainly a domineering presence, certainly
[18:52.420 --> 18:55.940]  somebody who held no truck with bullshit from people and could bowl people over.
[18:56.500 --> 18:59.060]  But clearly the kind of person that could take feedback.
[18:59.060 --> 19:01.860]  And I mean, actually, I think the thing he would tend to do with the next day, come back
[19:01.860 --> 19:03.460]  and sort of say, Oh, that was my idea.
[19:03.460 --> 19:06.980]  But he took the feedback and heard the point where somebody's like, that's not it.
[19:06.980 --> 19:07.940]  That's not working.
[19:08.580 --> 19:10.260]  And also stayed in his lane.
[19:10.260 --> 19:12.100]  Like he was not trying to be a cultural figure.
[19:12.100 --> 19:13.780]  He was not trying to date supermodels.
[19:13.780 --> 19:18.180]  He was not trying to the things are that the trappings of, of losing the plot about your
[19:18.180 --> 19:19.540]  ego in the world.
[19:19.540 --> 19:21.860]  And he had a huge ego, but not in that lane.
[19:21.860 --> 19:23.220]  Well, let's say this.
[19:23.220 --> 19:32.340]  I would say most obviously it almost indisputably would be his leadership of Pixar where yes,
[19:32.340 --> 19:40.020]  where by all accounts, he never tried to, he never stepped in and told them how to make
[19:40.020 --> 19:40.740]  movies.
[19:40.740 --> 19:45.780]  Now they famously, and John Lasseter has said this at Catmull has said this other directors
[19:45.780 --> 19:48.180]  have said this where, you know, while jobs was alive.
[19:48.180 --> 19:53.540]  And in those like early years of Pixar, I know it's not the earliest years of Pixar
[19:53.540 --> 19:55.940]  as a company, but Pixar post independent.
[19:55.940 --> 19:56.180]  Yeah.
[19:56.180 --> 19:56.500]  Yeah.
[19:56.500 --> 20:03.300]  In between Toy Story and Disney acquiring Pixar that they, and everybody who's ever
[20:03.300 --> 20:05.700]  worked at Pixar, it always talks about its story.
[20:05.700 --> 20:06.980]  It's not about the computers.
[20:06.980 --> 20:08.980]  It's not about the actors, it's story.
[20:08.980 --> 20:14.500]  And every Pixar movie has always had a point where they realize while they're in production,
[20:14.500 --> 20:22.020]  uh, the story, you got to start over the story breaks here 40, 45 minutes into it or 50 minutes
[20:22.020 --> 20:23.940]  into it or somewhere between act two and three.
[20:24.580 --> 20:26.180]  Oh, this really breaks.
[20:26.180 --> 20:29.460]  And that there have been, there were times where they would show Steve jobs, the rough
[20:29.460 --> 20:33.780]  cut, and he would have like, just like two comments, but it was because, Hey, Steve,
[20:33.780 --> 20:34.660]  take a look at this.
[20:34.660 --> 20:39.300]  And they asked him and then he'd get, and they said like, often he would come up with
[20:39.300 --> 20:44.740]  very insightful, but very brief, not acting like, Oh, I can direct movies.
[20:44.740 --> 20:47.460]  I can do line readings better than Tom Hanks.
[20:47.460 --> 20:47.620]  Yeah.
[20:47.620 --> 20:50.100]  That's sort of it is the idea of like expertise.
[20:50.100 --> 20:50.420]  Right.
[20:50.420 --> 20:56.740]  And I think, and you look at the, also the legacy of execs surrounding jobs where like
[20:56.740 --> 21:02.260]  there is not historically a better global supply chain manager than Tim Cook probably
[21:02.260 --> 21:02.740]  ever.
[21:02.740 --> 21:03.060]  Right.
[21:03.060 --> 21:03.540]  Right.
[21:03.540 --> 21:04.900]  Johnny Ive speaks for himself.
[21:04.900 --> 21:08.660]  I mean, and I think those things is like, people like that are drawn to a leader who's
[21:08.660 --> 21:11.220]  going to give them the shot to do the thing where they can be the best in the world at
[21:11.220 --> 21:14.340]  what they do and nobody's going to be what he is at a keynote.
[21:14.340 --> 21:19.780]  And there is zero people in the world who know how multi-million scale social networks
[21:19.780 --> 21:22.660]  work, who would tell you Jason Calcanis is the guy to get in the room.
[21:23.780 --> 21:24.100]  All right.
[21:24.100 --> 21:26.660]  Let's step back before we keep going with Twitter.
[21:27.860 --> 21:29.140]  I'm going to go out in the lane now.
[21:29.140 --> 21:33.460]  I've got, I've already got probably some crow to eat here on Twitter and I'm not afraid
[21:33.460 --> 21:34.420]  to admit when I'm wrong.
[21:34.420 --> 21:36.020]  I would like to think good trade.
[21:36.020 --> 21:42.180]  I've often said that the way to be right all the time is to hopefully be right, most
[21:42.180 --> 21:46.900]  correct most of the time, but to have the self-awareness and humility to recognize when
[21:46.900 --> 21:50.420]  you're wrong and then go back, figure out why you're wrong and say, Oh, I was wrong.
[21:50.420 --> 21:51.780]  And now here's what I think.
[21:51.780 --> 21:55.700]  And if you can do that, you can come pretty close to being right all the time.
[21:56.580 --> 22:03.140]  Probably said some things that have already not aged well about Twitter and under Elon
[22:03.140 --> 22:03.540]  Musk.
[22:03.540 --> 22:07.780]  But let me go out on a limb here politically and say something publicly that I have been
[22:07.780 --> 22:12.820]  saying to friends privately for over a year, which is that I do not believe Donald Trump
[22:12.820 --> 22:17.380]  is going to be the nominee for the Republicans in the next presidential election.
[22:17.380 --> 22:19.620]  And I don't even think it's going to be close.
[22:19.620 --> 22:24.100]  He can announce, you know, he did yesterday, but I don't even think it's going to come
[22:24.100 --> 22:26.260]  to the point where it's some kind of close.
[22:26.260 --> 22:29.140]  Oh, which the next slate of whatever.
[22:29.140 --> 22:34.740]  I think by the time the actual primary start in early 2024, he'll already be out of the
[22:34.740 --> 22:34.900]  race.
[22:34.900 --> 22:35.700]  It'll be a runaway.
[22:35.700 --> 22:38.500]  So this is interesting because I was talking to a friend of mine who is an immigrant who's
[22:38.500 --> 22:42.900]  been very successful in the U S and, and again, I hate grand unifying theories, but this is
[22:42.900 --> 22:46.500]  another one where I'm like, Oof, this one it's hard for me to argue against, which is
[22:46.500 --> 22:50.500]  that, and this is the thing where immigrants always have the insight into American culture
[22:50.500 --> 22:52.340]  that like we miss growing up here.
[22:52.340 --> 22:54.100]  Cause I grew up in Pennsylvania too, right.
[22:54.100 --> 22:56.900]  Is he's like, you know, Americans hate losers.
[22:56.900 --> 22:59.060]  It's like, they don't want to come back story.
[22:59.060 --> 23:01.460]  They don't mind the water in the wilderness.
[23:01.460 --> 23:06.500]  And then, and now you're going to try and regain your title, but they really hate losers
[23:06.500 --> 23:08.100]  and these hate sore losers.
[23:08.660 --> 23:11.620]  Like it's sad and it's gross and they don't want to get any on them.
[23:11.620 --> 23:15.940]  And that was the thing where I was like, man, if that ain't the truest truth, and especially
[23:15.940 --> 23:22.180]  in traditionally like conventional masculinity, conservative American identity, you know,
[23:22.180 --> 23:26.420]  I grew up like I, you know, my, my girlfriend drove me to my senior prom in an F one 50,
[23:26.420 --> 23:26.500]  right?
[23:26.500 --> 23:28.660]  Like this is where I'm from, although she was driving.
[23:28.660 --> 23:29.860]  So they probably got mad about that.
[23:29.860 --> 23:37.780]  But the thing is that like that identity cannot stand the idea of a loser, like a loser, like
[23:37.780 --> 23:41.140]  a sore loser is who I got to say is my guy.
[23:41.780 --> 23:43.540]  Like, no, like, no, I'm not going to do it.
[23:43.540 --> 23:44.100]  I'm not going to do it.
[23:44.100 --> 23:44.260]  Right.
[23:44.260 --> 23:45.700]  Cause like we're super fickle.
[23:45.700 --> 23:48.020]  Like I like my team when they're winning.
[23:48.020 --> 23:53.460]  And so I think that thing where like the nuance, like it definitely like folks like me who
[23:53.460 --> 23:58.340]  are like now the big city liberal media types are like, Oh, it's sometimes you have a downtime
[23:58.340 --> 23:58.660]  or whatever.
[23:58.660 --> 24:03.140]  But like the people who got mad about Luke Skywalker taking a sabbatical in the star
[24:03.140 --> 24:04.500]  Wars sequels, right?
[24:04.500 --> 24:09.700]  Like they're not trying to find a guy who's like still real mad about something that happened
[24:09.700 --> 24:11.700]  years ago as their leader.
[24:11.700 --> 24:14.340]  And I was like, that is a very plausible argument.
[24:14.340 --> 24:19.060]  And that does lead me to believe your assertion about a nomination doesn't look good because
[24:19.060 --> 24:21.060]  it's like, he's got loser stench all over him.
[24:21.060 --> 24:26.180]  The yep, what I'm predicting is not based on Trumpism declining, which I hope people
[24:26.180 --> 24:28.900]  who are in or in they're not right, but I would love it if it did.
[24:28.900 --> 24:34.500]  And I would love if whoever the Republican nomination nominee ends up being is untrumpy
[24:34.500 --> 24:41.540]  in as many ways as possible, even though I know that the least Trumpy Republican who
[24:41.540 --> 24:43.620]  might win, let's say like a Mitt Romney, right?
[24:43.620 --> 24:49.300]  Like I would not have been a fan of a Mitt Romney or a John McCain presidency in numerous
[24:49.300 --> 24:51.780]  ways, but I also respect both men.
[24:51.780 --> 24:58.020]  And that's part of living in a democracy is I understand that as long as my health maintains
[24:58.020 --> 25:03.300]  for the remaining decades of my life, there are going to be Republican presidents and
[25:03.300 --> 25:04.500]  Democratic presidents.
[25:04.500 --> 25:07.780]  And I'm probably not going to like any of the Republicans, but I at least hope that
[25:07.780 --> 25:13.540]  whoever they are, are honest people with the best intentions for the country.
[25:13.540 --> 25:17.620]  And I think Trumpism is a political slant that that's not true for.
[25:17.620 --> 25:19.860]  But yeah, no, it's a poison to the system, right?
[25:19.860 --> 25:23.620]  It's not a balance of this vision of democracy versus that one.
[25:23.620 --> 25:25.940]  It's like, let's break the system, but that's it.
[25:25.940 --> 25:33.700]  But but so I ideally and talking, you know what I mean, speaking of ideals, political
[25:33.700 --> 25:41.300]  ideals, I care more about that, but I'm just saying as an observer who's, you know, overall
[25:41.300 --> 25:42.660]  pretty good at predicting elections.
[25:42.660 --> 25:48.660]  I actually want some money betting on this one on predicted.
[25:48.660 --> 25:51.300]  No, I mean, it wasn't just because I was the market is wise.
[25:51.300 --> 25:55.380]  I wasn't just voting based on who I hoped win, but who I actually thought would win.
[25:55.380 --> 25:59.140]  Like here in Pennsylvania, I thought, I think John Fetterman will pull this out.
[25:59.140 --> 25:59.780]  And he did.
[25:59.780 --> 26:03.060]  But that's another one again, where it's like having grown up around the folks who would
[26:03.060 --> 26:05.060]  be voting for him, like, oh, yeah, this guy's got it.
[26:05.060 --> 26:06.260]  Yeah, it's a no brainer.
[26:06.260 --> 26:09.060]  Oh, and if he hadn't had the stroke, I mean, he would have run away with it.
[26:09.060 --> 26:10.900]  Yeah, I think he's going to be all right on that front.
[26:10.900 --> 26:13.140]  But anyway, it's that he's a loser.
[26:14.180 --> 26:15.860]  And Trump knows it, too.
[26:15.860 --> 26:20.660]  And I think that's why he's so latched on to this big lie theory is that it's his only
[26:20.660 --> 26:22.500]  chance because otherwise he lost.
[26:22.500 --> 26:26.500]  And you can't these two things can't both be true.
[26:26.500 --> 26:34.660]  You can't say Joe Biden totally sucks and I lost to the guy who totally sucks.
[26:34.660 --> 26:36.580]  You should vote for me again next time.
[26:36.580 --> 26:37.140]  Look at my power.
[26:37.140 --> 26:38.260]  Yeah, it doesn't work.
[26:38.260 --> 26:38.980]  It doesn't work.
[26:38.980 --> 26:39.860]  He's a loser.
[26:39.860 --> 26:43.780]  And you're so right when you're an outside observer, like an immigrant, and you just
[26:43.780 --> 26:48.580]  observe it, you just say, oh, yeah, Americans hate losers in a way that other countries
[26:48.580 --> 26:49.300]  maybe don't have.
[26:49.940 --> 26:52.740]  Nobody more empathetic about it, honestly, because they're like, well, everybody takes
[26:52.740 --> 26:53.060]  a turn.
[26:53.060 --> 26:54.180]  Everybody's a loser sometimes.
[26:54.180 --> 26:55.860]  Or we're like, no, I don't.
[26:55.860 --> 26:56.980]  I'm in straight denial.
[26:56.980 --> 26:58.020]  We've only ever been winners.
[26:58.020 --> 27:00.980]  You look at our narratives around national greatness.
[27:00.980 --> 27:05.300]  And I would say I bet the majority of Americans believe we've never lost a war.
[27:05.300 --> 27:06.980]  Oh, I grew up thinking that.
[27:07.540 --> 27:08.980]  I mean, we were probably taught that in school.
[27:08.980 --> 27:09.220]  Yeah.
[27:09.220 --> 27:14.340]  And it's just like a fascinating delusion, which I honestly kind of find charming.
[27:14.980 --> 27:17.700]  Obviously, there's a lot of really negative effects to it.
[27:17.700 --> 27:22.100]  But as a personality trait for a country, it's like, oh, that's kind of sweet.
[27:22.100 --> 27:25.780]  You have this weird fixation that you have to be the best, and you won everything, and
[27:25.780 --> 27:26.740]  you're a winner all the time.
[27:26.740 --> 27:28.100]  So anyway, that's my theory.
[27:28.100 --> 27:34.580]  But also, I just see a certain irony in it in that it was exacerbated in this midterm
[27:34.580 --> 27:38.100]  in a way that Trump himself exactly predicted.
[27:38.100 --> 27:42.180]  And his political instincts are astute.
[27:42.180 --> 27:47.860]  I mean, he agreed a moment very well, but he also has zero impulse control.
[27:47.860 --> 27:51.460]  And so I think it's a really weird combination.
[27:51.460 --> 27:55.220]  Usually, people who are good at understanding the political temperature, and therefore,
[27:55.220 --> 27:58.420]  I will use that to decide what I do in response.
[27:58.420 --> 27:59.300]  But that's not him.
[28:00.820 --> 28:06.580]  Let's get back to leaders who have very poor impulse control in a moment.
[28:06.580 --> 28:10.660]  But I'm going to take a break here and thank our first sponsor, our good friends at Collide.
[28:10.660 --> 28:12.500]  That's K-O-L-I-D-E.
[28:12.500 --> 28:17.700]  If you are listening to the talk show, the odds are very good that at some point, your
[28:17.700 --> 28:25.460]  company is going to go through an audit like SOC 2 or ISO 27001.
[28:25.460 --> 28:28.900]  I don't know what those things are because I don't work for a corporation, but they
[28:28.900 --> 28:30.180]  sound terrible to me.
[28:30.180 --> 28:34.580]  And when you do go through one of these audits, you have to answer some tough questions about
[28:34.580 --> 28:39.940]  endpoint security, like, do all of your company laptops have their disks encrypted?
[28:39.940 --> 28:42.740]  Does everyone have the company's password manager installed?
[28:42.740 --> 28:50.020]  Do you have a system in place to monitor and maintain compliance throughout your cross-platform
[28:50.020 --> 28:50.900]  fleet?
[28:50.900 --> 28:55.220]  Even if you're confident, the answer to all of those questions is yes.
[28:55.220 --> 28:59.460]  The bigger question when you're facing an audit is, can you prove it?
[28:59.460 --> 29:03.700]  If you're not quite sure how you'd go about proving that, you need Collide.
[29:03.700 --> 29:10.580]  Collide is an endpoint security tool for Mac, Windows, and Linux devices that does things
[29:10.580 --> 29:15.300]  MDMs cannot do, and it gives you visibility you need to achieve and maintain compliance.
[29:15.300 --> 29:21.540]  Best of all, Collide doesn't resort to surveilling your employees or locking down their devices.
[29:21.540 --> 29:28.500]  Instead, it works with your end users to resolve the issues, to teach them, and it relies on
[29:28.500 --> 29:32.500]  and it relies on their cooperation and informed consent.
[29:32.500 --> 29:37.620]  You can meet your security goals and pass your audit without compromising on privacy
[29:37.620 --> 29:40.340]  or a relationship with your employees based on trust.
[29:40.340 --> 29:44.580]  Visit Collide.com slash the talk show to find out how.
[29:44.580 --> 29:48.820]  If you follow that link, they will hook you up with a goodie bag that includes a free
[29:48.820 --> 29:51.780]  T-shirt just for activating a free trial.
[29:51.780 --> 29:57.380]  That's K-O-L-I-D-E dot com slash the talk show.
[29:57.380 --> 29:59.060]  My thanks to them.
[29:59.060 --> 30:00.900]  You don't want to mess around with SOC 2 compliance.
[30:00.900 --> 30:01.620]  You got to get it right.
[30:02.260 --> 30:02.820]  SOC 2?
[30:02.820 --> 30:04.500]  See, I never know what you pronounce.
[30:04.500 --> 30:07.460]  So for the first time in my life, I work at a publicly traded company.
[30:07.460 --> 30:09.300]  I've never had like a grown-up job.
[30:09.300 --> 30:13.380]  I've been in startups my whole career, and now I work at Vastly and they're a publicly
[30:13.380 --> 30:16.500]  traded company and they do all the grown-up stuff and it's like, oh, this is fascinating.
[30:16.500 --> 30:20.740]  It's actually very interesting and is the contrast to organizations that don't have
[30:20.740 --> 30:22.660]  grown-up leadership that wants to do things right.
[30:22.660 --> 30:23.620]  What was I talking about?
[30:23.620 --> 30:25.060]  Billionaires with impulse control.
[30:25.060 --> 30:28.260]  Although actually one of them is a legit billionaire.
[30:28.260 --> 30:29.380]  His name is Elon Musk.
[30:29.380 --> 30:29.620]  All right.
[30:29.620 --> 30:31.700]  Let me read a tweet from my good friend.
[30:31.700 --> 30:32.180]  Everybody.
[30:32.180 --> 30:34.100]  The internet's good friend, Cable Sasser.
[30:35.380 --> 30:38.100]  He tweeted at me, I believe it was this morning.
[30:38.100 --> 30:39.300]  Nope, it was yesterday.
[30:39.300 --> 30:41.780]  But he's a good friend.
[30:41.780 --> 30:46.740]  He was the first live guest, the first time I ever did a live episode of this show.
[30:46.740 --> 30:47.860]  Cable was my guest.
[30:47.860 --> 30:48.340]  Good friend.
[30:48.340 --> 30:50.660]  And I can take this in all the good spirit.
[30:50.660 --> 30:54.100]  But he said on Twitter, every day I am champing at the bit.
[30:54.100 --> 30:54.900]  He got champion.
[30:54.900 --> 30:55.300]  Correct.
[30:55.300 --> 30:56.100]  Of course.
[30:56.100 --> 30:56.580]  Yep.
[30:56.580 --> 30:57.300]  Not topic.
[30:57.300 --> 31:01.940]  I am champing at the bit is to make a small run of quote.
[31:01.940 --> 31:06.980]  I'm more optimistic about Twitter's future than I have been in years.
[31:06.980 --> 31:08.740]  John Gruber t-shirts.
[31:11.220 --> 31:12.260]  Do they taste like crow?
[31:12.980 --> 31:16.100]  They taste like clay claim chowder claim chowder.
[31:16.100 --> 31:16.340]  Yeah.
[31:17.700 --> 31:18.740]  I got chowder, man.
[31:18.740 --> 31:19.460]  You got chowder.
[31:19.460 --> 31:20.580]  Well, I did say that.
[31:20.580 --> 31:26.100]  And I would not say that today.
[31:27.700 --> 31:34.740]  I still am not as pessimistic about Twitter's future as many people are.
[31:34.740 --> 31:38.660]  But perhaps I, one of the reasons I wanted to have you on the show is maybe you'll talk
[31:38.660 --> 31:41.140]  me into being even more pessimistic than I should be.
[31:42.660 --> 31:44.180]  I want to diagnose why you said it.
[31:45.460 --> 31:46.020]  All right.
[31:46.020 --> 31:47.140]  Can I dig into that?
[31:47.140 --> 31:48.020]  Absolutely.
[31:48.020 --> 31:48.980]  That's a great question.
[31:48.980 --> 31:56.100]  All right, number one, my theory of Elon Musk, and I'm not disabused of it entirely yet,
[31:56.100 --> 32:00.980]  although I've obviously this is the part that I would have to backtrack the most on is regardless
[32:00.980 --> 32:01.460]  of Twitter.
[32:01.460 --> 32:10.660]  But Elon personally is that I see Elon Musk as an unreliable narrator, a highly unreliable
[32:10.660 --> 32:13.780]  narrator, and that this is as a strategy.
[32:13.780 --> 32:16.020]  It's an intentional, partially strategic.
[32:16.020 --> 32:21.300]  And again, that is I've said this on podcast before, too, that and some people, when I
[32:21.300 --> 32:24.420]  said it, made any comparison to Steve Jobs.
[32:25.220 --> 32:28.180]  Some people object to it because people still admire Steve Jobs.
[32:28.180 --> 32:31.540]  And now that he's passed, there's a martyr aspect to it.
[32:31.540 --> 32:37.700]  And people see it as sacrilegious or offensive to say that there's any similarity between
[32:37.700 --> 32:42.020]  a despised figure like Elon Musk and a revered figure like Steve Jobs.
[32:42.020 --> 32:46.900]  But with Steve Jobs, the example, the canonical example to me is when they first came out
[32:46.900 --> 32:52.260]  with the iPod that had a color screen and their reason there.
[32:52.260 --> 32:55.060]  Why would you add a color screen to these devices?
[32:55.060 --> 33:00.180]  And it was, well, you can now in addition to your music, you can sync your photo library
[33:00.180 --> 33:01.540]  and never adding video.
[33:01.540 --> 33:01.780]  Yeah.
[33:01.780 --> 33:08.020]  And in the hands on area after the keynote and Steve Jobs was there and they actually
[33:08.020 --> 33:10.980]  let the media ask questions at the time.
[33:10.980 --> 33:17.140]  Yeah, we said, hey, Steve, you know, these photos look great on the iPod, but why not?
[33:17.140 --> 33:18.100]  What about video?
[33:18.100 --> 33:21.220]  And he said, ah, nobody wants to watch video on a screen that small.
[33:22.660 --> 33:28.500]  And then 12 months later, they came out with an iPod with the same size screen that in
[33:28.500 --> 33:31.860]  addition to showing your photos played video.
[33:31.860 --> 33:37.540]  Now, in addition to it's not like, oh, in those 12 months, they realize that the way
[33:37.540 --> 33:42.420]  that these lead times work, the day that Steve Jobs said no one wants to watch video on a
[33:42.420 --> 33:49.620]  screen that size, he knew damn well that next year's iPod is already well into some phase
[33:49.620 --> 33:51.620]  of development of engineering.
[33:51.620 --> 33:56.580]  You know, it was halfway through development and was like in product testing at the quantities
[33:56.580 --> 33:58.340]  they were making iPods at that time.
[33:58.340 --> 34:02.340]  You don't add a feature like that six months beforehand.
[34:02.340 --> 34:05.300]  He knew that they were coming out with a video playing iPod.
[34:05.300 --> 34:09.860]  He was an unreliable narrator for strategic reasons because he didn't want to say anything
[34:09.860 --> 34:14.100]  that would discourage people from buying an iPod today and waiting a year for one that
[34:14.100 --> 34:14.900]  played video.
[34:14.900 --> 34:19.380]  Why not have them buy one today and then buy another one a year from now to get the video?
[34:19.380 --> 34:25.940]  So I do see Elon Musk as an unreliable narrator strategically in the same way.
[34:25.940 --> 34:32.420]  But I also see him as an unreliable narrator in a completely unstrategic way, which is
[34:32.420 --> 34:36.980]  his lack of impulse control, and that he'd be the first to admit it, that he at times
[34:36.980 --> 34:39.860]  has gotten high and tweeted things.
[34:41.060 --> 34:43.220]  Which is not a thing I think we would say about Jobs.
[34:43.220 --> 34:50.580]  No, and not a thing you would say about the CEO of any company or any of the other previous
[34:50.580 --> 34:53.220]  richest people in the world in the last several centuries.
[34:53.220 --> 34:53.540]  Right.
[34:53.540 --> 34:58.100]  It is not something that those people in those positions would tend to do.
[34:58.100 --> 35:05.940]  Right, and so therefore, my basic idea of why I felt like, hey, this might be good for
[35:05.940 --> 35:12.340]  Elon Musk to buy Twitter, take it private, alleviate it of any shareholder pressures,
[35:13.220 --> 35:18.500]  and seriously rejigger and do a lot of stuff.
[35:18.500 --> 35:24.820]  Yeah, so I want to sort of share a couple theories of how we get to, because this is
[35:24.820 --> 35:30.260]  not me dragging you, like I have made these bad calls many times too, being on social
[35:30.260 --> 35:31.700]  media for as long as you have been too.
[35:31.700 --> 35:34.820]  And I think there's a couple of things I've seen in terms of the pattern of like, why
[35:34.820 --> 35:37.220]  do we get it wrong or why do we get optimistic about these things?
[35:37.220 --> 35:40.820]  I think the first is to the unreliable narrator point.
[35:40.820 --> 35:44.020]  Visionaries don't deal in facts, right?
[35:44.020 --> 35:49.300]  Because if you say factually, I'm going to make a phone and we're going to sell 100
[35:49.300 --> 35:51.780]  million of them, it's an irrational statement.
[35:51.780 --> 35:55.060]  And every person who's ever said it, except for like two, was lying.
[35:56.180 --> 36:00.820]  And so you have to have an irrational belief or, you know, whatever.
[36:00.820 --> 36:03.460]  We're going to finally revive the electric car market.
[36:03.460 --> 36:04.900]  Like these are irrational statements.
[36:04.900 --> 36:11.300]  And so, or we'll have millions of electric cars on the road by 2017 or exactly right.
[36:11.300 --> 36:14.340]  So these are things where you have to believe beyond what's rational.
[36:14.340 --> 36:17.380]  And I mean, I've been a founder and run companies and obviously nowhere near that
[36:17.380 --> 36:21.380]  scale, but in terms of like, you know, we have a platform that people have made millions
[36:21.380 --> 36:22.260]  of apps on.
[36:22.260 --> 36:24.580]  And if five years ago you said people are gonna make millions of apps and they're
[36:24.580 --> 36:28.100]  going to do it on the regular old web, that that was an irrational statement with glitch.
[36:28.100 --> 36:31.460]  And so I think that's the thing where like, I have a tremendous respect for that.
[36:31.460 --> 36:34.180]  And I think there's something like, this is what we tell our kids, right?
[36:34.180 --> 36:35.780]  Dream big and shoot for the stars, right?
[36:35.780 --> 36:38.020]  Like it's a really, that is actually a good thing.
[36:38.740 --> 36:43.540]  And it's indistinguishable from narratively.
[36:43.540 --> 36:47.940]  I'm surrounded by a bunch of kiss asses in a boardroom and we're all high on our
[36:47.940 --> 36:49.380]  own supply or just high.
[36:49.380 --> 36:52.100]  And our takeaway is we can do anything we want.
[36:52.100 --> 36:52.580]  Right.
[36:52.580 --> 36:58.260]  And so, because those are so structurally similar, then the question is like, how can
[36:58.260 --> 37:02.740]  we distinguish when it's in the former visionary category and not in the latter,
[37:02.740 --> 37:04.500]  like I said, high on your own supply category.
[37:04.500 --> 37:10.100]  And I think part of it is we have a weird erroneous belief in the genius myth.
[37:10.100 --> 37:14.420]  And again, this is one of the things where jobs being an outlier has set us up for a
[37:14.420 --> 37:18.500]  whole generation of people that think they're him to make the same mistakes, because
[37:18.500 --> 37:21.940]  they've learned the wrong lessons about the narrative that was applied to him, which
[37:21.940 --> 37:25.380]  is that there's this idea of an ineffable genius that a person can have.
[37:25.380 --> 37:30.020]  And it's all dudes that some guy can have that is applied across different domains
[37:30.020 --> 37:33.300]  and genres and contexts and problem spaces.
[37:33.940 --> 37:34.260]  Right.
[37:34.260 --> 37:38.100]  And the thing that I love is like this conversation about the Twitter and must
[37:38.100 --> 37:40.900]  coming in, they're like, like, this isn't going to be that hard for him.
[37:40.900 --> 37:42.100]  It's not rocket science.
[37:42.100 --> 37:42.340]  Right.
[37:42.340 --> 37:43.220]  And I'm like, you're right.
[37:43.220 --> 37:43.860]  It's harder.
[37:44.500 --> 37:46.580]  It's harder than rocket science, right?
[37:46.580 --> 37:50.980]  Because when you launch a rocket at SpaceX, you're only launching one at a time and
[37:50.980 --> 37:52.740]  nobody's trying to take the rocket down.
[37:53.380 --> 37:54.980]  There's only gravity, right?
[37:54.980 --> 37:59.060]  Whereas you have bad actors that are trying to take Twitter down or share
[37:59.060 --> 38:00.100]  misinformation messages.
[38:00.100 --> 38:04.660]  And the problem is largely social, cultural, political, as much as it is technical.
[38:04.660 --> 38:06.100]  And it's really hard.
[38:06.100 --> 38:07.300]  It's a really hard problem.
[38:07.300 --> 38:07.700]  Right.
[38:07.700 --> 38:12.660]  And so this set of skills is not applicable across these domains.
[38:12.660 --> 38:16.660]  And that's the thing that like is not popular to say.
[38:16.660 --> 38:21.300]  And also the important thing here too, is that who are the deputies?
[38:21.300 --> 38:22.500]  Who are the people that surround you?
[38:22.500 --> 38:26.980]  Are they as enamored with the mission of doing this work?
[38:26.980 --> 38:28.580]  And is it the thing that gets them up in the morning?
[38:28.580 --> 38:31.780]  Cause I think everybody, again, like I don't know much about SpaceX and I'm not
[38:31.780 --> 38:34.340]  some huge fan of theirs, but like they got rockets in a lot of time.
[38:34.340 --> 38:35.460]  It's a hard problem.
[38:35.460 --> 38:38.420]  I guarantee you everybody in senior management there is obsessed with
[38:38.420 --> 38:39.460]  getting rockets in the air.
[38:40.180 --> 38:40.420]  Right.
[38:40.420 --> 38:41.700]  There's no question about it.
[38:41.700 --> 38:45.060]  You can tell like you don't, they wouldn't get there if that wasn't happening.
[38:45.060 --> 38:49.940]  And there is nobody in the inner circle around mosque that is like, I want to
[38:49.940 --> 38:52.180]  enable this new kind of conversation.
[38:52.180 --> 38:55.540]  And the talent was, he came in talking about the blue checkmark, which is a
[38:55.540 --> 39:00.660]  concern that is an obsession with a tiny percentage of people, even on Twitter
[39:00.660 --> 39:03.060]  itself, let alone in society as a whole.
[39:03.700 --> 39:09.220]  And also a particular obsession of the sort of extremist tech tycoon circle
[39:09.220 --> 39:10.260]  jerk that he's in right.
[39:10.260 --> 39:13.140]  Where they're like, this is the kind of thing they think is really important.
[39:13.140 --> 39:16.180]  And they kind of, this is why journalists hate us and all this kind of stuff.
[39:16.180 --> 39:18.980]  And you're like normal people are just like, I go on here to see what's
[39:18.980 --> 39:20.180]  happening with sports scores.
[39:20.180 --> 39:22.340]  Maybe like what's happening at an awards show.
[39:22.340 --> 39:25.140]  That's just like some detritus on the screen while I do it.
[39:25.140 --> 39:26.900]  It's Chrome and UI.
[39:26.900 --> 39:29.780]  It's not a thing that I think about conceptually is having to do with my
[39:29.780 --> 39:32.020]  sense of self or what's important in the world.
[39:32.020 --> 39:35.060]  But they started with this thing here, like of all the problems this company
[39:35.060 --> 39:38.500]  had, that was so low on the list of things that were broken.
[39:38.500 --> 39:43.780]  I start with, I will say that in these, what are we at three weeks, three
[39:43.780 --> 39:48.420]  weeks into the musk here in these very long three weeks, incredibly musk era.
[39:48.420 --> 39:52.740]  That was the moment where I first, my stomach sunk and I thought, Oh, well,
[39:53.380 --> 39:54.420]  this guy's a chump.
[39:55.540 --> 40:00.340]  Um, no, but let's, I don't want to move past the, uh, your, your keenly
[40:00.340 --> 40:04.580]  asked question of why would I say that I felt more optimistic when it was
[40:04.580 --> 40:08.020]  officially made, uh, it was officially going to be handed over to the
[40:08.020 --> 40:08.980]  handed over to musk.
[40:08.980 --> 40:11.860]  Why did I feel more optimistic about Twitter than I have in years?
[40:11.860 --> 40:12.180]  All right.
[40:12.180 --> 40:12.980]  Let me go back to that.
[40:12.980 --> 40:15.300]  I don't want to, cause it's, it's worth examining.
[40:15.300 --> 40:18.660]  So let's put musk aside Twitter as it stood.
[40:18.660 --> 40:22.500]  I thought was in a terrible position.
[40:22.500 --> 40:24.180]  It, and I love Twitter.
[40:24.180 --> 40:27.540]  I think it is from the moment it has been something special right from the
[40:27.540 --> 40:28.660]  start from the start.
[40:28.660 --> 40:31.380]  As soon as I saw it, it's the rare thing.
[40:31.380 --> 40:35.300]  And I tend to see, I tend to be confused by new things.
[40:35.300 --> 40:37.460]  And if I don't get it, I don't want to sign up for it.
[40:37.460 --> 40:38.340]  I got it right away.
[40:38.340 --> 40:41.220]  It's like, oh, you just get a name and then you have a box and you hit a
[40:41.220 --> 40:41.620]  button.
[40:41.620 --> 40:46.340]  And then it's like, you've said a thing and then it has a URL and everybody can
[40:46.340 --> 40:47.540]  see that you said the thing.
[40:48.260 --> 40:49.780]  And the limit is bloggers.
[40:49.780 --> 40:51.460]  It was better in some ways than what we had.
[40:51.460 --> 40:51.860]  Yeah.
[40:51.860 --> 40:55.060]  And the limit was, it was fascinating.
[40:55.060 --> 40:59.380]  In fact, I was so enamored of the one 40 character limit that I was opposed to
[40:59.380 --> 41:01.140]  raising it to two 80.
[41:01.140 --> 41:04.340]  But I realized the most John Gruber thing I've ever heard in my life.
[41:04.340 --> 41:04.980]  I remember that.
[41:04.980 --> 41:07.220]  And I was like, yeah, a lot of writers were, I
[41:07.220 --> 41:09.140]  remember Stephen King and J.K.
[41:09.140 --> 41:10.820]  Rowling both were too.
[41:11.380 --> 41:14.420]  Again, I don't want to, again, there's a whole discussion we could have, but
[41:14.420 --> 41:15.460]  broad examples, but sure.
[41:15.460 --> 41:16.020]  Let's keep it.
[41:16.020 --> 41:20.740]  But well, Stephen King, let's just say that Stephen King was not a fan of it
[41:20.740 --> 41:27.460]  because they saw the, I think I said, I think I said this on dithering.
[41:27.460 --> 41:30.820]  So because that's a paid podcast, I'm not.
[41:30.820 --> 41:31.380]  Yeah, I did.
[41:31.380 --> 41:33.140]  Or maybe it was on, well, whatever.
[41:33.140 --> 41:34.980]  I said it recently, but I'll say it again.
[41:34.980 --> 41:41.540]  To me, it fitting a complex thought into 140 characters to me, satisfied the
[41:41.540 --> 41:44.980]  same part of my brain that solving wordle every day does.
[41:44.980 --> 41:45.220]  Right.
[41:45.220 --> 41:46.020]  And it's a puzzle.
[41:46.740 --> 41:48.020]  And it's like, ah, crap.
[41:49.060 --> 41:53.460]  This thing I want to tweet this funny joke or I got to get in this box.
[41:53.460 --> 41:53.780]  Yeah.
[41:53.780 --> 41:58.180]  But Christ, I mean, they would tell you like a game.
[41:58.180 --> 42:00.980]  They would tell you how far away you were like, that's not even close.
[42:00.980 --> 42:02.420]  You're at a 211 characters.
[42:02.420 --> 42:05.460]  And it's like, it's puzzle solving in community with people, right?
[42:05.460 --> 42:07.220]  Now I had this where I had a link blog.
[42:07.220 --> 42:10.020]  Actually, I had one before you, as a matter of fact, I had a link blog and
[42:10.020 --> 42:11.700]  I love because my design was crappy.
[42:11.700 --> 42:13.460]  I had a very finite amount of space.
[42:13.460 --> 42:15.780]  It might've been 140 characters virtually.
[42:15.780 --> 42:18.100]  And I loved writing headlines there every day.
[42:18.100 --> 42:21.220]  Cause it had to fit into this little sidebar on the crappy blog layout that
[42:21.220 --> 42:22.020]  I had.
[42:22.020 --> 42:25.780]  And I did that for like four years and it was such a joy cause it was exactly
[42:25.780 --> 42:29.300]  that thing, which is like, I have this much space to get.
[42:29.300 --> 42:33.300]  And for me, it was like to get this story across and also have it like be
[42:33.300 --> 42:33.700]  funny.
[42:33.700 --> 42:37.700]  And it's probably like the best training grounds I could have had for Twitter.
[42:37.700 --> 42:38.900]  Yeah, that was possible.
[42:38.900 --> 42:40.580]  So I, you know, I've learned my lesson.
[42:40.580 --> 42:42.020]  Two 80 did not break Twitter.
[42:42.020 --> 42:45.780]  It still is a game because it turns out many thoughts are 300 or more
[42:45.780 --> 42:47.780]  characters and still feels like a game.
[42:47.780 --> 42:51.540]  But I think having a limit period when I know that there are numerous people
[42:51.540 --> 42:54.500]  who just think that you should be able to post this, why have any limit at
[42:54.500 --> 42:54.740]  all?
[42:54.740 --> 42:56.660]  Computers can handle lots of texts.
[42:56.660 --> 43:01.140]  And I think that would be disastrous because I know, again, no offense to
[43:01.140 --> 43:03.060]  anybody who's ever sent me a long email.
[43:03.060 --> 43:06.900]  I love the email I get from readers, but people have, sometimes people have a
[43:06.900 --> 43:14.820]  hard time editing and putting what could be a 280 character observation into
[43:14.820 --> 43:17.860]  less than 200, 2,800 words.
[43:17.860 --> 43:18.740]  So I love Twitter.
[43:18.740 --> 43:19.860]  I still like using it.
[43:19.860 --> 43:24.740]  It is the, it is and remains the only communal forum for daring fireball
[43:24.740 --> 43:26.740]  readers that has ever existed.
[43:26.740 --> 43:31.140]  I mean, if it does go away or becomes unusable, I mean, I'll find something
[43:31.140 --> 43:31.460]  else.
[43:31.460 --> 43:33.540]  But I want Twitter to thrive.
[43:33.540 --> 43:38.820]  I think it's worth saving, but I feel like they've never had great leadership.
[43:38.820 --> 43:41.700]  I feel like, or it's always been a kind of a clown car.
[43:42.580 --> 43:49.140]  When people like Ev Williams were nominally in charge, they were under, it's
[43:49.140 --> 43:53.060]  not that I think Ev didn't get it or want to see it go in a good way, but
[43:53.060 --> 43:56.820]  they were under pressure from like financial sources.
[43:56.820 --> 43:59.380]  And well, and also, I mean, one of the things I think about, like, you know, I
[43:59.380 --> 44:02.980]  was, I still talk to Ev a lot, Jason Colvin, who was early there, like all
[44:02.980 --> 44:05.620]  those early Twitter folks, except for Jack, I still have some degree
[44:05.620 --> 44:06.580]  relationship with.
[44:06.580 --> 44:10.580]  And I think one of the things is like, they were in over their heads from day
[44:10.580 --> 44:10.900]  one.
[44:10.900 --> 44:13.380]  Like it was again, it would be irrational.
[44:13.380 --> 44:14.180]  They were the opposite.
[44:14.180 --> 44:18.100]  They weren't like, we are going to make a text box that you type in and it will
[44:18.100 --> 44:22.980]  control the political and media conversation of the world in five years.
[44:22.980 --> 44:23.300]  Right.
[44:23.300 --> 44:25.380]  Like that's not, they weren't Babe Ruth pointing at that fence.
[44:25.380 --> 44:25.620]  Right.
[44:25.620 --> 44:25.860]  Right.
[44:25.860 --> 44:29.700]  It is like a thing that happened to them and then they're sort of holding on.
[44:29.700 --> 44:29.860]  Right.
[44:29.860 --> 44:32.980]  They are like, they're a dog that caught a car they didn't know they were chasing.
[44:33.700 --> 44:34.100]  Right.
[44:34.100 --> 44:38.340]  And so I got, I have so much more empathy for that, which is like, oops, it, a
[44:38.340 --> 44:40.100]  multi-billion dollar company happened to us.
[44:40.100 --> 44:43.300]  Like I have way more empathy for that than the person that's like, I set out to
[44:43.300 --> 44:43.620]  do this.
[44:43.620 --> 44:47.060]  I think part of why I'm always skeptical about the approaches people have to
[44:47.060 --> 44:50.820]  either competing with it or fixing it is like, it's a real hard thing to do on
[44:50.820 --> 44:51.300]  purpose.
[44:51.300 --> 44:53.460]  If nobody's ever done it on purpose.
[44:53.460 --> 44:53.780]  Right.
[44:53.780 --> 44:56.100]  And so, so I think that's really important, but I think the other thing
[44:56.100 --> 45:00.580]  that, that underpins a lot of this too, is the, you know, you and I are of a
[45:00.580 --> 45:05.140]  cohort of folks that came into technology sort of pre-internet right.
[45:05.140 --> 45:09.540]  And then the rise of the internet, I think justified why we liked computers
[45:09.540 --> 45:10.900]  right back when they used to be called.
[45:10.900 --> 45:14.820]  And then what came of that, and this is keep in mind, like we are the cohort
[45:14.820 --> 45:19.460]  too, that is mostly in political power, mostly in professional power.
[45:19.460 --> 45:23.460]  Like most organizations are run by people who came up from that same kind of
[45:23.460 --> 45:26.660]  Gen X cohort that we did or late Gen X cohort that we did.
[45:27.220 --> 45:32.580]  And there's this baked in kind of Clinton era techno-solutionism, which is
[45:32.580 --> 45:34.740]  like, we'll throw the software at it and that'll fix it.
[45:34.740 --> 45:37.220]  And that's happened in politics has happened on these areas.
[45:37.220 --> 45:41.140]  And I think it's really closely related to that idea of the genius creator,
[45:41.140 --> 45:41.460]  right?
[45:41.460 --> 45:45.300]  You know, like if you can get something to compile in X code, then you can
[45:45.300 --> 45:46.660]  solve any problem, right?
[45:46.660 --> 45:49.700]  Even if it's a domain you've never heard of or aren't good at.
[45:49.700 --> 45:56.660]  And that's a intoxicating thing that suits, like I have been poisoned by this.
[45:56.660 --> 46:01.860]  It suits my ego to believe that is true, even though demonstrably, it is false,
[46:01.860 --> 46:03.540]  sometimes catastrophically false.
[46:03.540 --> 46:07.700]  And so that's the thing that I'm very, and why I asked you that question about
[46:07.700 --> 46:08.420]  like, why do we say this?
[46:08.420 --> 46:13.700]  Cause like I have been, I was seduced by that same siren many times when I built
[46:13.700 --> 46:16.500]  social media tools that I think you still use.
[46:16.500 --> 46:19.460]  I was like, Oh, and then this will democratize publishing.
[46:19.460 --> 46:20.820]  And like, it was true.
[46:20.820 --> 46:26.500]  And we did get voices like yours and complete denial about the downside risk
[46:26.500 --> 46:30.420]  of like, also it might amplify conspiracy theorists or hate groups or whatever
[46:30.420 --> 46:32.260]  else that came along with it.
[46:32.260 --> 46:35.700]  And we took, I literally had a job that was to say, we're going to enable people
[46:35.700 --> 46:37.620]  to do things like daring fireball.
[46:37.620 --> 46:39.780]  We're going to enable great voices like John Gruber.
[46:39.780 --> 46:42.420]  And I was happy and proud to do it.
[46:42.420 --> 46:44.980]  And then when people use it to make hateful things, I was like, Oh, that's
[46:44.980 --> 46:45.540]  not our fault.
[46:45.540 --> 46:46.500]  That's just human nature.
[46:46.500 --> 46:51.460]  Well, and think back to go before publishing on the internet to earlier
[46:51.460 --> 46:56.420]  computer technologies, like the laser printer, where all of a sudden anybody
[46:56.420 --> 47:02.020]  could print out eight and a half by 11 output that looked professional.
[47:02.020 --> 47:04.260]  It didn't look like it came out of a typewriter.
[47:04.260 --> 47:05.860]  It didn't look, it wasn't dot name.
[47:05.860 --> 47:08.740]  It was indistinguishable from the most expensive thing you could do.
[47:08.740 --> 47:08.980]  Right.
[47:08.980 --> 47:14.020]  And that there were companies, big companies who had infrastructure that
[47:14.020 --> 47:17.940]  was all based around the typewriter or dot matrix printers for their stuff.
[47:17.940 --> 47:22.980]  So that you're you, the person, the Joe or Jane computer user who just had
[47:22.980 --> 47:27.620]  access to a laser printer could get better looking output than bigger name
[47:27.620 --> 47:28.180]  people did.
[47:28.180 --> 47:28.740]  Right.
[47:28.740 --> 47:32.260]  And of course, anybody you could print anything on your laser printer, right?
[47:32.260 --> 47:36.340]  So the person whose politics you agree with who had could just as easily make
[47:36.340 --> 47:41.540]  a very lovely looking flyer as somebody whose politics you completely disagree
[47:41.540 --> 47:41.780]  with.
[47:41.780 --> 47:44.500]  And nobody thought, well, that's the printer's fault.
[47:44.500 --> 47:49.220]  And I think that was the same mentality that we all had in the early years of
[47:49.220 --> 47:53.300]  publishing and publishing, creating publishing tools on the internet.
[47:53.300 --> 47:57.300]  I think there was also a naivete about the legitimizing effect that everybody
[47:57.300 --> 48:01.060]  having the same tools would do if you couldn't tell the difference, right?
[48:01.060 --> 48:04.900]  It's the same fonts and the same paper way of the paper and all that kind of
[48:04.900 --> 48:09.540]  stuff between the whack job and the expert.
[48:09.540 --> 48:12.500]  The fact that we were relying so much on the social signals is, I mean, again,
[48:12.500 --> 48:14.420]  you know this better than anybody having been a designer.
[48:14.420 --> 48:18.740]  Like, we take our credibility cues from the packaging.
[48:18.740 --> 48:22.740]  People, even people who claim that they don't care about design don't even
[48:22.740 --> 48:25.540]  realize how subliminally they are affected by it.
[48:25.540 --> 48:26.900]  They can't resist the cues of it.
[48:26.900 --> 48:28.580]  We've been trained and again, for good reason.
[48:28.580 --> 48:31.380]  Historically, there were lots of like, there was a lot of time where like,
[48:31.380 --> 48:32.340]  okay, this is well produced.
[48:32.340 --> 48:32.980]  It's in the magazine.
[48:32.980 --> 48:35.780]  That means that there was a gatekeeper, which is bad, but it also means there
[48:35.780 --> 48:37.300]  was an editor, which is probably good.
[48:37.300 --> 48:40.980]  And so that thing of that real balance, we weren't taught, right?
[48:40.980 --> 48:44.900]  That level of fluency, the meta level of fluency and the communications
[48:44.900 --> 48:46.100]  and media we weren't taught.
[48:46.740 --> 48:49.380]  And so, because nobody had encountered it before, like the last time that
[48:49.380 --> 48:51.140]  came around was the printing press.
[48:51.780 --> 48:54.820]  And so to come back around to this, we're like, oh, I didn't realize this
[48:54.820 --> 48:55.700]  was the stakes.
[48:56.260 --> 48:59.140]  And I think that there's a sort of a denial still.
[48:59.140 --> 49:02.980]  And I know like, again, I went through this or like I was the arms dealer
[49:02.980 --> 49:08.100]  giving people these weapons and in denial about the implications of it
[49:08.100 --> 49:10.420]  until it was being misused.
[49:10.420 --> 49:12.020]  And I think that still permeate.
[49:12.020 --> 49:16.980]  And also like we were of the cohort that got to see these impacts first,
[49:16.980 --> 49:17.220]  right?
[49:17.220 --> 49:19.220]  We were early and got to see it go through.
[49:19.220 --> 49:21.860]  So everybody is a couple of years behind, depending on when they got to
[49:21.860 --> 49:25.300]  social media, maybe several years behind in realizing these same things.
[49:25.300 --> 49:30.100]  And so that lag is an opportunity for the Musks of the world to sort of
[49:30.100 --> 49:32.660]  say, Hey, look, software is software.
[49:32.660 --> 49:36.180]  If I can make the dashboard on your Tesla, which he doesn't do, but, you
[49:36.180 --> 49:39.940]  know, he takes credit for, then I can certainly make a couple of tweets
[49:39.940 --> 49:41.540]  appear in a way that you like.
[49:41.540 --> 49:44.100]  And you're like, these are completely different problem spaces.
[49:44.100 --> 49:47.300]  The fact that they both involve writing some code does not mean they're
[49:47.300 --> 49:48.500]  the same kind of problem at all.
[49:50.580 --> 49:51.140]  Very much.
[49:51.140 --> 49:55.540]  Well, who was the CEO before to kill? Emilio was the CEO before Steve
[49:55.540 --> 49:55.940]  Jobs.
[49:55.940 --> 49:58.660]  And again, I see a similarity here where I see Twitter as being worth
[49:58.660 --> 49:59.220]  saving.
[49:59.220 --> 50:04.740]  I do not think that before this entire Musk saga started that they were
[50:04.740 --> 50:06.500]  on a path anywhere.
[50:06.500 --> 50:06.740]  Good.
[50:08.180 --> 50:13.380]  And I thought it was so disappointing when Jack Dorsey stepped down as
[50:13.380 --> 50:17.700]  CEO to, you know, well, and sold out his workers.
[50:17.700 --> 50:21.140]  I mean, the wild thing is that Jack was playing both sides of the deal.
[50:21.140 --> 50:24.020]  This was actually one of those things where, like, again, I don't get
[50:24.020 --> 50:24.740]  surprised easy.
[50:24.740 --> 50:27.140]  This industry is, I have no misgivings about what it is.
[50:27.140 --> 50:31.620]  It's a multi-trillion dollar industry, but I did not think he would be
[50:31.620 --> 50:35.220]  saying one thing in public and to his workers and be doing a backdoor
[50:35.220 --> 50:39.780]  deal to, to sell to Musk at the same time, just straight up.
[50:39.780 --> 50:41.860]  I mean, it's a lie and it's a rare thing.
[50:41.860 --> 50:45.780]  Like again, like you can be critical of CEOs for many valid reasons, but
[50:45.780 --> 50:50.580]  actually they very rarely will bald face tell a lie to the world about
[50:50.580 --> 50:51.300]  that kind of thing.
[50:51.300 --> 50:53.940]  They will about, are we going to do a video iPod or not?
[50:53.940 --> 50:55.300]  But not about like that kind of thing.
[50:55.300 --> 50:57.540]  That was really stark and striking.
[50:57.540 --> 51:01.540]  And one of the sort of like the first in the series of jaw dropping dominoes
[51:01.540 --> 51:03.460]  that started to fall around all this.
[51:03.460 --> 51:08.340]  And I just, I don't know Prague Agrawal, who was the CEO for what, a year,
[51:08.340 --> 51:09.860]  I guess, or almost a year.
[51:09.860 --> 51:11.220]  Although he'd been CTO for a while.
[51:11.220 --> 51:11.620]  I know.
[51:11.620 --> 51:17.220]  Well, but naming him CEO to me without knowing him or knowing that it
[51:17.220 --> 51:20.740]  just seemed very clear to me that he was not the person he wasn't going
[51:20.740 --> 51:23.300]  to do what I think needed to be done to fix Twitter.
[51:23.300 --> 51:25.700]  And again, it's not my specific ideas.
[51:25.700 --> 51:30.100]  Like, Oh, you should name me, John Gruber, the CEO, or, or pay me to be
[51:30.100 --> 51:33.220]  a consultant for a couple of weeks so I can put it all on a whiteboard.
[51:33.220 --> 51:34.580]  It's not that I had a plan.
[51:34.580 --> 51:37.140]  It's just that I would know it when I saw it.
[51:37.140 --> 51:42.660]  And steady as she goes, we'll just keep going the way we were, which
[51:42.660 --> 51:47.220]  was more or less Twitter for the last few years, wasn't going to do it.
[51:47.220 --> 51:50.660]  And so, I mean, I've had some conversations with paragraph over the
[51:50.660 --> 51:54.260]  years, and I have a little bit of a window into some of the technical
[51:54.260 --> 51:57.300]  choices because actually to this, as far as I know, I'm sure after this
[51:57.300 --> 51:58.420]  comes out, muscle deleted.
[51:58.420 --> 52:01.540]  But if you go to the Twitter developer site, they say, get started trying
[52:01.540 --> 52:01.620]  it.
[52:01.620 --> 52:03.460]  It's a glitch app and I run glitch.
[52:03.460 --> 52:04.180]  So we see that.
[52:04.180 --> 52:08.420]  And the, so we had a chance to talk about the platform and like, no,
[52:08.420 --> 52:09.220]  he's a technologist.
[52:10.020 --> 52:12.500]  One of the things that's important to understand with Jack having
[52:12.500 --> 52:15.700]  picked Parag as a successor is it's very rare.
[52:15.700 --> 52:19.060]  You almost never see a publicly traded company, multi-billion dollar
[52:19.060 --> 52:22.420]  company where somebody goes from CTO to CEO.
[52:22.420 --> 52:22.660]  Right.
[52:23.540 --> 52:27.620]  Technology is not the path by which you become executive of a technology
[52:27.620 --> 52:28.340]  company.
[52:28.340 --> 52:31.220]  That's a really, there's a million things that can impact from that
[52:31.220 --> 52:33.060]  statement, but that is just a factual statement.
[52:33.060 --> 52:35.860]  And get that happened there.
[52:35.860 --> 52:39.460]  And also Parag had started Blue Sky, which is their sort of attempted
[52:39.460 --> 52:42.100]  making a protocol that Twitter could run on to sort of decentralize
[52:42.100 --> 52:42.340]  things.
[52:42.340 --> 52:45.300]  And we can talk about Mastodon and Fediverse and all that stuff too,
[52:45.300 --> 52:48.740]  but the conceptually not the wrong idea, really interesting idea.
[52:48.740 --> 52:50.980]  And he was much more committed to it than Jack was.
[52:50.980 --> 52:52.420]  I mean, Jack was sort of like, yeah, we'll fund it.
[52:52.420 --> 52:54.900]  We'll do about Parag was a person that like understood how it worked.
[52:54.900 --> 52:55.540]  It was interesting.
[52:55.540 --> 53:00.340]  So like, I don't think conceptually he was impossible to have sort of
[53:00.340 --> 53:02.660]  tackled the problems, but I do think he was taking an incremental
[53:02.660 --> 53:03.460]  approach.
[53:03.460 --> 53:05.780]  And this is one of the things that I think I pull away from, like the
[53:05.780 --> 53:08.020]  valid part of what you're saying is like an incremental approach
[53:08.020 --> 53:09.540]  wasn't going to fix what was broken with Twitter.
[53:09.540 --> 53:12.180]  They needed a more vigorous shaking.
[53:12.180 --> 53:14.820]  Yeah, that's exactly what we're trying to make.
[53:14.820 --> 53:18.020]  Would you consider Satya Nadella an exception to that as well,
[53:18.020 --> 53:21.460]  though, as a technologist who became the leader of Microsoft?
[53:21.460 --> 53:21.700]  Yeah.
[53:21.700 --> 53:25.620]  I mean, I have a lot of complicated feelings about the pattern in our
[53:25.620 --> 53:30.820]  industry of Indian immigrant CEOs becoming CEOs at these companies
[53:30.820 --> 53:32.420]  when they're in duress, right?
[53:32.420 --> 53:35.700]  It's a really, there's a phrase that people use around, especially
[53:35.700 --> 53:37.460]  women becoming CEOs of glass cliff.
[53:37.460 --> 53:39.540]  It's related to the glass ceiling, right?
[53:39.540 --> 53:42.340]  If as soon as things get bad enough, we'll bring you in and it helps
[53:42.340 --> 53:45.380]  at the we'll let you drive the company over the cliff that it's
[53:45.380 --> 53:47.300]  obviously inevitably heading towards.
[53:47.300 --> 53:47.700]  Exactly.
[53:47.700 --> 53:48.580]  And then you'll take the fall.
[53:48.580 --> 53:51.940]  But I mean, I think it's one, I actually do think the pattern is real,
[53:51.940 --> 53:55.060]  but I also think of like a Google things were not in a dire place
[53:55.060 --> 53:55.700]  at Microsoft.
[53:55.700 --> 53:57.860]  You could argue things have been stagnant for a long time, which for
[53:57.860 --> 53:59.380]  their culture is a dire place.
[53:59.380 --> 54:01.780]  And then obviously Twitter was in serious duress.
[54:01.780 --> 54:05.140]  There's a, there is a rare path as a technologist.
[54:05.140 --> 54:08.980]  Microsoft is a, is an outlier place because they value technology
[54:08.980 --> 54:10.740]  to such a profound degree.
[54:10.740 --> 54:13.860]  And also they started as a developer tools company and have essentially
[54:13.860 --> 54:17.300]  come back to becoming a developer tools company, you know, especially
[54:17.300 --> 54:19.380]  with the acquisition of GitHub and all the other things they've done.
[54:19.380 --> 54:22.100]  So it's a really interesting thing where I think in a lot of ways,
[54:22.820 --> 54:27.220]  that was a return to the starting point after having had a lot of
[54:27.220 --> 54:28.580]  digressions over the years.
[54:28.580 --> 54:31.140]  That, that is a really interesting thing because they were, I mean,
[54:31.140 --> 54:34.340]  this is a tangent, but I think a relevant one, you know, Microsoft
[54:34.340 --> 54:37.860]  made developer tools for all major platforms.
[54:37.860 --> 54:40.660]  That was what they did to start with before Windows, before DOS,
[54:40.660 --> 54:41.540]  before anything.
[54:41.540 --> 54:44.260]  And, and then would make sure that the apps that you created on
[54:44.260 --> 54:46.420]  those could be pretty easily portable to any place that their
[54:46.420 --> 54:47.300]  platforms were running.
[54:47.940 --> 54:51.700]  And to an approximation, that is what they do now, where like their
[54:51.700 --> 54:55.460]  apps run on every platform and they own the entire developer stack
[54:55.460 --> 54:58.820]  top to bottom with coders, write their code in and where they host
[54:58.820 --> 55:01.060]  their code and what they hope is where they run their code.
[55:01.060 --> 55:04.180]  That's a really, that thing that I think is that explains the
[55:04.180 --> 55:06.100]  exception of why technologies can come up.
[55:06.100 --> 55:09.060]  But I think there's also this broader pattern of, was the problem
[55:09.060 --> 55:12.020]  with Twitter about technology and it's not, it's about culture,
[55:12.020 --> 55:12.180]  right?
[55:12.180 --> 55:14.180]  It was really about like, what does it want to be culturally?
[55:14.180 --> 55:16.820]  There was obviously a huge cultural battle about what it is.
[55:16.820 --> 55:20.500]  It had become a signifier, I think largely because of Donald Trump,
[55:20.500 --> 55:23.460]  of the larger cultural battles that are happening in America and
[55:23.460 --> 55:24.100]  around the world.
[55:24.100 --> 55:29.940]  And those are problems that are uniquely ill-suited to trying to
[55:29.940 --> 55:32.740]  solve through technical formats, right?
[55:32.740 --> 55:36.180]  Like it is not an API problem that people are having political
[55:36.180 --> 55:37.060]  battles on your platform.
[55:37.060 --> 55:40.420]  But basically that was my thinking was that this Prague was
[55:40.420 --> 55:43.460]  obviously not the person to give Twitter the shakeup, whether
[55:43.460 --> 55:46.580]  it's because maybe he had the ideas to do it, but he obviously
[55:46.580 --> 55:49.300]  didn't have the political clout to do it, right?
[55:49.300 --> 55:52.900]  Well, also there is an inherent conservatism to being a CEO of
[55:52.900 --> 55:55.700]  a publicly traded company, especially under an FTC consent
[55:55.700 --> 55:59.540]  decree, which leads to taking an incremental approach.
[55:59.540 --> 56:02.100]  He might have had, I don't know, this is not a conversation
[56:02.100 --> 56:04.900]  I've ever had with him or anybody else that was at that level,
[56:04.900 --> 56:06.500]  but he may have had a radical vision.
[56:07.380 --> 56:12.500]  And even if he did, and he had board buy-in to pursue it, the
[56:13.300 --> 56:17.700]  grown up right way to do it would be build a plan, iterate
[56:17.700 --> 56:20.740]  over time, make sure things are secure, reassure your
[56:20.740 --> 56:23.540]  advertisers, build a plan about what your staffing is going
[56:23.540 --> 56:25.780]  to look like, those are the things you do.
[56:26.340 --> 56:29.780]  And so there's no way to know now because of how things have
[56:29.780 --> 56:32.420]  played out, but it is not at all impossible that he had a
[56:32.420 --> 56:34.740]  good plan and was executing it and we couldn't see it.
[56:35.460 --> 56:38.020]  And that making your decisions based on what people are
[56:38.020 --> 56:40.340]  tweeting at you is actually a bad way to make decisions.
[56:40.340 --> 56:42.420]  And so I think that's because like you look at, again, going
[56:42.420 --> 56:44.740]  back to the jobs example, you know, when he goes to the sort
[56:44.740 --> 56:49.300]  of first, after the return from the next exile, he goes to
[56:49.300 --> 56:52.100]  Macworld and he's talking to people and it's not an obvious
[56:52.100 --> 56:53.860]  immediate turn, right?
[56:53.860 --> 56:56.980]  Like it is a short time to effectively when the iMac comes
[56:56.980 --> 56:57.460]  out, right?
[56:57.460 --> 57:01.300]  But on the way there, he didn't say anything that said, we're
[57:01.300 --> 57:02.420]  doing this radical change.
[57:02.420 --> 57:03.780]  He said, we have to get it together.
[57:03.780 --> 57:06.820]  There was no hint that a Microsoft partnership was coming.
[57:06.820 --> 57:09.220]  There was no hint, like the things that were seen as these
[57:09.220 --> 57:12.260]  radical, bold moves were not communicated until they were
[57:12.260 --> 57:12.900]  communicated.
[57:12.900 --> 57:14.980]  And so I think that's the thing that like a turnaround for
[57:14.980 --> 57:19.300]  an organization is a very hard thing for any leader to do.
[57:19.300 --> 57:22.340]  And you actually, there's the right way to do it is to not
[57:22.340 --> 57:24.420]  be disruptive until you know what you're doing.
[57:25.540 --> 57:28.180]  I remember, I don't know how to explain it.
[57:28.180 --> 57:30.900]  I just, again, it's an, I know it when I see it.
[57:30.900 --> 57:35.620]  And when Gil Amelio was named Apple CEO after a run of bad,
[57:36.980 --> 57:40.740]  even worse CEOs, Michael Spindler famously.
[57:40.740 --> 57:42.260]  Right, right, right, right, right.
[57:42.260 --> 57:46.020]  At one point it was reported in a book that he, it was, they
[57:46.020 --> 57:48.500]  had like an upcoming quarterly report and they thought he was
[57:48.500 --> 57:50.180]  in his office and he wasn't.
[57:50.180 --> 57:50.980]  And where is he?
[57:50.980 --> 57:53.060]  And it turns out he was in his office and he was under his
[57:53.060 --> 57:54.020]  desk crying.
[57:54.020 --> 57:59.140]  I mean, bad, bad, relatable, and really did not, if you
[57:59.140 --> 58:02.100]  listen to it, it wasn't there long, but he did a lot of damage
[58:02.100 --> 58:02.740]  to the company.
[58:02.740 --> 58:06.180]  But when Gil Amelio was named, he said some things that were
[58:06.180 --> 58:09.700]  right, you know, like he obviously didn't like totally not
[58:09.700 --> 58:11.380]  get the Mac or Apple.
[58:11.380 --> 58:14.580]  And I think the one thing I remember him saying was that he
[58:14.580 --> 58:18.420]  saw Apple as the mag light of computers and that sure, most
[58:18.420 --> 58:21.540]  people aren't going to buy, aren't going to, if they're going
[58:21.540 --> 58:24.340]  to go buy a flashlight, they're not going to spend the money
[58:24.340 --> 58:28.100]  on a mag light, but the people who really want a good one are
[58:28.100 --> 58:28.660]  going to.
[58:28.660 --> 58:31.140]  And that's Apple's role in the computer business.
[58:31.140 --> 58:33.060]  And in broad strokes, that's right.
[58:33.060 --> 58:35.300]  It's not factually incorrect, but it's a horrible story to
[58:35.300 --> 58:35.540]  tell.
[58:35.540 --> 58:38.500]  And it's also, that alone does not make you the right person
[58:38.500 --> 58:40.340]  to be CEO of Apple.
[58:40.340 --> 58:40.820]  That's right.
[58:40.820 --> 58:41.300]  That's right.
[58:41.300 --> 58:44.580]  And actually there's a meta point here too, which is Apple
[58:44.580 --> 58:47.940]  is the epitome of a company for whom the story has to come
[58:47.940 --> 58:50.900]  first, because it is what sustained them in the low points
[58:50.900 --> 58:52.980]  and is what made the high points possible.
[58:52.980 --> 58:56.340]  And so when you're bad at telling the story, you are a failure
[58:56.340 --> 59:00.180]  in the role, even if your business strategy is right.
[59:00.180 --> 59:02.420]  And this is true of Twitter as well.
[59:02.420 --> 59:04.820]  The reason Twitter is a household brand, despite not being
[59:04.820 --> 59:07.860]  that big, certainly compared to Facebook, but even compared
[59:07.860 --> 59:12.980]  to Pinterest, and they handed TikTok to the world by killing
[59:12.980 --> 59:14.660]  Vine, right?
[59:14.660 --> 59:16.820]  Their failures are billion dollar companies.
[59:17.460 --> 59:20.980]  And so this is the thing is you have to be a master
[59:20.980 --> 59:22.180]  storyteller.
[59:22.180 --> 59:24.580]  Jack is good at personal storytelling, but not at the
[59:24.580 --> 59:25.780]  company storytelling.
[59:25.780 --> 59:27.620]  Ev still doesn't like to tell a story.
[59:28.340 --> 59:30.740]  For 20 years, he has not wanted to be a public figure.
[59:30.740 --> 59:32.180]  So that wasn't the guy.
[59:32.180 --> 59:34.740]  So that part about that's why the story has been filled in
[59:34.740 --> 59:37.780]  by press and media and politics and the rest of the world.
[59:37.780 --> 59:38.420]  It's there.
[59:38.420 --> 59:41.540]  And then you get somebody in who wants to be the story at
[59:41.540 --> 59:43.140]  the expense of the product and the team.
[59:43.700 --> 59:44.420]  And it's a failure.
[59:44.420 --> 59:47.540]  And I think that's that thing that like the people who built
[59:47.540 --> 59:50.500]  the myth around Musk, like he has fans, which is a weird
[59:50.500 --> 59:51.860]  thing for CEO.
[59:51.860 --> 59:54.500]  Because again, even like going back to the jobs example,
[59:54.500 --> 59:56.500]  obviously there are lots of people who are jobs fans and
[59:56.500 --> 59:57.620]  acolytes and stuff like that.
[59:57.620 --> 01:00:02.420]  But he didn't have a fan culture in that way when he was
[01:00:02.420 --> 01:00:05.620]  alive because he didn't cultivate it.
[01:00:05.620 --> 01:00:07.860]  Like he was fine if people liked his work and appreciated
[01:00:07.860 --> 01:00:10.580]  it, but he wasn't carrying himself like he wasn't doing TV
[01:00:10.580 --> 01:00:13.700]  appearances and having people falling over him and creating
[01:00:13.700 --> 01:00:16.420]  that kind of cult of personality famously did very little
[01:00:16.420 --> 01:00:17.300]  of it, really.
[01:00:17.300 --> 01:00:17.800]  Right.
[01:00:19.380 --> 01:00:20.980]  I often say this.
[01:00:20.980 --> 01:00:24.100]  Another often recurring theme here on the podcast is me
[01:00:24.100 --> 01:00:27.380]  saying, boy, I've been writing Daring Fireball for over 20
[01:00:27.380 --> 01:00:30.580]  years now, but boy, I wish I'd been writing it for 25 because
[01:00:33.380 --> 01:00:35.300]  there's a lot of stuff when the story starts.
[01:00:35.300 --> 01:00:35.800]  Right.
[01:00:37.140 --> 01:00:38.180]  And I'm honest about it.
[01:00:38.180 --> 01:00:42.180]  And I will be very honest that if I had been writing about
[01:00:42.180 --> 01:00:48.340]  Apple when they acquired Next, I was as keen an observer of
[01:00:48.340 --> 01:00:50.660]  the company as I am now as I write Daring Fireball.
[01:00:50.660 --> 01:00:54.260]  I was still that obsessed with the company and was perhaps
[01:00:54.260 --> 01:00:57.460]  even if possibly even more so because I was so worried that
[01:00:57.460 --> 01:00:59.700]  they were going to go under and I didn't know what I would
[01:00:59.700 --> 01:01:02.020]  do with myself, what computers would I use.
[01:01:02.020 --> 01:01:08.740]  When they bought Next, my thought was, I don't know if this
[01:01:08.740 --> 01:01:09.780]  is the right decision.
[01:01:09.780 --> 01:01:13.700]  I was sort of more honestly hoping they would buy B.
[01:01:13.700 --> 01:01:15.540]  You know, the famous thing was that they could have bought
[01:01:15.540 --> 01:01:16.040]  B.
[01:01:16.420 --> 01:01:19.300]  B had the technical correctness again, right?
[01:01:19.300 --> 01:01:21.860]  And I thought was actually more technically correct than
[01:01:21.860 --> 01:01:23.220]  the next operating system.
[01:01:23.220 --> 01:01:23.780]  Totally.
[01:01:23.780 --> 01:01:24.340]  Totally.
[01:01:24.340 --> 01:01:24.820]  Right.
[01:01:24.820 --> 01:01:26.660]  And it was appealing at the superficial level.
[01:01:26.660 --> 01:01:30.020]  But again, Gasset was not this storyteller that jobs.
[01:01:30.020 --> 01:01:30.260]  Right.
[01:01:30.260 --> 01:01:33.780]  And I didn't own a B box, which is still it's a great name.
[01:01:33.780 --> 01:01:34.660]  What a great name.
[01:01:34.660 --> 01:01:38.660]  But I had used one and I knew that they ran on the PowerPC
[01:01:38.660 --> 01:01:39.140]  platform.
[01:01:39.140 --> 01:01:43.300]  And famously, they had this demo, which in 1995 or six or
[01:01:43.300 --> 01:01:49.460]  whenever they did the demo had four windows on a 15 inch or
[01:01:49.460 --> 01:01:52.900]  17 inch display running four different videos at the same
[01:01:52.900 --> 01:01:53.140]  time.
[01:01:53.140 --> 01:01:54.420]  It was incredible.
[01:01:54.420 --> 01:01:54.980]  It was incredible.
[01:01:54.980 --> 01:01:56.180]  One of the great demos of all time.
[01:01:56.180 --> 01:01:57.380]  It was jaw dropping.
[01:01:57.380 --> 01:02:00.260]  So I was of the opinion that they should have bought B and
[01:02:00.260 --> 01:02:00.980]  not next.
[01:02:00.980 --> 01:02:04.580]  I thought next was old news already and it sort of lost
[01:02:04.580 --> 01:02:09.620]  their workstation war to sun and that a workstation OS wasn't
[01:02:09.620 --> 01:02:11.220]  really the right thing for consumers.
[01:02:11.220 --> 01:02:12.580]  I was familiar with B.
[01:02:12.580 --> 01:02:15.860]  I knew B had better color support.
[01:02:15.860 --> 01:02:18.820]  Eh, I would have been, you know, I will admit I was on the
[01:02:18.820 --> 01:02:20.660]  record of thinking they should have gone that way.
[01:02:20.660 --> 01:02:25.140]  But when they went the next route instead, I at least
[01:02:25.140 --> 01:02:28.660]  thought, even though I thought I wish they had bought B
[01:02:28.660 --> 01:02:31.380]  instead, I thought at least this gives them a chance.
[01:02:32.660 --> 01:02:34.900]  And also, it wasn't hard to believe that Steve Jobs could
[01:02:34.900 --> 01:02:36.740]  understand Apple, right?
[01:02:36.740 --> 01:02:40.500]  No, like that was not the part where we're like, I don't
[01:02:40.500 --> 01:02:42.980]  know if he knows the culture like that is not the challenge.
[01:02:42.980 --> 01:02:45.940]  And, you know, famously in hindsight, he was not instantly
[01:02:45.940 --> 01:02:46.740]  named CEO.
[01:02:46.740 --> 01:02:51.220]  He was an advisor and then used political cloud and got
[01:02:51.220 --> 01:02:55.300]  Emilio was ousted and then he took the CEO title.
[01:02:55.300 --> 01:02:57.380]  Which is very Twitter-esque, actually, now that you think
[01:02:57.380 --> 01:02:57.860]  about it.
[01:02:57.860 --> 01:03:01.540]  Like that's that Dick Costolo tweet about like the first
[01:03:01.540 --> 01:03:04.180]  day of COO, step one, undermine the CEO.
[01:03:04.180 --> 01:03:05.540]  Yeah, the first day.
[01:03:06.980 --> 01:03:10.500]  He was the interim, you know, the joke was he was the
[01:03:10.500 --> 01:03:12.980]  I CEO, you know, interim CEO.
[01:03:12.980 --> 01:03:17.140]  I'll be the temporary CEO just while we find a permanent CEO.
[01:03:17.140 --> 01:03:18.580]  He was working real hard to find a replacement.
[01:03:18.580 --> 01:03:21.300]  But, you know, he said and he admitted to his biographer,
[01:03:21.300 --> 01:03:24.180]  you know, that he did it because he was uncertain that even
[01:03:24.180 --> 01:03:24.980]  he could save Apple.
[01:03:24.980 --> 01:03:26.420]  And he just did that way.
[01:03:26.420 --> 01:03:29.140]  You don't want to get the stench of failure on you, right?
[01:03:29.140 --> 01:03:30.180]  Nobody likes a failure.
[01:03:30.180 --> 01:03:31.700]  Nobody likes a loser, right?
[01:03:31.700 --> 01:03:32.900]  Yes, exactly.
[01:03:32.900 --> 01:03:35.140]  And that's the thing is, I mean, I think an important part
[01:03:35.140 --> 01:03:41.140]  of this whole story is next also would have failed, right?
[01:03:42.180 --> 01:03:44.100]  They were definitely going to fail, right?
[01:03:44.100 --> 01:03:46.820]  Like they had no negotiating leverage except his storytelling
[01:03:46.820 --> 01:03:48.580]  ability, but it's not like next was going to win.
[01:03:48.580 --> 01:03:51.460]  And I think that's part of it is like, he did not want to
[01:03:51.460 --> 01:03:56.180]  have a failure because America hates losers and also because,
[01:03:56.180 --> 01:03:58.660]  you know, he was a child of immigrants and I'm sure we're
[01:03:58.660 --> 01:03:59.300]  all aware of that.
[01:03:59.300 --> 01:04:04.660]  But I think that's this part that is really interesting
[01:04:04.660 --> 01:04:05.060]  with Musk.
[01:04:05.060 --> 01:04:07.860]  It's like Musk is very clearly in his flop era.
[01:04:08.500 --> 01:04:10.420]  It is dead obvious, right?
[01:04:10.420 --> 01:04:12.420]  Like he jumped the shark going on SNL.
[01:04:12.420 --> 01:04:16.820]  You jump the shark having the like the musician girlfriend
[01:04:16.820 --> 01:04:18.100]  and then the breakup and the whole thing.
[01:04:18.100 --> 01:04:22.260]  Like he is in every cliched of the middle-aged guy.
[01:04:22.260 --> 01:04:25.220]  Like he already had the hair plugs, like the whole thing
[01:04:25.220 --> 01:04:26.980]  about being in his flop era.
[01:04:26.980 --> 01:04:31.620]  And then this is the like grasp at relevance to sort of be
[01:04:31.620 --> 01:04:32.420]  like, I can do this.
[01:04:32.420 --> 01:04:33.140]  I'm this genius.
[01:04:33.140 --> 01:04:36.260]  And also a lot of Silicon Valley guys are obsessed with
[01:04:36.260 --> 01:04:39.860]  having a third win because then you're in jobs territory.
[01:04:39.860 --> 01:04:42.740]  Right, right, right, right.
[01:04:42.740 --> 01:04:44.980]  Because then it proves that you weren't a fluke, right?
[01:04:46.980 --> 01:04:49.620]  But basically, that's my feeling is, you know, Steve Jobs
[01:04:49.620 --> 01:04:52.340]  and Next wouldn't have been my first choice in 1997.
[01:04:52.340 --> 01:04:55.220]  But I thought at least this gives them a chance, especially
[01:04:55.220 --> 01:04:56.580]  if Jobs stays around.
[01:04:56.580 --> 01:04:58.180]  And, you know, turns out that was right.
[01:04:58.820 --> 01:05:02.900]  But Jobs also was not in a cultural moment where tech CEOs
[01:05:02.900 --> 01:05:06.100]  were cultural figures and where people were obsessed with
[01:05:06.100 --> 01:05:09.220]  them. Like they were nerds and unpopular in 97.
[01:05:09.220 --> 01:05:11.700]  And that's really, really important because you had to want
[01:05:11.700 --> 01:05:12.500]  to do it.
[01:05:12.500 --> 01:05:16.020]  And he was a person who did date musicians because they
[01:05:16.020 --> 01:05:16.500]  liked it.
[01:05:16.500 --> 01:05:17.220]  It wasn't cool.
[01:05:17.860 --> 01:05:18.500]  Right.
[01:05:18.500 --> 01:05:21.940]  And so this is the thing again where the sort of the funhouse
[01:05:21.940 --> 01:05:26.020]  mirror version of this is like, you know, the difference
[01:05:26.020 --> 01:05:30.340]  between Grimes and any given folk singer that Jobs is attached
[01:05:30.340 --> 01:05:32.260]  to. Joni Mitchell, I believe.
[01:05:32.260 --> 01:05:33.780]  Or Joan Baez, maybe both.
[01:05:33.780 --> 01:05:34.820]  Joni Mitchell, not Joni Mitchell.
[01:05:34.820 --> 01:05:37.460]  But Joni Mitchell, different vibes.
[01:05:37.460 --> 01:05:40.340]  But Joan Baez, and that's the thing is like, Joan Baez was
[01:05:40.340 --> 01:05:43.940]  not going for somebody cool and not going for the richest
[01:05:43.940 --> 01:05:44.740]  guy in the world.
[01:05:44.740 --> 01:05:46.660]  Well, like, if they were, I don't know if they were ever
[01:05:46.660 --> 01:05:48.980]  photographed together while they were out, but if they had
[01:05:48.980 --> 01:05:51.940]  been, it would have been there's Joan Baez with, I don't
[01:05:51.940 --> 01:05:52.420]  know who.
[01:05:52.420 --> 01:05:53.780]  Some guy who works in technology.
[01:05:53.780 --> 01:05:54.900]  Some handsome young man.
[01:05:54.900 --> 01:05:55.300]  Yeah, right.
[01:05:55.300 --> 01:05:55.860]  Exactly.
[01:05:55.860 --> 01:05:57.940]  And so that's really, really important, right?
[01:05:57.940 --> 01:06:00.660]  Because the thing that people can't understand is like,
[01:06:00.660 --> 01:06:03.220]  these things are shaped the same, aren't they the same?
[01:06:03.220 --> 01:06:06.260]  And yet the cultural signifiers are the exact opposite, right?
[01:06:06.260 --> 01:06:10.340]  Like, he absolutely could talk fluently about music to Joan
[01:06:10.340 --> 01:06:13.620]  Baez in a way where they're credibly spending time together
[01:06:13.620 --> 01:06:15.860]  because they care about creativity and culture.
[01:06:16.660 --> 01:06:19.940]  And that is the opposite of by the time I became the richest
[01:06:19.940 --> 01:06:22.020]  person in the world, I could find a cool musician to date
[01:06:22.020 --> 01:06:26.020]  me. And that part, like, and it's the same reason you have
[01:06:26.020 --> 01:06:28.580]  the difference in this approach to, and I'm not somebody who
[01:06:28.580 --> 01:06:29.460]  idealizes jobs.
[01:06:29.460 --> 01:06:31.780]  Like, I have lots of criticisms of them, but I think that
[01:06:31.780 --> 01:06:35.300]  part about like, the story has to be true at some level if
[01:06:35.300 --> 01:06:36.900]  you're going to tell a good story.
[01:06:36.900 --> 01:06:40.980]  And the story of like, when Elon Musk was a little boy, he
[01:06:40.980 --> 01:06:43.220]  dreamed of building a communication network so people could
[01:06:43.220 --> 01:06:45.380]  share their ideas with each other is not true.
[01:06:47.860 --> 01:06:50.500]  Well, before we move on, I will just say that that's the
[01:06:50.500 --> 01:06:53.860]  last part of my I'm more optimistic than I have been in years
[01:06:53.860 --> 01:06:55.860]  was at least with Elon Musk.
[01:06:55.860 --> 01:06:57.860]  I thought he will shake up the company.
[01:06:57.860 --> 01:06:59.060]  It needs a shake up.
[01:06:59.060 --> 01:07:03.540]  And he himself obviously uses and loves Twitter.
[01:07:03.540 --> 01:07:05.700]  And I think that gives good at it.
[01:07:05.700 --> 01:07:07.220]  No, and we'll get to that.
[01:07:07.780 --> 01:07:09.300]  You know, that might be a good sign.
[01:07:09.300 --> 01:07:12.500]  But I do think that that's been a profound problem for Twitter
[01:07:13.140 --> 01:07:18.340]  for its entire lifetime, that it's never been led by people
[01:07:18.340 --> 01:07:20.020]  who really seem to use it.
[01:07:20.020 --> 01:07:24.660]  You know, I mean, Jack used it, but not I'm not saying you
[01:07:24.660 --> 01:07:26.420]  have to tweet prolifically.
[01:07:26.420 --> 01:07:28.980]  I mean, maybe Jack used it enough, but Dick Costello didn't
[01:07:28.980 --> 01:07:30.100]  really use it at all.
[01:07:30.100 --> 01:07:32.340]  No, the thing is, he would have been good at it.
[01:07:32.340 --> 01:07:34.660]  But I think the culture is such that he couldn't have done
[01:07:34.660 --> 01:07:35.780]  it. I've met Dick.
[01:07:35.780 --> 01:07:38.420]  I met him at a South by Southwest, I think, a long time ago.
[01:07:38.420 --> 01:07:39.780]  But he's a very funny guy.
[01:07:39.780 --> 01:07:40.500]  He really is.
[01:07:40.500 --> 01:07:41.860]  Yeah, he's a brilliant.
[01:07:41.860 --> 01:07:44.180]  He did stand up comedy, actually, now that I think about
[01:07:44.180 --> 01:07:46.900]  it. I mean, that's how funny, you know, like, successfully,
[01:07:46.900 --> 01:07:49.860]  not like in a cringy Elon, right?
[01:07:49.860 --> 01:07:50.980]  Not on open mic night.
[01:07:50.980 --> 01:07:52.180]  Well, not open mic night.
[01:07:52.180 --> 01:07:56.740]  Not Elon Musk hosting SNL was actually, you know, could do
[01:07:56.740 --> 01:07:59.780]  it, but it therefore could have been, you know, comedians,
[01:07:59.780 --> 01:08:03.620]  in my opinion, tend to be excellent at tweeting.
[01:08:03.620 --> 01:08:08.020]  Well, and also, like, it's the skill is, especially for
[01:08:08.020 --> 01:08:11.700]  improv comedy, reading the room, right?
[01:08:11.700 --> 01:08:14.180]  And this is this really pertinent thing about, you know,
[01:08:14.180 --> 01:08:17.140]  how do you become, how do you have the right set of skills?
[01:08:17.140 --> 01:08:20.260]  But, you know, I think there's just such a, it's funny
[01:08:20.260 --> 01:08:22.500]  because all these examples keep coming back to culture.
[01:08:22.500 --> 01:08:24.740]  You talk about comedy, you talk about music, you talk about
[01:08:24.740 --> 01:08:27.060]  the arts, like, these are things that are about culture
[01:08:27.060 --> 01:08:31.060]  and fluency in what humans are passionate about.
[01:08:31.060 --> 01:08:35.460]  And those are not the, you know, the drivers for this,
[01:08:35.460 --> 01:08:37.220]  this sort of like outside acquisition.
[01:08:37.220 --> 01:08:37.860]  It was ego.
[01:08:37.860 --> 01:08:40.180]  And also the ambivalence about it is the indication, like,
[01:08:40.180 --> 01:08:41.940]  I'm not passionate about this thing.
[01:08:41.940 --> 01:08:46.420]  And those are the, again, zero question that, you know,
[01:08:46.420 --> 01:08:50.340]  a turnaround by Steve Jobs is, is he passionate about the
[01:08:50.340 --> 01:08:51.620]  computers that Apple builds?
[01:08:51.620 --> 01:08:55.220]  Like it's, it's like why he gets up in the morning, right?
[01:08:55.220 --> 01:08:58.340]  Liz breathes and eats it. And, and if you're like, I wasn't
[01:08:58.340 --> 01:09:00.900]  sure if I wanted to buy it or not, but then I got tied into
[01:09:00.900 --> 01:09:02.820]  the deal and I had to go through with it.
[01:09:02.820 --> 01:09:05.300]  You're like, man, that is, that's the opposite energy.
[01:09:05.300 --> 01:09:08.340]  Everybody knew and still knows that the reason Keynote is
[01:09:08.340 --> 01:09:11.700]  one of the best apps Apple has ever made and that anybody's
[01:09:11.700 --> 01:09:14.900]  ever made is that Steve Jobs himself was a diehard user
[01:09:14.900 --> 01:09:15.460]  of Keynote.
[01:09:15.460 --> 01:09:19.460]  And in fact, he had been using Keynote before there even
[01:09:19.460 --> 01:09:20.260]  was Keynote.
[01:09:20.260 --> 01:09:22.820]  There was some app that Next made, you know, that, that was
[01:09:22.820 --> 01:09:26.660]  the roots of Keynote and in between the next years and when
[01:09:26.660 --> 01:09:28.580]  they announced, okay, we're going to come out with this
[01:09:28.580 --> 01:09:32.340]  iWork suite for the Mac called, you know, it with a Keynote
[01:09:32.340 --> 01:09:33.620]  and pages and numbers numbers.
[01:09:33.620 --> 01:09:37.700]  Yeah, he had been using what is Keynote throughout all that
[01:09:37.700 --> 01:09:39.460]  time. He had a team of people making it.
[01:09:39.460 --> 01:09:41.780]  It was that I bet he had great product feedback.
[01:09:41.780 --> 01:09:43.620]  Oh, I'm sure because he used it all the time.
[01:09:44.980 --> 01:09:45.300]  All right.
[01:09:45.300 --> 01:09:46.420]  Anyway, let me take a break here.
[01:09:46.420 --> 01:09:49.220]  The holidays are approaching, so it's time to start thinking
[01:09:49.220 --> 01:09:51.860]  about what you're going to get for gifts for your loved ones.
[01:09:51.860 --> 01:09:54.180]  And I'm sure some of them are hard to shop for.
[01:09:54.180 --> 01:09:56.100]  If you're looking for a gift for somebody who's hard to
[01:09:56.100 --> 01:09:58.500]  shop for it, but you know, they love coffee.
[01:09:58.500 --> 01:10:01.700]  Look no further than a personalized coffee subscription
[01:10:01.700 --> 01:10:03.140]  from Trade Coffee.
[01:10:03.140 --> 01:10:06.100]  Trade Coffee is a coffee subscription service that makes
[01:10:06.100 --> 01:10:10.180]  it so simple to discover new coffees and make your best
[01:10:10.180 --> 01:10:12.260]  coffee at home every day.
[01:10:12.260 --> 01:10:16.500]  Trade partners with the nation's top rated independent
[01:10:16.500 --> 01:10:20.500]  roasters to send you coffee that they know you'll love fresh
[01:10:20.500 --> 01:10:23.540]  to your home and on your preferred schedule.
[01:10:23.540 --> 01:10:24.820]  You want a bag every week.
[01:10:24.820 --> 01:10:26.340]  You want a bag every two weeks.
[01:10:26.340 --> 01:10:27.940]  You want it every 10 days.
[01:10:27.940 --> 01:10:28.660]  You can get it.
[01:10:28.660 --> 01:10:31.220]  You want to pause it because you're going on vacation.
[01:10:31.220 --> 01:10:34.820]  Do you want to change from weekly to biweekly?
[01:10:34.820 --> 01:10:38.420]  Because you're actually not going through it fast enough.
[01:10:38.420 --> 01:10:40.260]  It's all easy to do on the fly.
[01:10:40.820 --> 01:10:43.620]  Whether you already know what type of coffee you like, or
[01:10:43.620 --> 01:10:47.780]  if you're new or your gift is new to specialty coffee and
[01:10:47.780 --> 01:10:51.700]  need some help, Trade makes it easy and convenient to discover
[01:10:51.700 --> 01:10:52.340]  new coffees.
[01:10:52.980 --> 01:10:54.420]  It's a perfect gift for loved ones.
[01:10:54.420 --> 01:10:56.500]  It's a perfect gift for anybody who's a coffee lover.
[01:10:56.500 --> 01:10:58.580]  It's also a perfect gift for yourself.
[01:10:58.580 --> 01:11:02.260]  If you just want fresh coffee, just magically delivered to
[01:11:02.260 --> 01:11:04.260]  your door on a regular schedule.
[01:11:04.260 --> 01:11:05.780]  And it really is terrific coffee.
[01:11:05.780 --> 01:11:08.900]  I had some at the beginning of the podcast right here today.
[01:11:08.900 --> 01:11:12.340]  Treat yourself or the coffee lover in your life with Trade
[01:11:12.340 --> 01:11:12.740]  Coffee.
[01:11:12.740 --> 01:11:16.020]  Right now, Trade is offering listeners of the talk show a
[01:11:16.020 --> 01:11:21.220]  total of $30 off a subscription and access to limited time
[01:11:21.220 --> 01:11:27.460]  holiday specials at DrinkTrade.com slash the talk show.
[01:11:27.460 --> 01:11:34.820]  That's DrinkTrade.com slash the talk show for $30 off.
[01:11:34.820 --> 01:11:36.820]  DrinkTrade.com slash the talk show.
[01:11:38.900 --> 01:11:39.220]  All right.
[01:11:39.220 --> 01:11:40.580]  That was why I was optimistic.
[01:11:42.580 --> 01:11:44.820]  So you know what's interesting, too, is there's a broader
[01:11:44.820 --> 01:11:48.740]  thing that's happening in some parts of tech, like I said,
[01:11:48.740 --> 01:11:49.540]  the tech tycoons.
[01:11:49.540 --> 01:11:52.980]  I think if you look at Musk, you look at Peter Thiel, you
[01:11:52.980 --> 01:11:56.740]  look at the sort of Andreessen Horowitz VC folks, they've
[01:11:56.740 --> 01:12:00.820]  kind of radicalized each other into the opposite of what
[01:12:00.820 --> 01:12:01.300]  they used to be.
[01:12:01.300 --> 01:12:03.700]  So there's a narrative that venture capitalists would say
[01:12:03.700 --> 01:12:07.860]  at the beginning of the Web 2.0 era, which is like, you're
[01:12:07.860 --> 01:12:10.580]  the founders, you're the visionaries, you're the geniuses.
[01:12:10.580 --> 01:12:13.780]  We just want to fund the brilliant things that you make so
[01:12:13.780 --> 01:12:15.540]  that they can change the world.
[01:12:15.540 --> 01:12:17.060]  And that was a very common refrain.
[01:12:17.060 --> 01:12:17.700]  They all said that.
[01:12:18.500 --> 01:12:20.100]  And then you go back.
[01:12:20.100 --> 01:12:21.540]  Actually, this is probably the beginning of the year.
[01:12:21.540 --> 01:12:24.420]  So more than a couple of months ago now, Andreessen Horowitz
[01:12:24.420 --> 01:12:26.980]  put out a really a political platform.
[01:12:26.980 --> 01:12:30.740]  They called it like the America Rebuilding or something
[01:12:30.740 --> 01:12:31.240]  like that.
[01:12:31.860 --> 01:12:36.260]  And it's a very explicitly strongly political document
[01:12:36.260 --> 01:12:39.300]  about the way that capital should be allocated as a country
[01:12:39.300 --> 01:12:41.220]  and what we should invest in, what the resources should be
[01:12:41.220 --> 01:12:41.720]  and the rest.
[01:12:41.720 --> 01:12:49.560]  And they sort of said, if you conform with this political
[01:12:49.560 --> 01:12:52.600]  platform that we are advocating, then we will write you a
[01:12:52.600 --> 01:12:56.440]  check. And this sort of even carried out in their partner,
[01:12:56.440 --> 01:12:58.360]  Chris Dixon, talking about Web 3.0 and the same kind of
[01:12:58.360 --> 01:13:01.960]  thing, which is like a very explicit political and economic
[01:13:01.960 --> 01:13:04.200]  set of goals and an approach.
[01:13:04.200 --> 01:13:06.360]  And if you conform with that, then we'll cut you a check.
[01:13:07.560 --> 01:13:11.000]  But it's akin to the old days when you would get a loan
[01:13:11.000 --> 01:13:14.200]  from your mom and pop company from the bank.
[01:13:14.200 --> 01:13:15.560]  You're like, I want to open a flower shop.
[01:13:15.560 --> 01:13:17.640]  And they're like, okay, we're going to tell you what flowers
[01:13:17.640 --> 01:13:17.960]  to sell.
[01:13:17.960 --> 01:13:19.160]  And if you sell those, you can have a loan.
[01:13:20.360 --> 01:13:21.800]  And it's the opposite.
[01:13:21.800 --> 01:13:25.400]  And it's a rare thing where you go like a 180 from the
[01:13:25.400 --> 01:13:30.040]  narrative of half a generation before of whatever you are,
[01:13:30.040 --> 01:13:32.520]  where our job is to support you and give you resources to.
[01:13:33.400 --> 01:13:35.080]  This is what we're commissioning, right?
[01:13:35.080 --> 01:13:39.160]  Like we're the metages and we expect you to deliver this.
[01:13:39.160 --> 01:13:43.080]  And I think that inversion of power of the big central
[01:13:43.080 --> 01:13:49.080]  capital folks saying, we want you to follow our political
[01:13:49.080 --> 01:13:53.560]  whims is a really stark and striking change.
[01:13:53.560 --> 01:13:54.440]  And it's very different.
[01:13:54.440 --> 01:13:58.040]  It leads to different things being made and a different
[01:13:58.040 --> 01:14:00.200]  allocation of resources to what people focus on.
[01:14:01.880 --> 01:14:07.400]  But I think it's a direct cause of why we're at the moment
[01:14:07.400 --> 01:14:10.600]  that we're at with not just mosque, but sort of across the
[01:14:10.600 --> 01:14:14.600]  board in tech is like, if you had the ambition to sort of
[01:14:14.600 --> 01:14:19.240]  do something really interesting and empowering for people,
[01:14:19.960 --> 01:14:23.240]  the first test is going to be well, but does this help us
[01:14:23.240 --> 01:14:23.960]  do what we're trying to do?
[01:14:23.960 --> 01:14:28.040]  And I think the good example is to look at in the last
[01:14:28.040 --> 01:14:29.880]  generation, one of the big wins for the venture capitalist
[01:14:29.880 --> 01:14:30.680]  is something like Uber.
[01:14:30.680 --> 01:14:30.920]  Right.
[01:14:30.920 --> 01:14:33.480]  And there's a lot of I think everybody's hashed out a lot
[01:14:33.480 --> 01:14:36.520]  of the pros and the cons like you can Google that stuff.
[01:14:36.520 --> 01:14:39.640]  But there are a couple of inarguable things about Uber.
[01:14:39.640 --> 01:14:41.800]  One of which is that it's never made money and it's never
[01:14:41.800 --> 01:14:46.760]  come close and that the investors who invested early in Uber
[01:14:46.760 --> 01:14:50.280]  have made billions of dollars off of it going public.
[01:14:51.240 --> 01:14:55.320]  And also that it's had, you know, a transformative and
[01:14:55.320 --> 01:14:58.680]  deleterious effect on the workers who drive cars and used
[01:14:58.680 --> 01:14:59.640]  to make money doing so.
[01:14:59.640 --> 01:15:05.800]  And that thing of you can make lots and lots of money as
[01:15:05.800 --> 01:15:08.920]  an investor by sucking all of the money out of a market,
[01:15:08.920 --> 01:15:11.160]  even to the harm of the people who were in that business
[01:15:11.160 --> 01:15:11.640]  before.
[01:15:12.280 --> 01:15:15.000]  And it doesn't matter if the business ever makes money
[01:15:15.000 --> 01:15:16.440]  because you'll still get ahead.
[01:15:16.440 --> 01:15:18.840]  And then, of course, we've seen sort of extreme versions
[01:15:18.840 --> 01:15:19.880]  of that with the crypto world.
[01:15:19.880 --> 01:15:23.000]  We're like, again, is people are losing their shirts in the
[01:15:23.000 --> 01:15:23.640]  crypto crash.
[01:15:24.200 --> 01:15:27.080]  You know, Andreessen Horowitz has had the most profitable
[01:15:27.080 --> 01:15:30.200]  fund they've ever had in their history investing in the web
[01:15:30.200 --> 01:15:30.920]  three stuff.
[01:15:30.920 --> 01:15:33.960]  This is a really striking shift from how we used to think
[01:15:33.960 --> 01:15:34.920]  about making technology.
[01:15:37.320 --> 01:15:39.400]  And then it leads to the takeaway, which is you should tell
[01:15:39.400 --> 01:15:41.480]  people what to do because you'll make lots of money that
[01:15:41.480 --> 01:15:43.160]  way, even if it all crashes and burns.
[01:15:45.880 --> 01:15:47.240]  You're really cheering me up here on you.
[01:15:47.240 --> 01:15:49.880]  I'm sorry, but this is why you know what?
[01:15:49.880 --> 01:15:52.440]  This is why I wasn't optimistic about Musk coming in.
[01:15:52.440 --> 01:15:55.800]  This is why I didn't have what I used to have the same
[01:15:55.800 --> 01:15:57.160]  hope you did.
[01:15:57.160 --> 01:16:00.280]  This will shake things up because I'm like, the direction
[01:16:00.280 --> 01:16:02.200]  you're shaking when you shake things up matters.
[01:16:02.200 --> 01:16:05.000]  And I'm like, I don't believe that he wants to solve the
[01:16:05.000 --> 01:16:06.600]  problem that Twitter was born to solve.
[01:16:07.720 --> 01:16:10.920]  And that's still my lens of like, why did you start doing
[01:16:10.920 --> 01:16:11.080]  this?
[01:16:11.080 --> 01:16:13.160]  And I'm like, if he had been skeptical of the other thing,
[01:16:13.160 --> 01:16:14.760]  because he is one of those people says you should make
[01:16:14.760 --> 01:16:15.000]  stuff.
[01:16:15.000 --> 01:16:15.720]  Cars are real.
[01:16:15.720 --> 01:16:16.520]  Rockets are real.
[01:16:16.520 --> 01:16:17.320]  You should make stuff.
[01:16:17.320 --> 01:16:18.120]  Right.
[01:16:18.120 --> 01:16:21.880]  And then I'm like, okay, okay, but how are you approaching
[01:16:21.880 --> 01:16:22.360]  this?
[01:16:22.360 --> 01:16:25.560]  And it was not, I know where we're headed.
[01:16:25.560 --> 01:16:26.440]  This is the vision.
[01:16:26.440 --> 01:16:29.400]  This is the story, which would have been what it looked like
[01:16:29.400 --> 01:16:30.600]  if this is the thing he cared about.
[01:16:30.600 --> 01:16:33.240]  Well, let me read a tweet from you.
[01:16:33.240 --> 01:16:35.720]  I think you tweeted it too, but I've got it on your Mastodon
[01:16:35.720 --> 01:16:36.360]  account in front of me.
[01:16:36.360 --> 01:16:38.200]  This is from April.
[01:16:38.200 --> 01:16:41.400]  Back in April of this year, you wrote people.
[01:16:41.400 --> 01:16:42.600]  This is an April.
[01:16:42.600 --> 01:16:47.880]  This year would be, I think after Musk announced that he
[01:16:47.880 --> 01:16:49.080]  wanted to buy Twitter.
[01:16:49.080 --> 01:16:51.240]  I think it was the day of the first conversation about it,
[01:16:51.240 --> 01:16:52.360]  but there hadn't been anything.
[01:16:52.360 --> 01:16:54.760]  And there had been a couple of weeks before where he might
[01:16:54.760 --> 01:16:55.640]  invest in Twitter.
[01:16:55.640 --> 01:16:56.760]  They might put him on a board.
[01:16:56.760 --> 01:16:57.560]  He said, F you.
[01:16:57.560 --> 01:16:59.080]  We don't want you on the board.
[01:16:59.080 --> 01:16:59.720]  This, that.
[01:16:59.720 --> 01:17:00.760]  And then he was like, you know what?
[01:17:00.760 --> 01:17:01.160]  Screw it.
[01:17:01.160 --> 01:17:03.880]  I'm just going to make an offer to buy you and take you
[01:17:03.880 --> 01:17:04.360]  public.
[01:17:04.360 --> 01:17:06.840]  And here is what you wrote in April.
[01:17:07.560 --> 01:17:10.440]  People are really not realizing how effing terrible.
[01:17:10.440 --> 01:17:11.400]  You wrote the real word.
[01:17:11.400 --> 01:17:14.520]  I'll just say effing in case people are trying.
[01:17:14.520 --> 01:17:18.520]  I swear enough on the fly on this podcast, but I'll try
[01:17:18.520 --> 01:17:20.520]  to keep this clean for people who listen in.
[01:17:20.520 --> 01:17:21.080]  I was cursing.
[01:17:21.080 --> 01:17:21.720]  I'm sorry.
[01:17:21.720 --> 01:17:21.960]  Right.
[01:17:21.960 --> 01:17:25.240]  People are really not realizing how effing terrible the
[01:17:25.240 --> 01:17:27.480]  Musk era of Twitter is going to be.
[01:17:27.480 --> 01:17:30.360]  They see it as some amusing novelty when it's actually going
[01:17:30.360 --> 01:17:33.880]  to reveal how many places Twitter was actually making good
[01:17:33.880 --> 01:17:35.960]  choices because those will end.
[01:17:36.680 --> 01:17:39.080]  So, you know, being right points to you at least so far.
[01:17:40.280 --> 01:17:41.080]  But you know what?
[01:17:41.080 --> 01:17:44.600]  You know what actually inspired that was a couple of years
[01:17:44.600 --> 01:17:49.880]  ago, I'd had an interaction with one of the guys who hosts
[01:17:49.880 --> 01:17:52.280]  the Chapo trap house podcast.
[01:17:52.280 --> 01:17:55.000]  And those guys at that time, I don't know how they feel now,
[01:17:55.000 --> 01:17:56.120]  but they really didn't like me.
[01:17:57.080 --> 01:18:01.080]  And it is one of those, like, you know, people being dicks
[01:18:01.080 --> 01:18:02.760]  to you on Twitter kind of things where I was like, oh, this
[01:18:02.760 --> 01:18:06.520]  sucks. And then one of the guys, Felix reached out to me
[01:18:06.520 --> 01:18:09.160]  and he's like, Hey, you know, folks at Twitter, right?
[01:18:09.160 --> 01:18:09.800]  I was like, yeah.
[01:18:10.360 --> 01:18:15.720]  And he's like, we found these folks that are reporting kids
[01:18:15.720 --> 01:18:20.920]  in Saudi Arabia who are gay and reporting them to the authorities
[01:18:20.920 --> 01:18:22.440]  because it's illegal to be gay there.
[01:18:22.440 --> 01:18:25.080]  And you can be imprisoned and even sentenced to death.
[01:18:26.680 --> 01:18:29.000]  And, you know, it's something he's very fluent in and cares
[01:18:29.000 --> 01:18:29.720]  sincerely about.
[01:18:29.720 --> 01:18:31.800]  And he, you know, the fact that he reached out to somebody
[01:18:31.800 --> 01:18:35.400]  who he had been publicly dunking on for months is an indication
[01:18:35.400 --> 01:18:35.960]  of sincerity.
[01:18:35.960 --> 01:18:37.080]  And I was like, yeah, you know what?
[01:18:37.080 --> 01:18:39.480]  Like none of this Twitter beef means anything.
[01:18:39.480 --> 01:18:41.240]  These kids are in harm's way.
[01:18:41.880 --> 01:18:44.200]  And so I connected him to the right folks and, you know,
[01:18:44.200 --> 01:18:47.560]  kudos to him for raising the issue and getting it handled.
[01:18:47.560 --> 01:18:51.160]  And kudos to Del Harvey, who used to be in charge of trust
[01:18:51.160 --> 01:18:53.320]  and safety at Twitter for doing the right thing on her.
[01:18:53.320 --> 01:18:56.840]  And this was based on these teens in Saudi Arabia, what they
[01:18:56.840 --> 01:18:59.160]  were doing on Twitter, either direct messages.
[01:18:59.160 --> 01:19:00.680]  So they were on Twitter.
[01:19:00.680 --> 01:19:04.760]  And I don't know the full circumstance because I don't read
[01:19:04.760 --> 01:19:09.000]  all of the relevant languages, but what was clear to me was
[01:19:09.880 --> 01:19:11.320]  they had not outed themselves.
[01:19:11.320 --> 01:19:17.720]  And that the people who were doxing them as being gay had
[01:19:17.720 --> 01:19:21.560]  like real world visibility, like physical world visibility
[01:19:21.560 --> 01:19:23.240]  into who they were.
[01:19:23.240 --> 01:19:25.080]  And so knew the implications of what they were doing there.
[01:19:25.800 --> 01:19:28.360]  It could not be a more stark and obvious example of what
[01:19:28.360 --> 01:19:32.440]  these platforms can do and things that Silicon Valley insiders
[01:19:32.440 --> 01:19:36.760]  don't think about, which is, you know, real people's real
[01:19:36.760 --> 01:19:37.160]  lives.
[01:19:37.160 --> 01:19:40.040]  The example I always go to is the Facebook one, which is,
[01:19:40.040 --> 01:19:43.480]  you know, Amnesty International, which could not be more
[01:19:43.480 --> 01:19:47.080]  credible and respected globally, has said that Facebook played
[01:19:47.080 --> 01:19:52.120]  a central role in the enabling the Rohingya genocide in Myanmar
[01:19:52.120 --> 01:19:54.120]  because of its information policies.
[01:19:54.120 --> 01:19:55.960]  And like, I know Rohingya people, right?
[01:19:56.760 --> 01:19:57.800]  That's not abstract to me.
[01:19:57.800 --> 01:20:00.040]  And this is like, you know, these can be my cousins.
[01:20:00.040 --> 01:20:01.800]  Like, they look like my family members.
[01:20:01.800 --> 01:20:06.120]  And this is a thing that doesn't get talked about very much
[01:20:06.120 --> 01:20:07.720]  in the Musk conversation.
[01:20:07.720 --> 01:20:09.400]  Nobody said, what are you going to do?
[01:20:09.400 --> 01:20:10.840]  Because he said, you know, I'm about free speech.
[01:20:10.840 --> 01:20:13.240]  And then one of his early policies actually around this
[01:20:13.240 --> 01:20:16.200]  time that I wrote that message was, you know, anything that's
[01:20:16.200 --> 01:20:19.240]  legal to share is going to be legal on Twitter, right?
[01:20:19.240 --> 01:20:20.680]  Because that's what free speech means.
[01:20:20.680 --> 01:20:28.520]  And it is absolutely 100% legal to out a gay child underage
[01:20:29.160 --> 01:20:33.640]  in Saudi Arabia and lead them to the destruction of their
[01:20:33.640 --> 01:20:34.280]  life.
[01:20:34.280 --> 01:20:35.560]  That is a legal thing to do.
[01:20:36.440 --> 01:20:38.120]  And it is immoral.
[01:20:38.120 --> 01:20:40.120]  Right.
[01:20:40.120 --> 01:20:42.520]  It's a terrific example because it's clearly not the right
[01:20:42.520 --> 01:20:44.200]  policy for Twitter, right?
[01:20:44.200 --> 01:20:46.360]  It's just such a crystal clear example.
[01:20:46.360 --> 01:20:49.160]  And it's also one that is very familiar to people who practice
[01:20:49.160 --> 01:20:52.440]  like this trust and safety organizations now as industry
[01:20:52.440 --> 01:20:55.640]  organizations where people have this trade craft across
[01:20:55.640 --> 01:20:58.280]  many different platforms and learn from each other and
[01:20:58.280 --> 01:20:58.680]  practice.
[01:20:58.680 --> 01:20:59.560]  How do you do this stuff?
[01:20:59.560 --> 01:21:01.400]  And what are the concerns and what do you need to be aware
[01:21:01.400 --> 01:21:01.880]  of?
[01:21:01.880 --> 01:21:04.200]  And there are people that have been doing this for 20 plus
[01:21:04.200 --> 01:21:09.960]  years and that's something where you can become an expert
[01:21:09.960 --> 01:21:10.520]  in it.
[01:21:10.520 --> 01:21:12.840]  And in doing so, you can save people's lives.
[01:21:13.560 --> 01:21:16.600]  And these are not people who were consulted or even considered
[01:21:17.320 --> 01:21:18.280]  in this transaction.
[01:21:18.280 --> 01:21:19.800]  And now they're all gone.
[01:21:19.800 --> 01:21:22.920]  All of them at Twitter, every person who had knowledge of
[01:21:22.920 --> 01:21:24.920]  this domain of problem is gone.
[01:21:25.960 --> 01:21:28.520]  And I didn't know that was going to happen in April, right?
[01:21:29.080 --> 01:21:31.000]  But I knew that he wasn't asking about it.
[01:21:31.000 --> 01:21:37.400]  And that is exactly the sort of thing that I have in these
[01:21:37.400 --> 01:21:38.280]  long three weeks.
[01:21:40.600 --> 01:21:45.320]  And again, just to go back, it's my domain of knowledge,
[01:21:45.320 --> 01:21:48.680]  but to go back to Steve Jobs and coming into Apple, he knew
[01:21:48.680 --> 01:21:49.880]  what they needed to shake up.
[01:21:49.880 --> 01:21:53.080]  They at the time, I think I just reread the article.
[01:21:53.080 --> 01:21:57.240]  I think Apple laid off 4100 people at some point after the
[01:21:57.240 --> 01:22:00.280]  next reunification, which is a lot of people.
[01:22:00.280 --> 01:22:02.840]  It was a substantial percentage of the whole company, a substantial
[01:22:02.840 --> 01:22:09.080]  percentage, but it was extremely measured and famously.
[01:22:09.080 --> 01:22:12.120]  I mean, this is not like, oh, that sounds like a good story
[01:22:12.120 --> 01:22:13.960]  in hindsight, but I'm sure it didn't work out that way.
[01:22:13.960 --> 01:22:16.920]  But no, it really did work out that way where Jobs thought
[01:22:16.920 --> 01:22:19.960]  I'm almost certainly going to have to lay off the entire
[01:22:22.360 --> 01:22:26.920]  hardware design wing of the company because everything they
[01:22:26.920 --> 01:22:27.880]  make looks like shit.
[01:22:27.880 --> 01:22:33.480]  So obviously they all suck, but didn't just ask them upon
[01:22:33.480 --> 01:22:38.280]  taking CEO, went and met them and found a young designer who
[01:22:38.280 --> 01:22:42.440]  was leading them named Johnny Ive and saw that they had all
[01:22:42.440 --> 01:22:47.240]  sorts of wonderful ideas that the company just wasn't making
[01:22:47.240 --> 01:22:49.560]  and that there was an enormous amount of talent.
[01:22:49.560 --> 01:22:52.760]  And he also famous Jobs also famously then said that he was
[01:22:52.760 --> 01:22:54.040]  extremely surprised.
[01:22:54.040 --> 01:22:58.200]  And once he got to know the company, how much software
[01:22:58.200 --> 01:23:00.440]  engineering talent was still there?
[01:23:00.440 --> 01:23:05.000]  Because he just assumed that all of the Apple was in such
[01:23:05.000 --> 01:23:08.920]  trouble that surely there are no good software engineers left
[01:23:08.920 --> 01:23:10.200]  because they would have left.
[01:23:10.200 --> 01:23:11.000]  They already left, right?
[01:23:11.000 --> 01:23:11.240]  No.
[01:23:11.240 --> 01:23:14.120]  And it turned out they love the company and its goals and
[01:23:14.120 --> 01:23:17.560]  its ideals so much that they still were there and it was
[01:23:17.560 --> 01:23:18.760]  talent to be tapped.
[01:23:18.760 --> 01:23:18.920]  Right.
[01:23:18.920 --> 01:23:21.560]  They were just enduring shipping things that they were
[01:23:21.560 --> 01:23:22.200]  crappy, right?
[01:23:22.200 --> 01:23:30.040]  And just as an outside observer with the timeline of Twitter's
[01:23:30.040 --> 01:23:40.120]  layoffs since Musk took over, you don't have to be an insider
[01:23:40.120 --> 01:23:42.920]  to think that they laid people off willy nilly.
[01:23:43.880 --> 01:23:47.240]  And there's reports even that they laid people off and then
[01:23:47.240 --> 01:23:49.160]  realized some of the people they laid off were actually
[01:23:49.160 --> 01:23:51.800]  essential and asked them back 24 hours later.
[01:23:51.800 --> 01:23:55.800]  I mean, I have a friend I've done for quite a while had that
[01:23:55.800 --> 01:23:56.200]  experience.
[01:23:56.200 --> 01:24:00.040]  I don't know anybody firsthand, but I know I can confirm
[01:24:00.040 --> 01:24:00.840]  second hand that.
[01:24:00.840 --> 01:24:05.320]  Yes, I know somebody second hand who that story is actually
[01:24:05.320 --> 01:24:05.560]  true.
[01:24:06.280 --> 01:24:07.640]  It wasn't just one person.
[01:24:07.640 --> 01:24:08.440]  It was quite a few.
[01:24:09.640 --> 01:24:12.360]  That's not how you do layoffs wisely.
[01:24:13.080 --> 01:24:15.880]  Well, it's also just the inhumanity of it all of it was
[01:24:15.880 --> 01:24:16.440]  needlessly cruel.
[01:24:16.440 --> 01:24:18.600]  I mean, I think the same day that Twitter began its layoffs,
[01:24:18.600 --> 01:24:21.480]  they had layoffs at Stripe, the payment company.
[01:24:21.480 --> 01:24:25.560]  And Stripe is obviously not Twitter in a million ways.
[01:24:25.560 --> 01:24:27.960]  One, it's very behind the scenes, sort of technical, but
[01:24:27.960 --> 01:24:32.120]  two, it's actually much bigger business in terms of dollars.
[01:24:33.160 --> 01:24:40.360]  And it's always awful to people being laid off and to go
[01:24:40.360 --> 01:24:41.000]  through that experience.
[01:24:41.560 --> 01:24:43.240]  They were so thoughtful about it.
[01:24:43.240 --> 01:24:46.600]  I mean, they really articulated what mistake they'd made,
[01:24:46.600 --> 01:24:49.240]  that it was a mistake, that the leadership is the ones who
[01:24:49.240 --> 01:24:51.000]  are accountable for why this has to happen in the first
[01:24:51.000 --> 01:24:52.680]  place. But here's what we can do about it.
[01:24:52.680 --> 01:24:56.920]  You know, the alumni email addresses for people to be able
[01:24:56.920 --> 01:24:58.760]  to be reachable and be able to connect with one another,
[01:24:58.760 --> 01:25:02.040]  because one of the most dehumanizing aspects of a layoff
[01:25:02.040 --> 01:25:05.000]  is you lose contact with your coworkers who were the people
[01:25:05.000 --> 01:25:07.320]  around you, you know, like all those things they sort of
[01:25:07.320 --> 01:25:07.880]  thought through.
[01:25:07.880 --> 01:25:10.920]  And I thought you never want to have to do it.
[01:25:10.920 --> 01:25:13.320]  But if you are going to have to do it, here's how you can
[01:25:13.320 --> 01:25:13.720]  do it.
[01:25:13.720 --> 01:25:15.320]  And it was the same day.
[01:25:15.320 --> 01:25:18.840]  It was the same day with the same 24 hours, and you can't
[01:25:18.840 --> 01:25:22.840]  make up the serendipity or the contrast.
[01:25:22.840 --> 01:25:23.240]  Yeah.
[01:25:23.240 --> 01:25:23.480]  Yeah.
[01:25:23.480 --> 01:25:27.640]  And it was stark, too, because I also think Patrick and John
[01:25:27.640 --> 01:25:30.760]  Carlson, the brothers who founded Stripe, they're Irish.
[01:25:30.760 --> 01:25:33.160]  And I think a big part of this, too, is also the culture,
[01:25:33.160 --> 01:25:33.320]  right?
[01:25:33.320 --> 01:25:37.400]  They come from a culture where you're supposed to treat
[01:25:37.400 --> 01:25:39.000]  people with dignity at work.
[01:25:39.000 --> 01:25:41.000]  There's a limited number of hours you work, and people are
[01:25:41.000 --> 01:25:43.080]  supposed to be paid, and there's a social safety net.
[01:25:43.080 --> 01:25:48.040]  And any manner of considerations is a very proud worker
[01:25:48.040 --> 01:25:49.880]  culture in Ireland.
[01:25:50.520 --> 01:25:55.320]  And so I think that informs their sense of obligation and
[01:25:55.320 --> 01:25:58.920]  sort of social responsibility around it.
[01:25:58.920 --> 01:25:59.960]  I don't want to be too reductive.
[01:25:59.960 --> 01:26:01.800]  Obviously, it's also they made a good choice, and their
[01:26:01.800 --> 01:26:03.320]  leaders make good choices all the way down.
[01:26:03.320 --> 01:26:05.640]  But that contrast sort of draws.
[01:26:05.640 --> 01:26:07.720]  There's no reason that these had to be different.
[01:26:07.720 --> 01:26:10.600]  There is no reason that these had to be so stark a contrast
[01:26:10.600 --> 01:26:12.600]  in terms of the humanity of it.
[01:26:12.600 --> 01:26:16.280]  And this is why I say I think one of the galvanizing forces
[01:26:16.280 --> 01:26:22.680]  for all this is that poisonous analog to owning the liberals,
[01:26:23.320 --> 01:26:27.400]  which is within the tech tycoon circles in that conference
[01:26:27.400 --> 01:26:30.200]  room with David Sachs and Jason Calcanis and all these folks
[01:26:30.200 --> 01:26:31.320]  that Musk has around him.
[01:26:32.760 --> 01:26:34.680]  This is how we show we're strong, which is the sort of
[01:26:34.680 --> 01:26:37.080]  classic thing that we can insecure people do.
[01:26:37.080 --> 01:26:39.320]  We show we're strong by bullying these people who we have
[01:26:39.320 --> 01:26:40.120]  power over.
[01:26:40.120 --> 01:26:40.680]  Right.
[01:26:40.680 --> 01:26:45.240]  They're doing layoffs in the most dehumanizing.
[01:26:45.240 --> 01:26:46.680]  I don't think there's any other word for it.
[01:26:46.680 --> 01:26:47.180]  Yeah.
[01:26:48.120 --> 01:26:51.160]  And again, you can come up with a hypothetical science fiction
[01:26:51.160 --> 01:26:55.560]  scenario of the worst, but in practical real world terms,
[01:26:55.560 --> 01:26:57.640]  it's hard to imagine how Twitter could have done it in a
[01:26:57.640 --> 01:27:02.040]  more dehumanizing way with emails going out at midnight
[01:27:02.760 --> 01:27:05.000]  that said, here's what you do.
[01:27:05.000 --> 01:27:07.800]  You check your email at eight in the morning, and it's either
[01:27:07.800 --> 01:27:09.560]  going to find out if you got a job still.
[01:27:09.560 --> 01:27:10.060]  Yeah.
[01:27:10.060 --> 01:27:16.620]  I mean, who would even come up with an idea like that?
[01:27:16.620 --> 01:27:22.620]  I mean, what was the rush?
[01:27:22.620 --> 01:27:28.540]  The rush wasn't however bad Twitter's finances are.
[01:27:28.540 --> 01:27:30.220]  And they're not good.
[01:27:30.220 --> 01:27:33.100]  It's famously one of the problems is overall in the history
[01:27:33.100 --> 01:27:34.860]  of the company, they're unprofitable.
[01:27:34.860 --> 01:27:35.420]  Yeah.
[01:27:35.420 --> 01:27:36.620]  And I do think they're bloated.
[01:27:36.620 --> 01:27:37.340]  I've said this.
[01:27:37.340 --> 01:27:38.700]  I'm sure.
[01:27:38.700 --> 01:27:40.300]  They're quite bloated.
[01:27:40.300 --> 01:27:44.940]  The layoffs were the right move, but there was no reason
[01:27:44.940 --> 01:27:47.740]  to do it on 12 hours notice.
[01:27:47.740 --> 01:27:50.380]  You know, it's just not even close, right?
[01:27:50.380 --> 01:27:53.820]  It's not even worth perseverating on the point here on the podcast.
[01:27:54.540 --> 01:27:58.540]  And other than to point out the point you made, which is
[01:27:58.540 --> 01:28:02.220]  that the cruelty of it was the point, you know, that doing
[01:28:02.220 --> 01:28:06.700]  it in this fashion wasn't a happenstance or, oh, they didn't
[01:28:06.700 --> 01:28:10.380]  even, it didn't really occur to them that this is a sort
[01:28:10.380 --> 01:28:15.340]  of cruel way of doing it.
[01:28:16.140 --> 01:28:18.780]  Well, and it's a performative cruelty for their peers, right?
[01:28:18.780 --> 01:28:21.900]  This is this thing that they're sort of, I think we're
[01:28:21.900 --> 01:28:23.500]  going to see one up some ship on this.
[01:28:23.500 --> 01:28:25.820]  I think the others in that cohort are going to do sort
[01:28:25.820 --> 01:28:29.740]  of similarly depraved things, you know, in the months and
[01:28:29.740 --> 01:28:33.020]  years to come, because that standard's now been set.
[01:28:33.020 --> 01:28:35.180]  He's being cheered on by his fanboys for this.
[01:28:35.180 --> 01:28:36.140]  Like, let's keep in mind.
[01:28:36.140 --> 01:28:39.340]  It's not like people's reaction to this was the, the human
[01:28:39.340 --> 01:28:42.860]  and, you know, rational thing where you sort of say, gosh,
[01:28:42.860 --> 01:28:45.100]  these are people with lives and families.
[01:28:45.100 --> 01:28:46.700]  And why are you acting this way?
[01:28:47.340 --> 01:28:50.460]  Like his fans are like, that shows them this is us getting
[01:28:50.460 --> 01:28:52.780]  back at, I don't know, woke culture or whatever their
[01:28:52.780 --> 01:28:53.340]  argument is.
[01:28:54.380 --> 01:28:57.500]  And I guess, you know, I did not see this coming.
[01:28:57.500 --> 01:29:00.140]  I, you know, I'm not a David Sachs fan.
[01:29:00.140 --> 01:29:03.180]  I don't know him that well, but I know of him, you know,
[01:29:03.180 --> 01:29:05.740]  and I know that he was close to Musk, but I really did not
[01:29:05.740 --> 01:29:09.580]  expect David Sachs to be at Twitter headquarters Friday
[01:29:09.580 --> 01:29:15.980]  night, you know, interviewing engineering managers and making
[01:29:15.980 --> 01:29:18.860]  a list of, yeah, that guy, you know, seems okay.
[01:29:18.860 --> 01:29:19.260]  Keep him.
[01:29:19.820 --> 01:29:21.580]  She doesn't just get rid of her.
[01:29:21.580 --> 01:29:25.180]  You know, I did not expect him to be playing a role like
[01:29:25.180 --> 01:29:29.420]  that. I did not expect massive layoffs to happen within a
[01:29:29.420 --> 01:29:32.700]  week. Obviously, nobody could do that within a week, right?
[01:29:32.700 --> 01:29:33.740]  No, no, you can't.
[01:29:33.740 --> 01:29:34.540]  And it's the whole point.
[01:29:34.540 --> 01:29:37.180]  How else do you find out that there's a Johnny Ive in the
[01:29:37.180 --> 01:29:39.820]  design department other than taking your time?
[01:29:39.820 --> 01:29:41.420]  There's the right pace.
[01:29:41.420 --> 01:29:43.660]  It's not, Oh, we have all the time in the world.
[01:29:43.660 --> 01:29:49.180]  You know, urgency is different than what's urgency is okay.
[01:29:52.220 --> 01:29:55.740]  Acting as though the building is on fire is not when it's
[01:29:55.740 --> 01:29:59.500]  not. I just didn't see it coming.
[01:29:59.500 --> 01:30:04.300]  And I think I put too much faith in the fact that he obviously
[01:30:04.300 --> 01:30:10.620]  knows Musk knows what it's like to lead very large companies
[01:30:10.620 --> 01:30:17.420]  that need very talented people working for them to succeed,
[01:30:17.420 --> 01:30:17.660]  right?
[01:30:17.660 --> 01:30:22.540]  There is no way to create a rocket ship that works, let
[01:30:22.540 --> 01:30:26.540]  alone to innovate and have a rocket ship that can go up and
[01:30:26.540 --> 01:30:30.140]  then come back down and land on a raft as opposed to going,
[01:30:30.140 --> 01:30:32.940]  you know, and again, you make breakthroughs like that.
[01:30:32.940 --> 01:30:35.500]  And I forget what you were talking about earlier on the show
[01:30:35.500 --> 01:30:38.780]  where we look back and, you know, years and laugh.
[01:30:38.780 --> 01:30:42.220]  But in hindsight, it's crazy that the way that we've been
[01:30:42.220 --> 01:30:46.060]  putting things into satellites into space for 50 years
[01:30:46.060 --> 01:30:49.820]  involves massively expensive rockets just ending up in the
[01:30:49.820 --> 01:30:52.300]  bottom of the Pacific or Atlantic oceans, you know?
[01:30:52.300 --> 01:30:54.700]  Yeah, that's that's right.
[01:30:54.700 --> 01:30:56.300]  That's that's a high five.
[01:30:56.300 --> 01:30:57.660]  That's that's the team mission.
[01:30:57.660 --> 01:30:58.220]  Victory.
[01:30:58.220 --> 01:31:00.460]  Mission control is high fiving each other.
[01:31:00.460 --> 01:31:02.300]  You know, it's Miller time, you know, celebrate.
[01:31:02.300 --> 01:31:03.580]  It was a successful launch.
[01:31:03.580 --> 01:31:07.980]  We just dropped a missile in the ocean, right?
[01:31:09.100 --> 01:31:15.500]  You make breakthroughs like that by acquiring and holding
[01:31:15.500 --> 01:31:17.500]  talented people.
[01:31:18.540 --> 01:31:19.100]  Yeah.
[01:31:19.100 --> 01:31:22.700]  So what I'll give is that people talk about coders, right?
[01:31:22.700 --> 01:31:23.420]  Or programmers.
[01:31:23.420 --> 01:31:24.860]  Are they talking about one?
[01:31:24.860 --> 01:31:28.060]  I think there's a again amongst the bubble that he's in and
[01:31:28.060 --> 01:31:30.300]  the sort of most extreme of right wing media.
[01:31:30.300 --> 01:31:33.020]  I think there's this perception of like Twitter was like 90%
[01:31:33.580 --> 01:31:36.380]  content moderators just trying to shut down anybody saying
[01:31:36.940 --> 01:31:38.380]  anything nice about Republicans.
[01:31:38.380 --> 01:31:40.380]  You know, it's sort of this weird, distorted thing.
[01:31:40.380 --> 01:31:43.340]  It's like it's mostly a bunch of coders like it's a technology
[01:31:43.340 --> 01:31:47.100]  company, but also, you know, you'll know what this has been.
[01:31:47.100 --> 01:31:50.860]  Maybe not everybody else to the S.R.E.'s systems reliability
[01:31:50.860 --> 01:31:51.420]  engineers.
[01:31:51.420 --> 01:31:56.460]  This is a very specific discipline within large tech
[01:31:56.460 --> 01:31:59.340]  companies, but it is, you know, the people what it sounds like
[01:31:59.340 --> 01:32:00.380]  it's about reliability.
[01:32:00.380 --> 01:32:03.580]  It's making sure that these these systems that the very many
[01:32:03.580 --> 01:32:08.140]  complicated systems that run these modern Internet platforms
[01:32:08.700 --> 01:32:09.340]  keep running.
[01:32:09.340 --> 01:32:16.460]  And it's a extremely demanding, extremely technical practice
[01:32:16.460 --> 01:32:21.660]  and very frequently relies on being on call like just like
[01:32:21.660 --> 01:32:22.300]  doctors are, right?
[01:32:22.300 --> 01:32:24.460]  It's like if this thing blows up, you got to come in and fix
[01:32:24.460 --> 01:32:30.300]  it and and Twitter has arguably some some of the best S.R.E.'s
[01:32:30.300 --> 01:32:32.700]  who have ever done this work anywhere.
[01:32:32.700 --> 01:32:34.620]  You know, you put them up against Google, you put them up
[01:32:34.620 --> 01:32:37.500]  against, you know, Facebook, anybody you want to put up there
[01:32:37.500 --> 01:32:40.940]  and keep in mind, Google and Facebook are much, much larger
[01:32:40.940 --> 01:32:42.860]  than Twitter as much attention as Twitter gets.
[01:32:42.860 --> 01:32:45.900]  It is nowhere near in the same league as the trillion dollar
[01:32:45.900 --> 01:32:50.060]  companies like Amazon and Google and get some of the best
[01:32:50.060 --> 01:32:53.260]  S.R.E.'s who've ever done the work have been at Twitter
[01:32:53.260 --> 01:32:53.900]  historically.
[01:32:53.900 --> 01:32:57.500]  And it's because of the challenge, because it is that hard
[01:32:57.500 --> 01:33:00.220]  to be the real time information engine for the world.
[01:33:01.260 --> 01:33:07.580]  And and that group being decimated like I can obviously
[01:33:07.580 --> 01:33:09.740]  articulate the story around the content moderators.
[01:33:09.740 --> 01:33:10.940]  We can all understand that.
[01:33:10.940 --> 01:33:13.420]  But this is the kind of thing where you have you have the
[01:33:13.420 --> 01:33:15.100]  rocket scientists, right?
[01:33:15.100 --> 01:33:18.220]  You have the people who can do this unique task in the world
[01:33:18.220 --> 01:33:20.460]  in a way better than anybody else has done it to the point
[01:33:20.460 --> 01:33:23.340]  where all the other platforms are leaning on their their
[01:33:23.340 --> 01:33:24.540]  technologies that they invent.
[01:33:24.540 --> 01:33:28.380]  They're using the same architecture, you know, and those
[01:33:28.380 --> 01:33:31.100]  folks are all gone or worse, willy nilly.
[01:33:31.100 --> 01:33:33.500]  People are feeling like the guy to the left of me and the
[01:33:33.500 --> 01:33:35.980]  person to the right of me both got picked off and I'm still
[01:33:35.980 --> 01:33:38.620]  here and I don't know why I survived, which is a lot of
[01:33:38.620 --> 01:33:39.260]  people's feeling.
[01:33:41.580 --> 01:33:42.620]  It's so destabilizing.
[01:33:43.260 --> 01:33:47.580]  And and that's what I I honestly find surprising given
[01:33:47.580 --> 01:33:51.980]  that, you know, that Musk didn't he's not coming from.
[01:33:51.980 --> 01:33:55.820]  I realized that Tesla is that they're not similar to Twitter
[01:33:55.820 --> 01:33:57.660]  and their problems, but they're similar in the way that they
[01:33:57.660 --> 01:34:01.500]  need to, like I said, acquire and hold on to talent.
[01:34:02.140 --> 01:34:06.620]  Why in the world, given his leadership in three weeks, would
[01:34:06.620 --> 01:34:12.220]  anybody of of talent take a job at Twitter going forward?
[01:34:12.220 --> 01:34:16.300]  I mean, it's I mean, SREs are leaving Tesla because of this.
[01:34:16.300 --> 01:34:18.460]  Like this is the thing is like it is a community that exists
[01:34:18.460 --> 01:34:23.420]  and beyond one company and they all talk and and and you go
[01:34:23.420 --> 01:34:26.300]  into that practice because you value stability.
[01:34:26.300 --> 01:34:27.500]  That is your job.
[01:34:28.140 --> 01:34:30.140]  The thing you were doing there is sacrificing your nights
[01:34:30.140 --> 01:34:32.700]  and weekends for and missing out on movies with your kids
[01:34:32.700 --> 01:34:35.340]  for is because you think it's important to offer stability
[01:34:35.340 --> 01:34:37.420]  to the world and the technology that they use.
[01:34:38.940 --> 01:34:41.420]  And there is nothing less stable than this.
[01:34:41.420 --> 01:34:44.620]  Like it could not be a more perfect way to undermine their
[01:34:44.620 --> 01:34:47.660]  values at a human level, their sense of purpose in the world.
[01:34:47.660 --> 01:34:54.140]  And as you alluded to earlier, to demand personal fealty from
[01:34:54.140 --> 01:34:57.500]  engineers, I mean, again, it's not a way to me demanding
[01:34:57.500 --> 01:35:00.140]  personal fealty is no way to lead any group, anything.
[01:35:00.140 --> 01:35:01.660]  Yeah, it's always a sickness.
[01:35:01.660 --> 01:35:04.780]  But in this case, it's the particular worst sickness you
[01:35:04.780 --> 01:35:05.660]  could possibly have.
[01:35:05.660 --> 01:35:06.860]  And I've often said this.
[01:35:06.860 --> 01:35:07.660]  I have many friends.
[01:35:07.660 --> 01:35:08.380]  I know you do, too.
[01:35:08.380 --> 01:35:11.980]  I'm sure most of many of the people listening are engineers.
[01:35:11.980 --> 01:35:15.660]  And certainly almost everybody who listens to my show knows
[01:35:15.660 --> 01:35:17.580]  software engineers or hardware engineers.
[01:35:17.580 --> 01:35:22.140]  I have always thought engineers are among are the most
[01:35:22.140 --> 01:35:24.620]  interesting if you just if that's all I know about you is
[01:35:24.620 --> 01:35:28.140]  that you're an engineer of some sort, then there's a much
[01:35:28.140 --> 01:35:34.380]  higher way higher chance than a random person that I would
[01:35:34.380 --> 01:35:38.380]  enjoy talking about politics with you, whether we agree or
[01:35:38.380 --> 01:35:41.500]  disagree, whether you have voted Republican almost every
[01:35:41.500 --> 01:35:45.660]  time for your life, and I've voted Democrat most of the time
[01:35:45.660 --> 01:35:49.100]  my life, I bet we could have a really interesting decision
[01:35:49.100 --> 01:35:53.020]  or discussion about the differences, because the engineering
[01:35:53.020 --> 01:35:57.660]  mindset is to look at it analytically and rationally and
[01:35:57.660 --> 01:36:01.100]  talk about actual problems and actual solutions and to try
[01:36:01.100 --> 01:36:06.140]  to try actively to take the emotion out of it.
[01:36:06.140 --> 01:36:06.460]  Right.
[01:36:06.460 --> 01:36:09.180]  And politics famously, it's you know, nobody can completely
[01:36:09.180 --> 01:36:12.060]  detach emotion from it, but you can try.
[01:36:12.060 --> 01:36:15.420]  And that's what can give an interesting discussion between
[01:36:15.420 --> 01:36:19.420]  people who disagree and probably will not come to agreement
[01:36:19.420 --> 01:36:21.180]  simply by having the discussion.
[01:36:21.180 --> 01:36:24.220]  But that's that that mindset is exactly the sort of thing
[01:36:24.220 --> 01:36:28.540]  that, you know, click this link to say you agree that you're
[01:36:28.540 --> 01:36:30.860]  going to you're going to go totally hardcore.
[01:36:30.860 --> 01:36:33.740]  I mean, I'm not as offended by his memo that he sent out last
[01:36:33.740 --> 01:36:36.300]  night, as some some people are totally outraged.
[01:36:36.300 --> 01:36:38.460]  I see some of what he's saying there.
[01:36:38.460 --> 01:36:41.260]  I certainly wouldn't have used the words that he used.
[01:36:41.260 --> 01:36:47.260]  I think calling it going I don't know how you could what's
[01:36:47.260 --> 01:36:50.060]  the show on HBO Silicon Valley, right?
[01:36:50.060 --> 01:36:53.580]  Yeah, they mock they mock Silicon Valley culture.
[01:36:55.100 --> 01:36:58.140]  If I were in the writers, this is more extreme than any
[01:36:58.140 --> 01:36:58.540]  parody.
[01:36:59.100 --> 01:37:02.700]  Yeah, if I were in the writers room and the episode had the
[01:37:02.700 --> 01:37:07.340]  Elon Musk thinly veiled Callan character writing an email
[01:37:07.340 --> 01:37:10.140]  saying that their culture was going to be, quote, totally
[01:37:10.140 --> 01:37:14.460]  hardcore. I would say that's that's too much, you know, I
[01:37:14.460 --> 01:37:15.420]  get horny.
[01:37:15.420 --> 01:37:17.180]  I mean, that's the other thing, too, that I think is really
[01:37:17.180 --> 01:37:18.140]  important in all this, too.
[01:37:18.140 --> 01:37:22.780]  It's so that what more personifies the tech bro attitude.
[01:37:22.780 --> 01:37:24.860]  The guy's got no taste, right?
[01:37:24.860 --> 01:37:25.660]  Like this is this thing.
[01:37:25.660 --> 01:37:27.980]  It's like this is corny shit, right?
[01:37:27.980 --> 01:37:28.940]  This is embarrassing.
[01:37:28.940 --> 01:37:31.420]  That's an embarrassing thing to put in the subject line of
[01:37:31.420 --> 01:37:34.700]  an email who talks like that in 2022, right?
[01:37:34.700 --> 01:37:35.900]  That's boomer behavior.
[01:37:35.900 --> 01:37:37.020]  Why are you doing that?
[01:37:37.020 --> 01:37:42.220]  Inspiring the whole company to that we we're we need to build
[01:37:42.220 --> 01:37:43.740]  Twitter 2.0.
[01:37:43.740 --> 01:37:45.980]  We the company is not in good shape.
[01:37:45.980 --> 01:37:48.860]  You know, we've had to let go of a lot of people.
[01:37:48.860 --> 01:37:51.660]  So now there's fewer of us than there were.
[01:37:52.460 --> 01:37:55.740]  We need to work harder than we've been working to build this
[01:37:55.740 --> 01:37:57.260]  thing that there you go there.
[01:37:57.260 --> 01:37:59.660]  You know, I mean, I think the other thing is you would do
[01:37:59.660 --> 01:38:00.860]  that first, right?
[01:38:00.860 --> 01:38:03.340]  That's not the thing you do after chaos for a month.
[01:38:03.340 --> 01:38:08.300]  You can, you know, saying we need to work harder and come up
[01:38:08.300 --> 01:38:11.260]  with better ideas and we need to do a better job of execution
[01:38:11.260 --> 01:38:13.020]  and ship new features faster.
[01:38:13.020 --> 01:38:13.420]  All of it.
[01:38:13.420 --> 01:38:14.220]  You could say that.
[01:38:14.220 --> 01:38:17.820]  And that's the CEO and the industry is saying that right
[01:38:17.820 --> 01:38:18.060]  now.
[01:38:18.060 --> 01:38:22.140]  That's the CEO as the coach of the team, inspiring the team
[01:38:22.140 --> 01:38:25.980]  to play at the highest level that they're capable of.
[01:38:25.980 --> 01:38:29.180]  But it's totally got to be totally hardcore.
[01:38:29.180 --> 01:38:29.580]  Totally.
[01:38:29.580 --> 01:38:30.300]  It's ridiculous.
[01:38:30.300 --> 01:38:31.660]  I also want to I want to put out something.
[01:38:31.660 --> 01:38:34.300]  So as we're recording this, I'm getting ready tomorrow.
[01:38:34.300 --> 01:38:35.100]  I'm going to be at this.
[01:38:36.380 --> 01:38:38.140]  This is going to be like the most political episode you've
[01:38:38.140 --> 01:38:38.460]  ever had.
[01:38:38.460 --> 01:38:41.980]  I'm at this Obama Foundation, a democracy forum, and they're,
[01:38:41.980 --> 01:38:43.580]  you know, sort of wrangling with all the different things
[01:38:43.580 --> 01:38:45.340]  that are threatening democracy around the world.
[01:38:45.340 --> 01:38:46.700]  No big topic there.
[01:38:47.660 --> 01:38:51.020]  And we have conversation about misinformation, disinformation,
[01:38:51.020 --> 01:38:53.180]  media manipulation, all these sort of related topics.
[01:38:53.180 --> 01:38:55.260]  But obviously, Twitter is a huge part of that conversation.
[01:38:55.980 --> 01:38:58.700]  And there's an interesting thing where like Obama had done
[01:38:58.700 --> 01:39:03.260]  a speech at Stanford in the spring of this year and it got,
[01:39:03.260 --> 01:39:05.340]  you know, I got a little bit of coverage, not actually that
[01:39:05.340 --> 01:39:07.740]  much, because it's sort of, you know, I think people feel
[01:39:07.740 --> 01:39:08.860]  like they already know he's going to say.
[01:39:09.580 --> 01:39:14.620]  And it was in his way, you know, very professorial and even
[01:39:14.620 --> 01:39:15.100]  handed.
[01:39:15.100 --> 01:39:17.660]  And, you know, like these are things that are not entirely
[01:39:17.660 --> 01:39:19.180]  compliments, but like, it's fine.
[01:39:19.180 --> 01:39:20.780]  He did what he does and he's a great speaker.
[01:39:21.340 --> 01:39:24.300]  But in there, there was a really interesting section that
[01:39:24.300 --> 01:39:27.500]  jumped out to me, which was he talked about, you know,
[01:39:27.500 --> 01:39:30.300]  everybody's focused on the algorithms and what gets, you
[01:39:30.300 --> 01:39:33.020]  know, amplified and whether they're being fair to everybody.
[01:39:33.020 --> 01:39:36.620]  But he's like, it's a market failure that we care this much
[01:39:36.620 --> 01:39:40.060]  about any one platform, whether it's Twitter or anything
[01:39:40.060 --> 01:39:40.140]  else.
[01:39:40.140 --> 01:39:43.020]  And I think it was right after Musk had talked about, you
[01:39:43.020 --> 01:39:44.860]  know, started saber rattling around Twitter.
[01:39:45.820 --> 01:39:49.740]  And it was a really astute analysis or is a really sharp
[01:39:49.740 --> 01:39:52.540]  point, which is the fact that we care about any one of these
[01:39:52.540 --> 01:39:55.980]  platforms means the market isn't competitive and that we're
[01:39:55.980 --> 01:39:58.540]  not inventing enough new ways to communicate and connect and
[01:39:58.540 --> 01:39:59.500]  that we don't have enough.
[01:39:59.500 --> 01:40:00.940]  You know, he did not.
[01:40:00.940 --> 01:40:02.060]  Those were kind of his words of the party.
[01:40:02.060 --> 01:40:04.060]  He didn't say it's like what I would articulate, open
[01:40:04.060 --> 01:40:06.700]  protocols, open standards, interoperability, right?
[01:40:06.700 --> 01:40:09.740]  Like, like nobody feels like beholden to their email
[01:40:09.740 --> 01:40:10.780]  provider, right?
[01:40:11.740 --> 01:40:15.820]  And it was really stunning because I was like, one, it's
[01:40:15.820 --> 01:40:16.140]  true.
[01:40:16.140 --> 01:40:18.220]  It's absolutely correct diagnosis, right?
[01:40:18.220 --> 01:40:21.580]  Like it shouldn't matter this much if Twitter gets broken.
[01:40:21.580 --> 01:40:22.220]  You know what I mean?
[01:40:22.220 --> 01:40:25.900]  Like it actually is a failure of the ecosystem that there
[01:40:25.900 --> 01:40:29.180]  isn't some other player and, you know, in competitive markets,
[01:40:29.180 --> 01:40:32.700]  like it is, and it's been absolutely phenomenal for the
[01:40:32.700 --> 01:40:36.060]  iPhone that Android is such a strong ecosystem and so
[01:40:36.060 --> 01:40:36.700]  innovative, right?
[01:40:36.700 --> 01:40:37.660]  Like that's a great thing.
[01:40:37.660 --> 01:40:40.140]  That is a competitive, fiercely competitive market.
[01:40:40.140 --> 01:40:43.260]  Even if there's a little bit of unfair play by the two big
[01:40:43.260 --> 01:40:44.300]  players who run it, right?
[01:40:44.300 --> 01:40:48.620]  But like it's inarguably competitive and Twitter does not
[01:40:48.620 --> 01:40:49.980]  have any direct competitors, right?
[01:40:49.980 --> 01:40:50.700]  Facebook is not.
[01:40:50.700 --> 01:40:52.300]  Nobody said, I'm fed up with Twitter.
[01:40:52.300 --> 01:40:53.180]  I'm going to go to Facebook.
[01:40:53.180 --> 01:40:55.740]  Not one person, right? Even though everybody has a Facebook
[01:40:55.740 --> 01:40:58.220]  account, that's telling these are not the closest thing they
[01:40:58.220 --> 01:41:00.780]  have to a direct competitor would be Instagram because the
[01:41:00.780 --> 01:41:04.220]  basic paradigm is sort of similar where it's you, but nobody
[01:41:04.220 --> 01:41:07.020]  uses in the same way, socially and culturally right, right.
[01:41:07.020 --> 01:41:12.060]  And because of Instagram's design, and again, I could go on
[01:41:12.060 --> 01:41:16.140]  and on about it, but it really does matter what you started
[01:41:16.140 --> 01:41:19.420]  ads, even when you started, you know, when Instagram started
[01:41:19.420 --> 01:41:24.060]  as, you know, three, four or five people and Twitter was,
[01:41:24.060 --> 01:41:27.260]  you know, just a weird side project of audio and there were
[01:41:27.260 --> 01:41:29.820]  only a half a dozen people working on it.
[01:41:29.820 --> 01:41:33.900]  But the basic idea, that little kernel that grows into this
[01:41:33.900 --> 01:41:37.420]  massive billion user thing that Instagram has, I know Twitter
[01:41:37.420 --> 01:41:41.500]  only has 200 million users or whatever it that matters.
[01:41:41.500 --> 01:41:43.580]  It was, but yeah, you're right.
[01:41:43.580 --> 01:41:46.940]  There is no direct competitor, but that's also true of
[01:41:46.940 --> 01:41:47.820]  Instagram too, right?
[01:41:47.820 --> 01:41:50.620]  We could do a whole podcast episode about the the defacement
[01:41:50.620 --> 01:41:54.460]  of Instagram over the last few years by Facebook.
[01:41:54.460 --> 01:41:56.460]  I don't recognize I don't use Instagram very much.
[01:41:56.460 --> 01:41:58.140]  I go in like maybe every couple months.
[01:41:58.140 --> 01:42:00.620]  It's never the same twice and it is never what I think it is.
[01:42:00.620 --> 01:42:04.140]  It's it, you know, and again, there is no real competitor.
[01:42:04.140 --> 01:42:07.820]  You know, you know, I've I've moved to glass and I had the
[01:42:07.820 --> 01:42:10.380]  founders of glass on the podcast a couple months ago, but
[01:42:10.380 --> 01:42:12.940]  they they don't describe themselves as a competitor to
[01:42:12.940 --> 01:42:14.700]  no, they're doing a different thing that happens to be
[01:42:14.700 --> 01:42:15.420]  photos, right?
[01:42:15.420 --> 01:42:18.700]  I I actually have been really heartened by like seeing I've
[01:42:18.700 --> 01:42:21.820]  been seeing Flickr a lot lately since this sort of chaos and
[01:42:21.820 --> 01:42:26.300]  and with the the the NASA launch of Artemis talking about,
[01:42:26.300 --> 01:42:29.500]  you know, innovation and competition there.
[01:42:29.500 --> 01:42:31.820]  The official NASA account photos are on Flickr because
[01:42:31.820 --> 01:42:34.060]  Flickr's got this, you know, the Flickr Foundation where
[01:42:34.060 --> 01:42:36.860]  they're sort of preserving historical photos over time.
[01:42:36.860 --> 01:42:38.460]  And it was just such an interesting thing where I was
[01:42:38.460 --> 01:42:40.220]  like, look at that 20 years in.
[01:42:40.780 --> 01:42:44.460]  This is the place that you know, our our preeminent, you
[01:42:44.460 --> 01:42:47.260]  know, space agency finds is a good home.
[01:42:47.260 --> 01:42:49.500]  But going back to this point about the competition, right?
[01:42:49.500 --> 01:42:53.740]  Like that was a that was a really key point that I think got
[01:42:53.740 --> 01:42:55.900]  lost in his in the Obama's conversation.
[01:42:55.900 --> 01:43:00.620]  But also what was telling was the reaction on Twitter from
[01:43:00.620 --> 01:43:03.340]  Marc Andreessen, who is as powerful a figure as the tech
[01:43:03.340 --> 01:43:07.420]  industry has was Obama's telling you to shut up.
[01:43:07.980 --> 01:43:10.060]  It's literally what he said, right, right?
[01:43:10.060 --> 01:43:14.620]  And again, think of the contrast of a generation ago,
[01:43:14.620 --> 01:43:17.260]  venture capitalists would say we want robust competitive
[01:43:17.260 --> 01:43:17.580]  markets.
[01:43:17.580 --> 01:43:19.420]  We'd like to fund the next Twitter.
[01:43:19.420 --> 01:43:21.900]  If you've got a competitor, Obama is right.
[01:43:21.900 --> 01:43:24.220]  Build that competitor with us, right?
[01:43:24.220 --> 01:43:25.580]  We need more competitive markets.
[01:43:25.580 --> 01:43:27.180]  Who's the who's the radical upstart?
[01:43:27.180 --> 01:43:29.180]  This is what Silicon Valley's narrative was supposed to be.
[01:43:29.740 --> 01:43:31.660]  We are disruptors.
[01:43:31.660 --> 01:43:33.340]  We challenge the status quo.
[01:43:33.340 --> 01:43:34.460]  We make radical things.
[01:43:34.460 --> 01:43:35.180]  We think different.
[01:43:35.180 --> 01:43:37.020]  That's what we are, right?
[01:43:37.020 --> 01:43:42.380]  And instead he hears somebody saying at Stanford, right where
[01:43:42.380 --> 01:43:45.980]  Google and Yahoo and all these things come from at Stanford.
[01:43:45.980 --> 01:43:49.020]  We need to be more competitive and have more dynamic markets
[01:43:49.020 --> 01:43:50.140]  and invent new things.
[01:43:51.180 --> 01:43:53.980]  And he lies and says, this guy's telling you to shut up.
[01:43:54.620 --> 01:43:57.260]  And that is not how it used to go, right?
[01:43:57.260 --> 01:43:57.900]  That's different.
[01:43:57.900 --> 01:44:01.580]  And I think that change is so stark and so obvious that like,
[01:44:01.580 --> 01:44:04.220]  and it's hard because like, I think people process these
[01:44:04.220 --> 01:44:05.260]  things as inherently political.
[01:44:05.260 --> 01:44:06.860]  As soon as you hear Obama's name, you think, oh,
[01:44:06.860 --> 01:44:07.820]  this is a political statement.
[01:44:07.820 --> 01:44:11.580]  And it's like, it is not like, I am a very boring middle-aged
[01:44:11.580 --> 01:44:13.340]  dad who has been a CEO.
[01:44:13.340 --> 01:44:16.700]  I'm not a radical person structurally in what I am in the
[01:44:16.700 --> 01:44:20.620]  world. And yet I'm like, I like that story that I should be
[01:44:20.620 --> 01:44:23.260]  able to be an entrepreneur and be competitive in technology.
[01:44:23.260 --> 01:44:25.420]  And the person who's telling me I don't is the guy who wrote
[01:44:25.420 --> 01:44:28.540]  a political tract and said, we will funnel billions of dollars
[01:44:28.540 --> 01:44:31.100]  to anybody who builds in compliance with our political
[01:44:31.100 --> 01:44:33.100]  tract. And that guy is not Obama.
[01:44:33.100 --> 01:44:34.380]  That guy's Andreessen.
[01:44:35.260 --> 01:44:36.460]  All right, let me take one last break here.
[01:44:36.460 --> 01:44:38.140]  Thank our third and final sponsor of the show.
[01:44:38.140 --> 01:44:41.020]  It is our very good friends, or at least my very good friends
[01:44:41.020 --> 01:44:41.980]  at Squarespace.
[01:44:42.860 --> 01:44:44.220]  Squarespace, you know what that is.
[01:44:44.220 --> 01:44:50.140]  It's the all-in-one platform to build, design, host, update,
[01:44:50.140 --> 01:44:55.020]  post, publish a website, everything from domain name
[01:44:55.020 --> 01:45:00.540]  registration to choosing from untold, uncountable number
[01:45:00.540 --> 01:45:03.500]  of great professionally designed templates that you can
[01:45:03.500 --> 01:45:09.500]  tweak to your heart's content and just all the features
[01:45:09.500 --> 01:45:10.140]  that you can think of.
[01:45:10.140 --> 01:45:13.020]  They have member areas where they make it easy.
[01:45:13.020 --> 01:45:16.060]  If you're a creator to monetize your content and your expertise
[01:45:16.060 --> 01:45:19.020]  in a way that fits your brand with a member area, you can
[01:45:19.020 --> 01:45:24.460]  do, you know, unlock new revenue and do stuff like have
[01:45:24.460 --> 01:45:28.860]  gated content like videos or online courses or newsletters
[01:45:28.860 --> 01:45:32.300]  that are only available to your paying members.
[01:45:32.300 --> 01:45:35.900]  They have their own built-in analytics, which is just a terrific
[01:45:35.900 --> 01:45:39.020]  design, just one of the best analytic designs I've ever seen
[01:45:39.020 --> 01:45:39.900]  for a dashboard.
[01:45:40.860 --> 01:45:42.380]  How much traffic are you getting?
[01:45:42.380 --> 01:45:43.740]  Where is it coming from?
[01:45:43.740 --> 01:45:45.820]  What parts of your site are getting traffic?
[01:45:45.820 --> 01:45:48.700]  Which parts aren't online stores?
[01:45:48.700 --> 01:45:49.980]  You want to host a store?
[01:45:49.980 --> 01:45:53.900]  Squarespace can do everything from having the actual catalog
[01:45:53.900 --> 01:45:58.140]  to doing the actual e-commerce parts of the transaction part
[01:45:58.140 --> 01:45:59.660]  of having an online store.
[01:46:01.420 --> 01:46:01.900]  You name it.
[01:46:01.900 --> 01:46:02.540]  They've got it.
[01:46:03.260 --> 01:46:04.940]  What do you do to find out more?
[01:46:05.900 --> 01:46:09.500]  Go to squarespace.com slash talk show.
[01:46:10.380 --> 01:46:12.540]  You go to squarespace.com slash talk show.
[01:46:12.540 --> 01:46:16.540]  You get a free trial, 30 days, full featured.
[01:46:16.540 --> 01:46:18.620]  Everything you can do at Squarespace, you can do.
[01:46:18.620 --> 01:46:21.420]  There's no watermark on the site that says, oh, you're in
[01:46:21.420 --> 01:46:22.700]  trial mode or something like that.
[01:46:22.700 --> 01:46:23.020]  Nope.
[01:46:23.020 --> 01:46:25.100]  It's the real deal for 30 days.
[01:46:25.100 --> 01:46:28.060]  And then when you're ready to launch, just remember that
[01:46:28.060 --> 01:46:31.900]  same offer code talk show, and you will save 10% off your
[01:46:31.900 --> 01:46:32.620]  first purchase.
[01:46:32.620 --> 01:46:35.020]  When your free trial is up, you can purchase a whole year
[01:46:35.020 --> 01:46:39.820]  at once and save 10% just by going to squarespace.com slash
[01:46:39.820 --> 01:46:40.300]  talk show.
[01:46:43.100 --> 01:46:45.180]  How bad do you think it is at Twitter?
[01:46:45.180 --> 01:46:48.460]  Do you think it's the people I talk to every single person
[01:46:48.460 --> 01:46:49.100]  is leaving.
[01:46:49.100 --> 01:46:50.620]  There's not one person I know.
[01:46:50.620 --> 01:46:52.780]  And I know a lot of people at Twitter.
[01:46:52.780 --> 01:46:54.140]  Well, I used to know a lot of people at Twitter.
[01:46:54.140 --> 01:46:54.860]  Now I know a handful.
[01:46:54.860 --> 01:46:58.860]  There's not one who is saying I'm staying.
[01:46:58.860 --> 01:47:02.300]  And it's funny because even there's people, this is a really
[01:47:02.300 --> 01:47:03.100]  interesting thing.
[01:47:03.100 --> 01:47:05.260]  I know a good number of people there who are like, this is
[01:47:05.260 --> 01:47:05.740]  my job.
[01:47:05.740 --> 01:47:06.380]  This is what I do.
[01:47:06.940 --> 01:47:10.540]  A lot of them had stints at other tech companies, right?
[01:47:10.540 --> 01:47:12.220]  So they worked at Google or they worked at Microsoft or
[01:47:12.220 --> 01:47:14.140]  something, and they're like, this is my stint at Twitter.
[01:47:15.900 --> 01:47:19.660]  And they were not like, I'm somebody who's like very
[01:47:19.660 --> 01:47:21.900]  politically opinionated and has a point of view and like a
[01:47:21.900 --> 01:47:23.740]  very mission driven around when it gets my job.
[01:47:23.740 --> 01:47:24.940]  It's what I do.
[01:47:24.940 --> 01:47:27.260]  They have been radicalized by this.
[01:47:27.900 --> 01:47:31.100]  Like they have come out and been like what they say because
[01:47:31.100 --> 01:47:31.580]  they know me.
[01:47:31.580 --> 01:47:33.980]  They're like all this stuff you've been ranting about all
[01:47:33.980 --> 01:47:34.300]  these years.
[01:47:34.300 --> 01:47:35.020]  Now I get it.
[01:47:35.660 --> 01:47:37.100]  Like there wasn't some opt out.
[01:47:37.100 --> 01:47:40.300]  There wasn't some way to like not think about what is the
[01:47:40.300 --> 01:47:42.300]  political agenda of these guys or what are they saying to
[01:47:42.300 --> 01:47:42.460]  each other?
[01:47:42.460 --> 01:47:43.900]  Because like I used to tune all that stuff out.
[01:47:43.900 --> 01:47:45.500]  Who cares what somebody says about Elon Musk?
[01:47:45.500 --> 01:47:46.860]  Like I just do my job and I'm fine.
[01:47:47.740 --> 01:47:52.060]  And in every case, what galvanized them and what
[01:47:52.060 --> 01:47:55.980]  radicalized them is cruelty to their coworkers.
[01:47:55.980 --> 01:47:59.740]  Like there's nothing more effective at making people
[01:48:00.540 --> 01:48:04.540]  suddenly have a really strong motivator about what they
[01:48:04.540 --> 01:48:05.420]  want to see in the world.
[01:48:05.980 --> 01:48:08.620]  Then them seeing good people harmed, you know, and, and
[01:48:08.620 --> 01:48:10.620]  that's really, really consistently.
[01:48:10.620 --> 01:48:12.380]  And I'm sure you probably hear the same from people talk
[01:48:12.380 --> 01:48:14.620]  to they're like a guest where they're like, you know, I'll
[01:48:14.620 --> 01:48:15.020]  be okay.
[01:48:15.020 --> 01:48:18.060]  I'll figure it out, but I cannot believe my, you know,
[01:48:18.060 --> 01:48:21.420]  what I hear is like my pregnant coworker is in, you know,
[01:48:21.420 --> 01:48:22.060]  disarray.
[01:48:22.060 --> 01:48:23.500]  Like they don't know if they're, they're going to be able
[01:48:23.500 --> 01:48:24.220]  to hold it together.
[01:48:24.220 --> 01:48:28.940]  I hear a lot from, you know, being of Indian descent, a lot
[01:48:28.940 --> 01:48:32.940]  of Indian workers who are here on visas and they're being
[01:48:32.940 --> 01:48:36.380]  in America is contingent on them having a job and their
[01:48:36.380 --> 01:48:37.260]  job is into rest.
[01:48:37.260 --> 01:48:39.660]  And they don't know, they said, they're like, I don't know
[01:48:40.300 --> 01:48:41.580]  what's going to happen day to day.
[01:48:42.140 --> 01:48:44.700]  And in many cases, their family back home in India is
[01:48:44.700 --> 01:48:46.380]  dependent on them sending money home to them.
[01:48:47.100 --> 01:48:50.620]  And so the idea of like your entire, an immigration is a
[01:48:50.620 --> 01:48:51.500]  brutal process.
[01:48:51.500 --> 01:48:53.180]  It's a terrifying process.
[01:48:53.180 --> 01:48:56.460]  And the idea of all that being put at risk, even though you
[01:48:56.460 --> 01:48:59.980]  did your job, even though you have, in some cases, a skillset
[01:48:59.980 --> 01:49:01.020]  that they say they want.
[01:49:03.660 --> 01:49:05.100]  Well, it's just unfathomable.
[01:49:05.100 --> 01:49:09.340]  It says a lot too, that we're obviously, I mean, I'm not
[01:49:09.340 --> 01:49:13.100]  Warren Buffett here giving amazing insight into the market,
[01:49:13.100 --> 01:49:17.420]  but we're obviously in a moment where the entire industry
[01:49:17.420 --> 01:49:18.380]  is tightening, right?
[01:49:18.380 --> 01:49:18.780]  Do you?
[01:49:18.780 --> 01:49:19.740]  Yeah, yeah, for sure.
[01:49:19.740 --> 01:49:21.900]  It's a button down moment.
[01:49:21.900 --> 01:49:24.780]  Successful companies are laying people off.
[01:49:24.780 --> 01:49:27.580]  Stripe is a very successful company and they had it laid
[01:49:27.580 --> 01:49:30.780]  off, Facebook laid off 11.
[01:49:30.780 --> 01:49:33.100]  I know Facebook has had a bad couple of years, but they're
[01:49:33.100 --> 01:49:36.300]  still very profitable, laid off 11,000 people, which is
[01:49:36.300 --> 01:49:41.100]  more than all of Twitter, all of Twitter, you know, and
[01:49:41.100 --> 01:49:43.260]  Facebook laid off 11,000 people.
[01:49:43.820 --> 01:49:48.380]  And I mean, Amazon just made a show of 10,000 people, a lot
[01:49:48.380 --> 01:49:51.100]  of, and it's not like, you know, although in fairness, Amazon
[01:49:51.100 --> 01:49:53.580]  will turn 10,000 people in that time period anyway, so they
[01:49:53.580 --> 01:49:55.260]  might just be taking credit for what was going to happen.
[01:49:55.820 --> 01:50:00.620]  Well, maybe, but it sounds like some of the people at Amazon
[01:50:00.620 --> 01:50:01.900]  are in the product division.
[01:50:01.900 --> 01:50:04.940]  Like they're going to sort of get out of the business of
[01:50:04.940 --> 01:50:06.140]  making a bunch of their own.
[01:50:07.420 --> 01:50:09.260]  I don't think they're going to entirely abandon it, but I
[01:50:09.260 --> 01:50:13.660]  think that we're going to see fewer, you know, fire, whatever
[01:50:13.660 --> 01:50:16.220]  or Alexa devices.
[01:50:16.220 --> 01:50:19.660]  Hopefully I didn't set off anybody's device by saying it,
[01:50:19.660 --> 01:50:24.700]  but, you know, there's engineering tightening going on
[01:50:24.700 --> 01:50:28.940]  there, but the bottom line though, is it is not, if you
[01:50:28.940 --> 01:50:32.140]  didn't get laid off at Twitter, if you were still there and
[01:50:32.140 --> 01:50:36.460]  you're choosing to leave on your own, you're doing it a time
[01:50:36.460 --> 01:50:40.140]  when it's probably the hardest it's been in five years or
[01:50:40.140 --> 01:50:43.900]  will be in the foreseeable future to find another job,
[01:50:43.900 --> 01:50:47.420]  because the places that are, this is a tough moment, right?
[01:50:47.420 --> 01:50:52.060]  Even Apple is not laying anybody off, but made a show of
[01:50:52.060 --> 01:50:55.820]  mentioning on their quarterly call last week or 10 days ago
[01:50:55.820 --> 01:50:58.940]  that they are instituting a higher and effective hiring
[01:50:58.940 --> 01:51:00.860]  freeze, you know, so they're not hiring.
[01:51:00.860 --> 01:51:03.660]  Yeah, everybody's either frozen or going slow or whatever
[01:51:03.660 --> 01:51:04.860]  at the best case.
[01:51:04.860 --> 01:51:08.700]  Whereas I don't even just a year or two ago, really, or,
[01:51:08.700 --> 01:51:12.380]  you know, certainly for a while the industry was in a hiring
[01:51:12.380 --> 01:51:17.580]  craze, right? It was, you know, and if you had the talent
[01:51:17.580 --> 01:51:21.580]  and even better, you know, a resume that had a couple of
[01:51:21.580 --> 01:51:26.460]  good, you know, well-known companies on it, the ability to
[01:51:26.460 --> 01:51:29.580]  jump ship and go, you know, go from Twitter and land a new
[01:51:29.580 --> 01:51:31.420]  job at Google or something like that.
[01:51:31.420 --> 01:51:31.820]  Right, right, right.
[01:51:31.820 --> 01:51:34.540]  You can just sort of, yeah, switch gears pretty easily in
[01:51:34.540 --> 01:51:35.820]  most technical roles.
[01:51:35.820 --> 01:51:37.260]  Whereas now it's the opposite.
[01:51:37.260 --> 01:51:39.740]  It is probably the, you know, one of the worst times we'll
[01:51:39.740 --> 01:51:43.260]  see, hopefully, to do that. Nobody would do that lately.
[01:51:44.300 --> 01:51:46.380]  And I do think that's the part that I find.
[01:51:46.380 --> 01:51:50.780]  So I just did not, I don't like Elon Musk.
[01:51:50.780 --> 01:51:51.580]  I'm not a fan.
[01:51:51.580 --> 01:51:53.260]  I don't, I've never followed his Twitter.
[01:51:53.260 --> 01:51:54.700]  I think his jokes are stupid.
[01:51:56.220 --> 01:51:59.020]  The guy's bad at Twitter, which I think should be relevant,
[01:51:59.020 --> 01:52:01.420]  but that's, it's a side point.
[01:52:01.420 --> 01:52:03.180]  I mean, we're talking about thousands of people going
[01:52:03.180 --> 01:52:05.500]  through duress, but also guy's a shitty tweeter.
[01:52:05.500 --> 01:52:10.060]  Sorry.
[01:52:10.060 --> 01:52:14.620]  I'm like, you know, I'm actually stepping on your toes
[01:52:14.620 --> 01:52:15.980]  here because this is your job.
[01:52:15.980 --> 01:52:18.620]  I don't have employees, but this is literally your job.
[01:52:18.620 --> 01:52:21.900]  I think you will agree with me wholeheartedly that for any
[01:52:21.900 --> 01:52:29.020]  company in tech, the single most important thing is acquiring
[01:52:29.020 --> 01:52:31.420]  and holding talent.
[01:52:31.420 --> 01:52:33.180]  It is inarguable.
[01:52:33.180 --> 01:52:34.140]  It's the hardest thing.
[01:52:34.140 --> 01:52:35.340]  It's the hardest thing.
[01:52:35.340 --> 01:52:40.220]  And, and, you know, and also in a great way, tech workers
[01:52:40.220 --> 01:52:42.940]  historically have been amongst the most empowered, like coders
[01:52:42.940 --> 01:52:45.980]  have been amongst the most empowered workers of recent years
[01:52:45.980 --> 01:52:48.700]  and in a great way, because they have this valuable set of
[01:52:48.700 --> 01:52:52.940]  skills and there is such demand and they're starting to seize
[01:52:52.940 --> 01:52:54.860]  that power, which I think is incredible.
[01:52:54.860 --> 01:52:57.660]  But this is that, I think this is also part of it is that
[01:52:57.660 --> 01:53:00.940]  amongst Musk and his, his cohort of, of, you know, the sort
[01:53:00.940 --> 01:53:04.940]  of these insiders that I keep talking about, they really want
[01:53:04.940 --> 01:53:06.540]  to crush that worker power.
[01:53:06.540 --> 01:53:10.060]  They really want to crush that sense that of solidarity and
[01:53:10.060 --> 01:53:12.220]  organizing that's happening everywhere.
[01:53:12.220 --> 01:53:15.820]  And so this is setting an example of like, if this is the,
[01:53:15.820 --> 01:53:18.620]  what they would say, quote unquote, wokest workforce, then
[01:53:18.620 --> 01:53:23.100]  we have to crush them the most and set this tone that these
[01:53:23.100 --> 01:53:27.020]  people can, and, and, you know, I, I do think, well, I mean,
[01:53:27.020 --> 01:53:29.180]  I think actually in the fullness of time, there will be
[01:53:29.180 --> 01:53:32.780]  nothing that more galvanizes the union movement and the tech
[01:53:32.780 --> 01:53:35.100]  industry than Elon Musk's mismanagement of Twitter.
[01:53:35.660 --> 01:53:36.300]  Hmm.
[01:53:36.300 --> 01:53:40.220]  I wonder, I wouldn't, it could have that effect.
[01:53:40.220 --> 01:53:42.620]  I think that in our field, you don't, you know, I think what
[01:53:42.620 --> 01:53:45.580]  we're seeing, you know, with, with the people who remain at
[01:53:45.580 --> 01:53:50.460]  Twitter leaving on their own, that you don't need a union to
[01:53:50.460 --> 01:53:51.180]  organize.
[01:53:51.180 --> 01:53:51.740]  Right.
[01:53:51.740 --> 01:53:55.740]  I mean, this isn't me arguing against, against a tech company
[01:53:55.740 --> 01:53:58.380]  like Twitter unionizing the workforce, but I'm just saying
[01:53:59.740 --> 01:54:00.140]  part of it.
[01:54:00.140 --> 01:54:01.660]  Well, thanks for everybody that can't do it.
[01:54:01.660 --> 01:54:01.820]  Right.
[01:54:01.820 --> 01:54:05.340]  I mean, cause part of it is one of the, some of the groups
[01:54:05.340 --> 01:54:10.220]  that he targeted most, like content moderation and, and some
[01:54:10.220 --> 01:54:12.460]  of the human rights groups and all that stuff that were inside
[01:54:12.460 --> 01:54:13.980]  the organization, none of those are coders.
[01:54:13.980 --> 01:54:16.060]  So they don't have that same sort of power, right?
[01:54:16.060 --> 01:54:18.460]  But they do, they do have the ability, but the one thing
[01:54:18.460 --> 01:54:20.860]  that's different in today's world, especially at a company
[01:54:20.860 --> 01:54:23.980]  like Twitter that has, you know, is a communication company,
[01:54:23.980 --> 01:54:26.140]  people know how to talk to each other, right?
[01:54:26.140 --> 01:54:29.900]  That then people within Twitter are communicating and they
[01:54:29.900 --> 01:54:33.900]  can organize in an ad hoc fashion in a way that wasn't
[01:54:33.900 --> 01:54:37.260]  possible generations ago, right?
[01:54:37.260 --> 01:54:39.900]  Like the only way, the only way that people who worked at
[01:54:39.900 --> 01:54:43.180]  General Motors could organize together on the factory floor
[01:54:43.180 --> 01:54:45.740]  was through an official organization like a union.
[01:54:45.740 --> 01:54:48.780]  There was no, there wasn't a Slack, you know, that they
[01:54:48.780 --> 01:54:50.460]  could talk to each other on.
[01:54:50.460 --> 01:54:53.020]  Well, yeah, except, well, we've seen with Twitter, right?
[01:54:53.020 --> 01:54:55.820]  Slack is a tool that's owned and controlled by the company
[01:54:55.820 --> 01:54:58.860]  and therefore they can monitor and surveil and fire you for
[01:54:58.860 --> 01:55:00.300]  what you say in Slack, right?
[01:55:00.300 --> 01:55:00.780]  And it's there.
[01:55:00.780 --> 01:55:02.460]  The other thing is just the legal protections, right?
[01:55:02.460 --> 01:55:08.380]  Like we have the NLRB, we have labor laws, the API for lack
[01:55:08.380 --> 01:55:12.460]  of a less technical analogy, the API for accessing those
[01:55:12.460 --> 01:55:14.220]  protections to labor is organized.
[01:55:14.780 --> 01:55:18.140]  And so I think, you know, I'm agnostic as to like the
[01:55:18.140 --> 01:55:19.100]  specific implications.
[01:55:19.100 --> 01:55:21.580]  Like I look, I think it's telling, for example, the, the
[01:55:21.580 --> 01:55:24.700]  Amazon union in Staten Island is an independent org.
[01:55:24.700 --> 01:55:27.500]  It's not affiliated with any, it's not like SEIU or whatever.
[01:55:27.500 --> 01:55:30.940]  It's like an independent org that, you know, the workers
[01:55:30.940 --> 01:55:31.420]  put together.
[01:55:31.420 --> 01:55:36.220]  And I think that that's a really sensible and modern and
[01:55:36.220 --> 01:55:37.100]  dynamic way to do it.
[01:55:37.100 --> 01:55:37.900]  And so that makes sense.
[01:55:37.900 --> 01:55:41.900]  And again, that's a good example where like the, the, the,
[01:55:41.900 --> 01:55:44.220]  the myth of Silicon Valley that I grew up on would have
[01:55:44.220 --> 01:55:46.620]  been like, oh, you independently organized major own
[01:55:46.620 --> 01:55:48.700]  institution or were able to transform one of the biggest
[01:55:48.700 --> 01:55:52.220]  incumbent companies in the world by doing so, like that's
[01:55:52.220 --> 01:55:52.940]  disruptive.
[01:55:52.940 --> 01:55:53.500]  That's great.
[01:55:54.700 --> 01:55:57.180]  But that's not the reaction to Chris Smalls and the team
[01:55:57.180 --> 01:55:59.500]  in Staten Island of like, wow, look at what technical
[01:55:59.500 --> 01:56:02.380]  innovators you are, you know, Bezos is like, we have to crush
[01:56:02.380 --> 01:56:05.260]  you under our heel or I guess a chassis and, and, and sort
[01:56:05.260 --> 01:56:07.820]  of similarly, I think of this as like, I don't, I'm agnostic
[01:56:07.820 --> 01:56:11.420]  as to what structure it takes at Twitter, but I think the
[01:56:11.420 --> 01:56:13.420]  key takeaway people are going to have is we got to stick
[01:56:13.420 --> 01:56:16.540]  together because they will try and pick us off and wear us
[01:56:16.540 --> 01:56:16.860]  down.
[01:56:16.860 --> 01:56:17.340]  If we don't.
[01:56:19.100 --> 01:56:23.020]  I'm just a flabbergasted at how obviously stupid it is, you
[01:56:23.020 --> 01:56:25.580]  know, and product decisions can be reversed.
[01:56:25.580 --> 01:56:29.260]  So I think his whole, the whole, we, you mentioned the whole
[01:56:29.260 --> 01:56:32.060]  blue check mark thing and being worried about it and, and
[01:56:32.700 --> 01:56:35.900]  taking that, even giving a shit about it, it's such a corny
[01:56:35.900 --> 01:56:36.940]  thing to care about.
[01:56:36.940 --> 01:56:38.380]  It really is.
[01:56:38.380 --> 01:56:40.780]  I always thought, I mean, I've heard people, you know, call
[01:56:40.780 --> 01:56:43.260]  it, they talk about people who have them being the blue
[01:56:43.260 --> 01:56:47.820]  checks and I think it's so silly and I don't, I have one
[01:56:47.820 --> 01:56:51.820]  cause you know, I write the site and you know, I got mine
[01:56:51.820 --> 01:56:54.460]  automatically after Matt Honan was hacked a couple of years
[01:56:54.460 --> 01:56:57.020]  ago and they just found all the people who were like Matt
[01:56:57.020 --> 01:56:57.740]  Honan.
[01:56:57.740 --> 01:57:00.620]  And I, you know, I fit that profile and they gave us, they
[01:57:00.620 --> 01:57:03.420]  verified us so that our accounts couldn't be hijacked
[01:57:03.420 --> 01:57:06.540]  because they realize, Oh, people, you know, of my profile
[01:57:06.540 --> 01:57:09.100]  might be of, you know, it'd be a juicy targeted.
[01:57:09.100 --> 01:57:12.300]  It would be a juicy target to take my Twitter account, even
[01:57:12.300 --> 01:57:15.180]  if you only have it for six hours and tweet a bunch of
[01:57:15.180 --> 01:57:17.820]  crypto non-censors or whatever the scam of the day is.
[01:57:19.180 --> 01:57:22.460]  But you can make a bad decision, a product decision, and
[01:57:22.460 --> 01:57:23.740]  then you can reverse it.
[01:57:23.740 --> 01:57:28.220]  And that is the sort of thing that I actually think is what
[01:57:29.340 --> 01:57:32.300]  had, had stagnated Twitter.
[01:57:32.300 --> 01:57:35.020]  You know, that their, their fear of making decisions, you
[01:57:35.020 --> 01:57:38.620]  know, like the years they spent talking about an edit
[01:57:38.620 --> 01:57:44.140]  button for editing a tweet, you know, then launch it.
[01:57:44.140 --> 01:57:45.580]  They should have launched it years ago.
[01:57:45.580 --> 01:57:49.180]  And then if problems showed up with it, Oh, well then change
[01:57:49.180 --> 01:57:51.340]  it, you know, you can always take it back.
[01:57:51.340 --> 01:57:53.260]  You can try things, try things.
[01:57:53.260 --> 01:57:55.660]  If they don't work, here's a, here's a counter example.
[01:57:55.660 --> 01:57:58.060]  They had fleets, which was not a wild success, but they,
[01:57:58.060 --> 01:57:58.860]  they built a platform.
[01:57:58.860 --> 01:57:59.900]  It is what it is.
[01:57:59.900 --> 01:58:03.500]  And then within Silicon Valley and, and again, it sort of
[01:58:03.500 --> 01:58:06.940]  introduced in Horowitz cohort, they got obsessed with
[01:58:06.940 --> 01:58:07.660]  clubhouse.
[01:58:07.660 --> 01:58:08.700]  We're all going to clubhouse.
[01:58:09.420 --> 01:58:11.420]  It was a big, big hype bubble for a while, especially
[01:58:11.420 --> 01:58:12.620]  even the web three folks.
[01:58:14.220 --> 01:58:19.180]  And Twitter pivoted really quickly and built spaces and
[01:58:19.180 --> 01:58:20.700]  killed that category.
[01:58:20.700 --> 01:58:21.580]  Like this still exists.
[01:58:21.580 --> 01:58:22.220]  People do spaces.
[01:58:22.220 --> 01:58:23.580]  I like a lot of them that I joined in.
[01:58:23.580 --> 01:58:25.660]  It's kind of like live podcast kind of feel to it.
[01:58:26.220 --> 01:58:30.380]  And, but even if it's not a huge product, absolutely, they
[01:58:30.380 --> 01:58:32.540]  ripped the market out of the hands of clubhouse.
[01:58:32.540 --> 01:58:34.620]  Like they sucked all the air out of the room and instantly
[01:58:35.820 --> 01:58:38.620]  you remember, I mean, we're old, you know, but remember
[01:58:38.620 --> 01:58:42.620]  chat lines, you, you, you would before, you know, this was
[01:58:42.620 --> 01:58:45.500]  before the computers could handle anything as complicated
[01:58:45.500 --> 01:58:47.420]  as audio, but you can call man days.
[01:58:47.420 --> 01:58:51.260]  You could call like a local phone number and you know, and,
[01:58:51.260 --> 01:58:54.860]  and up to 50 people or a hundred people or whatever, you
[01:58:54.860 --> 01:58:57.340]  know, some capability, a hundred people could be on the
[01:58:57.340 --> 01:58:59.580]  chat line at once talking to each other in a group.
[01:58:59.580 --> 01:59:02.060]  And it was, you know, I wasn't really into it.
[01:59:02.060 --> 01:59:04.620]  And of course, you know, you can predict the way a lot of
[01:59:04.620 --> 01:59:08.620]  them went and which sort of things people chose to talk
[01:59:08.620 --> 01:59:09.660]  about anonymously.
[01:59:10.620 --> 01:59:11.660]  But people enjoyed it.
[01:59:11.660 --> 01:59:12.540]  It was a thing a bit.
[01:59:12.540 --> 01:59:15.180]  And, you know, clubhouse had that feel.
[01:59:15.180 --> 01:59:15.580]  I get it.
[01:59:15.580 --> 01:59:17.180]  I was, you know, I've done some.
[01:59:17.180 --> 01:59:21.740]  I, I, but here's, here's the point.
[01:59:21.740 --> 01:59:26.540]  Twitter shipped that feature really quickly, really
[01:59:26.540 --> 01:59:28.380]  effectively and won the market.
[01:59:28.380 --> 01:59:31.340]  Yes, this contradicts the narrative that they can't do
[01:59:31.340 --> 01:59:32.540]  Musk's painting.
[01:59:32.540 --> 01:59:35.340]  And part of it is like, they can't acknowledge that without
[01:59:35.340 --> 01:59:37.820]  acknowledging that clubhouse is a failure, despite having
[01:59:38.700 --> 01:59:42.220]  as much possible backing of, of, you know, again, injuries
[01:59:42.220 --> 01:59:44.460]  and horror, which in that cohort as is possible.
[01:59:44.460 --> 01:59:46.860]  I mean, they went all, all in right.
[01:59:46.860 --> 01:59:49.580]  Money, attention, time, their selves, like they're, you know,
[01:59:49.580 --> 01:59:52.460]  you have the VCs themselves showing up on there every night
[01:59:52.460 --> 01:59:53.900]  to try and prop the thing up.
[01:59:53.900 --> 01:59:56.940]  And despite that got, you know, their butts handed to them
[01:59:56.940 --> 01:59:59.980]  by the culture at Twitter that allegedly can't ship anything.
[01:59:59.980 --> 02:00:00.480]  Right.
[02:00:03.340 --> 02:00:08.460]  The one thing that I did, I just see that there's no product
[02:00:08.460 --> 02:00:12.060]  decision that Elon Musk could mandate that would permanently
[02:00:12.060 --> 02:00:14.860]  wreck Twitter because it could always be reversed.
[02:00:14.860 --> 02:00:17.660]  Now there are product decisions or content moderation
[02:00:17.660 --> 02:00:20.380]  decisions, which is, which to me for Twitter is a product
[02:00:20.380 --> 02:00:20.940]  decision, right?
[02:00:20.940 --> 02:00:22.060]  The content moderation.
[02:00:22.780 --> 02:00:24.860]  Nilay Patel wrote, I think that was the headline.
[02:00:24.860 --> 02:00:28.300]  It is, that is their product or it's the product of all of
[02:00:28.300 --> 02:00:28.940]  these networks.
[02:00:29.660 --> 02:00:32.300]  But being unable to hire and retain people is not a bug
[02:00:32.300 --> 02:00:32.940]  you could undo.
[02:00:32.940 --> 02:00:34.460]  It is not it.
[02:00:34.460 --> 02:00:39.340]  And the loss of institutional knowledge cannot be recovered
[02:00:39.340 --> 02:00:40.460]  on a dime.
[02:00:40.460 --> 02:00:44.300]  But in longer term, being a place where talented people
[02:00:44.300 --> 02:00:47.020]  don't want to work and where the people who are left don't
[02:00:47.020 --> 02:00:50.140]  want to stay, you cannot recover from.
[02:00:50.140 --> 02:00:51.420]  The well is poisoned.
[02:00:51.420 --> 02:00:52.140]  The well is poisoned.
[02:00:52.700 --> 02:00:56.140]  Trust me, as somebody who, you know, as we talked about
[02:00:56.140 --> 02:00:59.020]  an hour ago, I was optimistic about Twitter.
[02:00:59.020 --> 02:01:02.700]  I, my pessimism about Twitter has nothing to do with the
[02:01:03.340 --> 02:01:06.780]  product decisions that Elon Musk claims to still be wanting
[02:01:06.780 --> 02:01:08.540]  to make or has made so far.
[02:01:08.540 --> 02:01:13.420]  It is entirely the pessimism, the despair over what he has
[02:01:13.420 --> 02:01:18.460]  done to their the staff and the workers in the culture.
[02:01:18.460 --> 02:01:18.940]  Right.
[02:01:18.940 --> 02:01:21.820]  And again, they obviously needed to lay off a lot of people.
[02:01:23.500 --> 02:01:26.700]  I know that from my people I know who work at Twitter that
[02:01:26.700 --> 02:01:29.100]  they were vastly overstaffed and that there were a lot of
[02:01:29.100 --> 02:01:31.660]  people who really didn't do much.
[02:01:31.660 --> 02:01:35.580]  They had an entire team whose the team's job was to do the
[02:01:35.580 --> 02:01:39.660]  search text box, not search, not a search team, just the
[02:01:39.660 --> 02:01:42.700]  text box on the website where you type what you want to
[02:01:42.700 --> 02:01:43.180]  search for.
[02:01:43.180 --> 02:01:45.180]  There was a whole team behind that.
[02:01:45.180 --> 02:01:51.820]  That's almost comically in violation of Brooks's law.
[02:01:53.020 --> 02:01:53.500]  Maybe.
[02:01:53.500 --> 02:01:53.980]  I don't know.
[02:01:53.980 --> 02:01:56.860]  I mean, you know, I've built some text boxes in my day.
[02:01:59.740 --> 02:02:01.900]  I don't know anybody who's worked at Twitter who doesn't
[02:02:01.900 --> 02:02:03.340]  think that they were overstaffed.
[02:02:03.340 --> 02:02:04.860]  I agree.
[02:02:04.860 --> 02:02:07.260]  Everybody says Twitter's overstaffed and everybody says
[02:02:07.260 --> 02:02:08.940]  where they're overstaffed is that team over there.
[02:02:10.460 --> 02:02:11.900]  That's been true.
[02:02:11.900 --> 02:02:14.300]  That literally I literally was the feeling at Twitter when
[02:02:14.300 --> 02:02:15.420]  there's 20 people, right?
[02:02:16.220 --> 02:02:19.340]  So I just say this again with nothing but love and
[02:02:19.340 --> 02:02:20.460]  appreciation for what they've all done.
[02:02:20.460 --> 02:02:22.620]  But like, you know, like I spoke at the first Twitter
[02:02:22.620 --> 02:02:23.740]  developer conference, right?
[02:02:23.740 --> 02:02:26.460]  And chirp, this was like 2011.
[02:02:26.460 --> 02:02:29.580]  And actually, this is a sidebar, but it's such a great
[02:02:29.580 --> 02:02:31.900]  story because nothing epitomizes Twitter better.
[02:02:31.900 --> 02:02:34.140]  In the early days, Twitter didn't have its own app.
[02:02:34.140 --> 02:02:37.180]  Just to recap, I know you know this, but Twitter didn't have
[02:02:37.180 --> 02:02:37.980]  its own app.
[02:02:37.980 --> 02:02:40.460]  And so there were a lot of apps in the app store that all
[02:02:40.460 --> 02:02:41.980]  said you can post on Twitter using this.
[02:02:42.540 --> 02:02:44.220]  And it was confusing.
[02:02:44.220 --> 02:02:45.180]  Some of them had great features.
[02:02:45.180 --> 02:02:46.140]  Some of them were terrible.
[02:02:47.020 --> 02:02:50.220]  And so Twitter, probably rightfully from a strategy
[02:02:50.220 --> 02:02:53.980]  standpoint, decided we're going to make our own official
[02:02:53.980 --> 02:02:54.700]  apps called Twitter.
[02:02:54.700 --> 02:02:56.460]  Nobody else can call their app Twitter.
[02:02:56.460 --> 02:02:58.460]  And we're going to build them for Android and iOS because
[02:02:58.460 --> 02:02:59.340]  we want people to use it.
[02:03:00.380 --> 02:03:04.620]  And they decided to announce this on the eve of their first
[02:03:04.620 --> 02:03:06.860]  ever developer conference where every developer in the
[02:03:06.860 --> 02:03:09.580]  world who had built a client for Twitter would be in the
[02:03:09.580 --> 02:03:12.460]  room or at least following along intently.
[02:03:12.460 --> 02:03:13.180]  Absolutely.
[02:03:13.180 --> 02:03:15.180]  Or watching with rapt attention.
[02:03:15.180 --> 02:03:18.220]  And they opened literally like the thing they set themselves
[02:03:18.220 --> 02:03:21.260]  up for was we're just going to knife all of you in the back.
[02:03:21.260 --> 02:03:22.380]  Just wanted to set that up.
[02:03:22.380 --> 02:03:24.140]  That's the starting point.
[02:03:24.140 --> 02:03:25.420]  All right, now let's start the show.
[02:03:26.060 --> 02:03:28.060]  I have never seen anything like it in my life.
[02:03:28.060 --> 02:03:29.900]  Like it was and I had to speak at this thing.
[02:03:29.900 --> 02:03:31.660]  I was like a development student.
[02:03:31.660 --> 02:03:33.020]  We did an analytics app.
[02:03:33.020 --> 02:03:38.060]  I did with Gino Trapani and we were and I was like, I got
[02:03:38.060 --> 02:03:38.860]  to follow that.
[02:03:38.860 --> 02:03:40.380]  Like, you got to be kidding me.
[02:03:40.380 --> 02:03:42.540]  Like you just told all these people, like, we are eating
[02:03:42.540 --> 02:03:43.100]  your lunch.
[02:03:43.100 --> 02:03:43.580]  Go home.
[02:03:44.460 --> 02:03:45.180]  It was incredible.
[02:03:45.180 --> 02:03:46.140]  And I just was like that.
[02:03:46.140 --> 02:03:48.140]  And at the time, like Twitter was still young enough that
[02:03:48.140 --> 02:03:52.220]  you didn't know that this would be, you know, a harbinger
[02:03:52.220 --> 02:03:55.500]  of things to come in terms of this issue over the years,
[02:03:55.500 --> 02:03:56.780]  especially for developers.
[02:03:56.780 --> 02:03:59.020]  But it just felt like now in retrospect, I'm like, oh,
[02:03:59.020 --> 02:04:01.180]  that's like the moment Twitter became Twitter.
[02:04:01.180 --> 02:04:03.500]  Because then immediately after that, like being on stage
[02:04:03.500 --> 02:04:07.020]  for that, I went backstage and will.i.am for the Black Eyed
[02:04:07.020 --> 02:04:09.100]  Peas was there as a developer conference.
[02:04:09.100 --> 02:04:10.220]  And I said, sure, of course.
[02:04:10.220 --> 02:04:10.720]  Why not?
[02:04:11.820 --> 02:04:12.700]  Yeah, that makes sense.
[02:04:14.380 --> 02:04:16.540]  Yeah, let's get it started.
[02:04:16.540 --> 02:04:16.940]  All right.
[02:04:16.940 --> 02:04:18.700]  So where do we think Twitter is going?
[02:04:18.700 --> 02:04:24.380]  We think I think I was on this line of thinking, and now
[02:04:24.380 --> 02:04:27.180]  you could more or less convince me over the course of the
[02:04:27.180 --> 02:04:28.860]  show that I'm never wrong about Twitter.
[02:04:28.860 --> 02:04:29.820]  I got to tell you, I hate it.
[02:04:30.460 --> 02:04:33.340]  It's a horrible curse that I actually can always predict
[02:04:33.340 --> 02:04:34.700]  what's going to happen, and it's horrible.
[02:04:34.700 --> 02:04:38.460]  But that fundamentally, the company is now on a perhaps
[02:04:38.460 --> 02:04:42.460]  irrevocable sunken.
[02:04:43.420 --> 02:04:45.500]  There's some kind of death spiral going on.
[02:04:45.500 --> 02:04:47.340]  I don't think Twitter ceases to exist.
[02:04:47.340 --> 02:04:49.340]  The bird is going to be around the logo around.
[02:04:49.340 --> 02:04:50.060]  There'll be an app.
[02:04:50.620 --> 02:04:54.460]  But in terms of its cultural relevance and its importance
[02:04:54.460 --> 02:04:57.660]  and centrality to the media and political ecospheres, I
[02:04:57.660 --> 02:05:00.940]  don't think that you can recover that because I think one
[02:05:00.940 --> 02:05:05.660]  so we'll sort of say we're talking now in mid November 22.
[02:05:06.620 --> 02:05:09.820]  I think within the next 90 days, you're going to have a
[02:05:09.820 --> 02:05:16.940]  massive downtime outage or instability on the platform,
[02:05:16.940 --> 02:05:18.540]  like the likes of which we haven't seen since the
[02:05:18.540 --> 02:05:19.260]  Failwhale base.
[02:05:21.580 --> 02:05:25.340]  Or some kind of catastrophic exposure of DMs through.
[02:05:25.340 --> 02:05:26.380]  That's the other thing I was going to say.
[02:05:26.380 --> 02:05:29.500]  I think people can't conceive of like there was that moment
[02:05:29.500 --> 02:05:31.180]  a couple of years ago, people seem to have already forgotten
[02:05:31.180 --> 02:05:35.580]  about where all of the verified accounts got theoretically
[02:05:35.580 --> 02:05:35.980]  at risk.
[02:05:35.980 --> 02:05:38.780]  And so they shut them all off from being able to post and
[02:05:38.780 --> 02:05:40.300]  all these big accounts got hacked.
[02:05:41.260 --> 02:05:43.660]  And that was like when they had a lot of teams working on
[02:05:43.660 --> 02:05:44.060]  this stuff.
[02:05:44.860 --> 02:05:50.460]  So with nobody at the wheel, the idea of, say, 10 million
[02:05:50.460 --> 02:05:53.180]  accounts having all of their direct messages dumped due to
[02:05:53.180 --> 02:05:57.740]  a security bug or a really, really major account getting
[02:05:57.740 --> 02:06:00.460]  taken over in ways that people are not a bunch of kids that
[02:06:00.460 --> 02:06:04.780]  immediately tweet out cryptocurrency spam, but instead
[02:06:04.780 --> 02:06:08.060]  are deliberately doing credible misinformation.
[02:06:09.340 --> 02:06:12.220]  These are attack vectors that we haven't reckoned with in
[02:06:12.220 --> 02:06:13.020]  any major platform.
[02:06:13.020 --> 02:06:14.540]  We've never seen this kind of vulnerability.
[02:06:14.540 --> 02:06:16.940]  And then that's all if the thing stays running.
[02:06:18.700 --> 02:06:21.820]  It's not at all unlikely that you just have one thing,
[02:06:21.820 --> 02:06:25.740]  dusty old server in the corner that falls over because
[02:06:25.740 --> 02:06:30.860]  computers love to fail and all of a sudden you've got the
[02:06:30.860 --> 02:06:34.860]  guy who knows what box to kick doesn't work there anymore.
[02:06:35.500 --> 02:06:40.220]  And Twitter is not exactly famous for having a very simple
[02:06:40.220 --> 02:06:43.660]  diagram of how the back end actually works.
[02:06:43.660 --> 02:06:44.300]  Right, right.
[02:06:44.300 --> 02:06:46.140]  Yes, this is a very clean architecture diagram.
[02:06:46.140 --> 02:06:48.380]  Like, oh, you simply push the reset button here, right?
[02:06:48.380 --> 02:06:48.780]  Oh, yeah.
[02:06:48.780 --> 02:06:50.300]  Just let me stand in front of the whiteboard here.
[02:06:50.300 --> 02:06:51.820]  It'll take me about 30 seconds.
[02:06:51.820 --> 02:06:53.180]  You got this and you got that.
[02:06:53.180 --> 02:06:54.300]  And then this one goes here.
[02:06:54.300 --> 02:06:57.180]  And then when you make a legendarily complex architecture,
[02:06:57.180 --> 02:06:59.740]  the hardest one of the hardest problems in computer science
[02:06:59.740 --> 02:07:01.020]  is getting the tweets out.
[02:07:01.020 --> 02:07:06.060]  And everybody who knew about it for sure is gone.
[02:07:06.060 --> 02:07:09.180]  And everybody who remains is got one foot out the door or
[02:07:09.180 --> 02:07:10.860]  is terrified.
[02:07:10.860 --> 02:07:13.500]  So that's like a real that thing.
[02:07:14.700 --> 02:07:19.100]  Like I said, I think next 90 days is going to start.
[02:07:19.100 --> 02:07:21.420]  And then after that, the question is like, what happens?
[02:07:21.420 --> 02:07:24.940]  It's kind of like if you've ever been on a bike or a motorcycle,
[02:07:24.940 --> 02:07:26.700]  it starts to wobble, right?
[02:07:26.700 --> 02:07:29.340]  Like you got like a real short window where you got to get
[02:07:29.340 --> 02:07:32.540]  it back up on two wheels or the wobble gets worse and worse
[02:07:32.540 --> 02:07:32.940]  and worse.
[02:07:33.500 --> 02:07:36.940]  And that's the question is like, how bad is the wobble after
[02:07:36.940 --> 02:07:42.620]  that? And in the meantime, the flourishing of my good old
[02:07:42.620 --> 02:07:46.300]  friend, the old open web, it's wild, like Mastodon and
[02:07:46.300 --> 02:07:48.860]  Fediverse and all these things are just popping up.
[02:07:48.860 --> 02:07:50.940]  And people are like, yeah, it's confusing and weird, but
[02:07:50.940 --> 02:07:52.060]  so was Twitter in the beginning.
[02:07:52.620 --> 02:07:54.700]  It's not for everybody, but neither was Twitter in the
[02:07:54.700 --> 02:07:57.500]  beginning still isn't Twitter stolen a niche product.
[02:07:58.060 --> 02:08:02.860]  And so that all these folks who were laying in wait for
[02:08:02.860 --> 02:08:06.140]  five and 10 and 15 to 20 years building open protocols and
[02:08:06.140 --> 02:08:11.180]  open standards and weirdly named Mastodon apps and servers
[02:08:11.180 --> 02:08:13.420]  and stuff are like, all right, come on over.
[02:08:13.420 --> 02:08:16.460]  It's not the smoothest experience in the world, but it's
[02:08:16.460 --> 02:08:18.540]  here and we're going to be here and we'd love to welcome
[02:08:18.540 --> 02:08:20.540]  you and try some weird stuff and you're going to have fun
[02:08:20.540 --> 02:08:24.060]  again. And also you're not going to get run over with ads
[02:08:24.060 --> 02:08:24.460]  and whatever.
[02:08:24.940 --> 02:08:29.180]  That's a really interesting thing that I would not have
[02:08:29.180 --> 02:08:32.060]  guessed. I'm somebody who's been, you know, I've talked
[02:08:32.060 --> 02:08:32.940]  about this over the years.
[02:08:32.940 --> 02:08:34.940]  I am somebody who's loved to kind of like, well, I think
[02:08:34.940 --> 02:08:37.180]  open protocol should win and people should make open source
[02:08:37.180 --> 02:08:39.100]  tools, but it's like, I'd given up.
[02:08:40.140 --> 02:08:40.460]  You know what?
[02:08:40.460 --> 02:08:40.860]  We tried.
[02:08:40.860 --> 02:08:41.740]  It didn't work.
[02:08:41.740 --> 02:08:42.620]  Bummer about that.
[02:08:42.620 --> 02:08:43.260]  We should have worked.
[02:08:43.260 --> 02:08:47.740]  And then it's like the third act of some Marvel movie or
[02:08:47.740 --> 02:08:51.900]  something where like what the ragtag band of misfits came
[02:08:51.900 --> 02:08:54.060]  together and, and, and save the day.
[02:08:54.060 --> 02:08:56.860]  Like it's a really very heartwarming thing to see.
[02:08:56.860 --> 02:08:58.540]  I I've, I've worried hopeful.
[02:08:58.540 --> 02:09:02.300]  I have worried for so long that podcasting was the last
[02:09:02.300 --> 02:09:06.220]  open thing that would really take root in that it was at
[02:09:06.220 --> 02:09:08.140]  the time it seemed like, Oh, what a great idea.
[02:09:08.140 --> 02:09:10.380]  What another great idea for the open web, right?
[02:09:10.380 --> 02:09:13.660]  When podcasting started and now in hindsight, I've been
[02:09:13.660 --> 02:09:15.740]  thinking for a while, Oh my God, it's a miracle that
[02:09:15.740 --> 02:09:19.900]  podcasting exists the way it does today as this open thing.
[02:09:19.900 --> 02:09:23.820]  What you said there is so, so good speaking of, of having
[02:09:23.820 --> 02:09:25.180]  fun with computers.
[02:09:25.740 --> 02:09:30.380]  I would love to just real briefly tell me, tell our audience,
[02:09:30.380 --> 02:09:32.220]  tell us, tell everybody about glitch.
[02:09:32.220 --> 02:09:33.020]  Oh, sure.
[02:09:33.020 --> 02:09:33.980]  Let me plug my stuff.
[02:09:34.620 --> 02:09:39.180]  No, I mean, it's, it's what glitch is, is a community where
[02:09:39.180 --> 02:09:42.620]  you can go in your web browser to glitch.com and build a
[02:09:42.620 --> 02:09:45.660]  real app or website in 30 seconds for free.
[02:09:46.300 --> 02:09:50.460]  And it feels as joyous as the first time you built a
[02:09:50.460 --> 02:09:54.620]  MySpace page back in the day, or, you know, saw something
[02:09:54.620 --> 02:09:55.820]  cool on the internet that you made.
[02:09:55.820 --> 02:09:59.260]  And, and it is very informed by the fact that from the
[02:09:59.260 --> 02:10:02.220]  beginning, the web was supposed to be not just something
[02:10:02.220 --> 02:10:03.580]  you consume, but something you create.
[02:10:03.580 --> 02:10:05.660]  And then the first web browser that Tim Berners-Lee made
[02:10:05.660 --> 02:10:06.540]  could read and write the web.
[02:10:07.100 --> 02:10:09.260]  And what's been amazing was six years ago, we started
[02:10:09.260 --> 02:10:11.660]  talking about that with glitch and it was like this kind
[02:10:11.660 --> 02:10:14.300]  of cross your fingers, hope it becomes real today.
[02:10:14.300 --> 02:10:18.300]  Glitch is over 2 million developers that are signed up.
[02:10:18.300 --> 02:10:20.620]  They have made millions and millions of apps.
[02:10:21.340 --> 02:10:23.660]  And it's everything from, for example, all these people
[02:10:23.660 --> 02:10:26.220]  discovering Mastodon and the Fetaverse, they want to find
[02:10:26.220 --> 02:10:29.100]  their Twitter friends and bring them over to this sort of
[02:10:29.100 --> 02:10:30.060]  new platform.
[02:10:30.060 --> 02:10:33.100]  The most popular tool for doing that is called Feta Finder.
[02:10:33.100 --> 02:10:36.540]  And it was made by a guy named Luca Hammer, who is a glitch
[02:10:36.540 --> 02:10:39.180]  user. And he made this app in like a couple hours on glitch,
[02:10:39.180 --> 02:10:42.060]  like a very quick amount of time, and hundreds of thousands
[02:10:42.060 --> 02:10:45.100]  of people have used it to migrate their follower and friends
[02:10:45.100 --> 02:10:47.340]  lists from Twitter to Mastodon.
[02:10:47.340 --> 02:10:49.900]  And that's one app on glitch out of the millions.
[02:10:49.900 --> 02:10:52.380]  There's also stuff where people are building VR stuff.
[02:10:54.060 --> 02:10:57.100]  And anything you could imagine that, and also work stuff.
[02:10:57.100 --> 02:10:59.820]  Someone wants to build a Slack bot to be able to get their
[02:10:59.820 --> 02:11:01.660]  sales reports into a Slack channel for that.
[02:11:01.660 --> 02:11:03.500]  They're using glitch for that, too.
[02:11:03.500 --> 02:11:10.620]  But it is this, frankly, very idealistic idea that I was not
[02:11:10.620 --> 02:11:13.980]  convinced all these people would buy into still because I
[02:11:13.980 --> 02:11:16.780]  had bought the story that the web had closed up and people
[02:11:16.780 --> 02:11:18.540]  don't create the web themselves anymore.
[02:11:18.540 --> 02:11:23.100]  But what it's proven is it's just like food.
[02:11:23.100 --> 02:11:24.460]  We were talking about that earlier.
[02:11:26.140 --> 02:11:27.980]  All of us have fast food sometimes, right?
[02:11:27.980 --> 02:11:29.420]  You're in the airport, you're going to have some McDonald's,
[02:11:29.420 --> 02:11:30.380]  it's going to be fine.
[02:11:30.380 --> 02:11:33.660]  And if all you ever eat is the factory farmed fast food,
[02:11:33.660 --> 02:11:35.180]  you are not going to feel good.
[02:11:36.220 --> 02:11:39.020]  And the things we remember in our lives at the end of our
[02:11:39.020 --> 02:11:43.020]  lives are what are those great meals we had surrounded by
[02:11:43.020 --> 02:11:46.700]  people we love, made by people who love us, that was a cuisine
[02:11:46.700 --> 02:11:49.020]  that's part of our community or part of our culture, part of
[02:11:49.020 --> 02:11:50.060]  our tradition.
[02:11:50.060 --> 02:11:53.340]  And the same thing could be true of the web that we spend
[02:11:53.340 --> 02:11:58.060]  our time on is what if an app that we use every day or a site
[02:11:58.060 --> 02:12:00.860]  that we go to every day was made by somebody we know or that
[02:12:00.860 --> 02:12:04.460]  we love, it's part of a community that we're part of, was
[02:12:04.460 --> 02:12:06.220]  made by people that we can name?
[02:12:06.220 --> 02:12:08.540]  How many apps on your phone were made by somebody you know
[02:12:08.540 --> 02:12:09.900]  who made it, right?
[02:12:09.900 --> 02:12:10.460]  Not enough.
[02:12:11.100 --> 02:12:14.300]  And so Glitch is that place and it's been something really
[02:12:14.300 --> 02:12:14.700]  special.
[02:12:15.340 --> 02:12:16.380]  Our team is incredible.
[02:12:16.380 --> 02:12:18.380]  I've been so lucky to attract that talent.
[02:12:18.380 --> 02:12:21.820]  We talk about those kinds of people that are hopefully
[02:12:21.820 --> 02:12:25.020]  feeling very empowered as workers, but also that builds
[02:12:25.020 --> 02:12:28.780]  something out of the sincere desire in their heart that they
[02:12:28.780 --> 02:12:32.060]  give a new generation the same web that we grew up on, which
[02:12:32.060 --> 02:12:34.620]  is this is a place I can make something for the world.
[02:12:35.180 --> 02:12:39.100]  And do it, you know, like if the idea fits in an evening
[02:12:39.100 --> 02:12:40.940]  worth of hacking, you know?
[02:12:40.940 --> 02:12:41.340]  Yeah.
[02:12:41.340 --> 02:12:43.500]  And you don't have to spend your life learning to code with
[02:12:43.500 --> 02:12:45.740]  some new language and setting up a development environment.
[02:12:45.740 --> 02:12:47.180]  I mean, I love doing that stuff sometimes.
[02:12:47.180 --> 02:12:49.020]  Like if you just want to tinker, but if you're like, I got
[02:12:49.020 --> 02:12:51.020]  an idea and I would just be cool to kick the tires and see
[02:12:51.020 --> 02:12:52.300]  if I could put it up out there.
[02:12:52.300 --> 02:12:53.660]  Maybe it's a joke.
[02:12:53.660 --> 02:12:55.980]  Like God forbid you make a website just because it's funny.
[02:12:59.260 --> 02:13:03.260]  I'm so heartened, likewise, to see some of that mentality
[02:13:03.260 --> 02:13:03.980]  coming back.
[02:13:03.980 --> 02:13:07.100]  And, you know, it's just fantastic.
[02:13:08.060 --> 02:13:09.660]  And Neil, thank you for joining me.
[02:13:09.660 --> 02:13:11.420]  What a fantastic discussion.
[02:13:14.700 --> 02:13:19.500]  What a fantastically fun discussion of a totally disheartening subject matter.
[02:13:19.500 --> 02:13:23.260]  I think we're in a moment where that pain and transition
[02:13:23.260 --> 02:13:27.500]  and turmoil that everything's going through could catalyze
[02:13:27.500 --> 02:13:30.620]  the thing that made us optimistic about tech in the first place.
[02:13:30.620 --> 02:13:31.100]  Right.
[02:13:31.100 --> 02:13:33.100]  And so that's the thing where I sort of see some hope.
[02:13:33.100 --> 02:13:35.660]  And I am really grateful that, you know, you have me on
[02:13:35.660 --> 02:13:40.540]  because I also have been inspired by like 20 plus years of you
[02:13:40.540 --> 02:13:44.620]  saying I can tell a story in my own voice on my own website
[02:13:44.620 --> 02:13:49.100]  and maybe have some impact on this space in this industry.
[02:13:49.100 --> 02:13:51.900]  I still, it still gives me chills to think about.
[02:13:51.900 --> 02:13:53.820]  Like we can put those tools in people's hands
[02:13:53.820 --> 02:13:55.820]  and they can tell a story that has an impact on the world.
[02:13:55.820 --> 02:13:56.700]  So I'm grateful you do it.
[02:13:56.700 --> 02:13:59.420]  And I appreciate you validating that part, too.
[02:13:59.980 --> 02:14:01.500]  That is very kind of you to say.
[02:14:01.500 --> 02:14:01.740]  All right.
[02:14:01.740 --> 02:14:04.620]  Let me also thank our sponsors for the show.
[02:14:04.620 --> 02:14:06.060]  Let's see if I could do it off my head.
[02:14:06.780 --> 02:14:09.020]  We had Squarespace where you can build your own website.
[02:14:09.580 --> 02:14:14.620]  Collide where you can manage your fleet of Mac,
[02:14:14.620 --> 02:14:16.620]  Windows and Linux devices.
[02:14:16.620 --> 02:14:21.820]  And drink trade coffee where you can buy yourself a coffee subscription
[02:14:21.820 --> 02:14:25.180]  or get one as a gift for someone who you know who loves coffee.
[02:14:25.180 --> 02:14:25.900]  Anil, thank you.
[02:14:25.900 --> 02:14:46.620]  Thank you.
