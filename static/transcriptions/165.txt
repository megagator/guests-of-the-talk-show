[00:00.000 --> 00:02.240]  This argument is why we're going to stop being friends.
[00:02.240 --> 00:04.840]  Like one day we're going to get drunk and get really mad about this.
[00:05.040 --> 00:06.080]  I think we have.
[00:06.080 --> 00:08.880]  I think we probably we probably have.
[00:08.880 --> 00:11.800]  Like like in a way that like,
[00:11.800 --> 00:13.960]  you know, maybe other guys would get in a fight over,
[00:13.960 --> 00:16.560]  you know, sports or a girl or something like that.
[00:16.560 --> 00:20.640]  Like, you know, getting fights over Celsius versus Fahrenheit.
[00:20.760 --> 00:22.480]  Right. Yeah.
[00:22.480 --> 00:25.200]  You're the only person I know who I can't convince that.
[00:25.200 --> 00:28.680]  OK, at least it makes sense for temperature.
[00:28.680 --> 00:31.960]  Yeah. You can't convince me because it doesn't make sense.
[00:31.960 --> 00:36.360]  It's just anyway, whatever, I don't want to get into it, but it's it's
[00:36.360 --> 00:39.320]  in the 90s, way too hot in the hundreds,
[00:39.320 --> 00:42.880]  dangerously hot in the 80s, nice and warm.
[00:42.880 --> 00:46.240]  Honestly, I kind of believe you.
[00:46.240 --> 00:48.520]  I get it. I really do.
[00:48.520 --> 00:53.400]  Especially as I spend more time in in the States, I really do.
[00:53.400 --> 01:00.080]  And I can't leave this close circle of you, me and all of you listeners.
[01:00.080 --> 01:01.960]  So I do get it.
[01:01.960 --> 01:06.800]  I just it's but the arguments for it make no sense, man.
[01:06.800 --> 01:09.320]  Like it's all about what you're accustomed to.
[01:09.320 --> 01:12.920]  I totally agree that for anything else, for, you know, doctors,
[01:12.920 --> 01:15.760]  you know, you go to the hospital, they should do everything in Celsius.
[01:15.760 --> 01:19.760]  You know, all science obviously should be conducted in Celsius
[01:19.760 --> 01:24.360]  or Kelvin or whatever scale makes sense, but for sure about the weather.
[01:24.360 --> 01:26.320]  Fahrenheit's the bomb.
[01:26.320 --> 01:30.320]  So, OK, trying to trying to get away from this a little bit.
[01:30.320 --> 01:36.560]  Apple introduced a whole bunch of new APIs this last cycle
[01:36.560 --> 01:39.760]  for different measurements.
[01:39.760 --> 01:43.080]  And one of them was temperature.
[01:43.080 --> 01:47.480]  What do you think the system they used was?
[01:47.480 --> 01:51.680]  Probably Celsius, Kelvin, Kelvin.
[01:51.680 --> 01:54.920]  Yeah, because I wanted it to be Celsius because I want it to be like,
[01:54.920 --> 01:56.120]  hey, screw you, John.
[01:56.120 --> 02:02.480]  But no, it was Kelvin, which makes sense because zero and Kelvin is like.
[02:02.480 --> 02:03.720]  It's absolute zero, right?
[02:03.720 --> 02:05.000]  Oh, it's absolute zero.
[02:05.000 --> 02:07.080]  Yeah, there is. I mean, there was.
[02:07.080 --> 02:09.680]  So it's the there is nothing moves there.
[02:09.680 --> 02:11.600]  There is no like it is zero zero.
[02:11.600 --> 02:13.200]  It's not like water gets cold.
[02:13.200 --> 02:17.040]  It's like done.
[02:17.040 --> 02:17.920]  Yeah, that makes some sense.
[02:17.920 --> 02:23.480]  It's sort of like, you know, the equivalent of keeping time from the epoch.
[02:23.480 --> 02:25.640]  Yes, yeah.
[02:25.640 --> 02:26.280]  Yeah, right.
[02:26.280 --> 02:28.280]  Like you got to pick a number to date kind of thing.
[02:28.280 --> 02:30.600]  So, right.
[02:30.600 --> 02:31.440]  I got some follow up.
[02:31.440 --> 02:33.240]  I don't know if you listen to my last show, Jason.
[02:33.240 --> 02:38.160]  Jason Snell was on and we got we got talking about mechanical keyboards.
[02:38.160 --> 02:38.480]  Yeah.
[02:38.480 --> 02:46.000]  And I expressed my frustration with the fact that that there's
[02:46.000 --> 02:47.760]  you get into mechanical keyboards.
[02:47.760 --> 02:52.520]  Like I got into them and I like the Apple extended to I don't know what kind of switches.
[02:52.520 --> 02:56.160]  I think they're made by a company called Alps, but you don't have to choose.
[02:56.160 --> 03:00.200]  I just know that I like the Apple extended to keyboard.
[03:00.200 --> 03:02.480]  I used it when I was a kid.
[03:02.480 --> 03:06.040]  I owned one since I was 19 years old.
[03:06.040 --> 03:12.600]  Yeah, this is one thing where I I mean, honestly, really only the temperature thing is working.
[03:12.600 --> 03:15.200]  But you are totally right about that keyboard.
[03:15.200 --> 03:17.360]  I think you have a weird obsession with it.
[03:17.360 --> 03:22.400]  Like I move with the times, but I admire.
[03:22.400 --> 03:24.560]  I admire your dedication to that one keyboard.
[03:24.560 --> 03:29.640]  Well, Jason and I, Jason, I've got talking about modern mechanical keyboards and you buy like a new USB one.
[03:29.640 --> 03:33.080]  And when you buy them, you get the choice between different switches.
[03:33.080 --> 03:34.880]  So and there's other companies, too.
[03:34.880 --> 03:36.920]  But the famous company is Cherry.
[03:36.920 --> 03:45.120]  This company Cherry makes mechanical keyboard switches and they make blue ones, red ones, brown ones.
[03:45.120 --> 03:49.600]  Clear ones, black ones, and I think green ones.
[03:49.600 --> 03:50.640]  And how do you choose?
[03:50.640 --> 03:52.800]  And there's descriptions of them and they play.
[03:52.800 --> 03:55.680]  You go to the website and they have little sounds and you can listen to them.
[03:55.680 --> 03:59.920]  But that listening to the click of a keyboard is nothing like actually using it.
[03:59.920 --> 04:00.720]  Couple of readers.
[04:00.720 --> 04:01.360]  This is the follow up.
[04:01.360 --> 04:07.760]  Couple of readers sent in that there's a company called, I don't know how you pronounce it, WASD keyboards.
[04:07.760 --> 04:10.320]  W A S D keyboards.
[04:10.320 --> 04:14.880]  And they know that's the those are the movement keys for like games like Doom.
[04:14.880 --> 04:16.080]  Or Quaker.
[04:16.080 --> 04:16.800]  If it's a Mac.
[04:18.640 --> 04:20.880]  Oh, man, it's a classic Mac one.
[04:20.880 --> 04:21.760]  Mac shooter.
[04:21.760 --> 04:22.000]  Right.
[04:22.000 --> 04:24.800]  I guess that's, uh, it's not Destiny.
[04:24.800 --> 04:26.800]  It's the Bungie guys from way back in the day.
[04:26.800 --> 04:28.000]  And I'm blanking on it right now.
[04:28.000 --> 04:28.480]  You know, it's funny.
[04:28.480 --> 04:29.040]  I did not.
[04:29.040 --> 04:30.800]  It's been so long since I was in the games.
[04:30.800 --> 04:33.280]  I didn't realize that that's where they got the company name from.
[04:33.280 --> 04:34.800]  But that is exactly what I'm guessing.
[04:34.800 --> 04:40.400]  But if you look at their logo, it makes no sense.
[04:40.400 --> 04:42.480]  So WASD keyboards.
[04:42.480 --> 04:44.960]  They sell a product that is amazing.
[04:44.960 --> 04:48.720]  It is called the WASD six key Cherry MX switch tester.
[04:48.720 --> 04:50.240]  You pay 15 bucks.
[04:50.240 --> 04:52.160]  And it's not like an electrical device.
[04:52.160 --> 04:58.640]  It's just like a piece of metal with one of each of the six types of switches on top and the clear key cap.
[04:58.640 --> 05:02.800]  And then they also send you a pack of these O ring dampeners.
[05:02.800 --> 05:10.000]  They're just like little rubber band type things that you can optionally put into the key to sort of dampen the clickiness, the sound of it.
[05:10.000 --> 05:12.400]  It's for 15 bucks.
[05:12.400 --> 05:13.120]  It's a great thing.
[05:13.120 --> 05:17.360]  I have no idea if I'm even going to buy one of these keyboards, but I instantly bought this thing for 15 bucks.
[05:17.360 --> 05:18.160]  Came today.
[05:18.160 --> 05:18.640]  Why not?
[05:18.640 --> 05:18.880]  Yeah.
[05:21.040 --> 05:24.640]  Marathon just before Syracuse gets mad at me.
[05:24.640 --> 05:25.520]  It was Marathon.
[05:25.520 --> 05:25.760]  Right.
[05:25.760 --> 05:26.000]  Yeah.
[05:26.000 --> 05:26.800]  Anyway, so sorry.
[05:26.800 --> 05:27.440]  15 bucks.
[05:27.440 --> 05:30.400]  Marathon was the only was the last time I really got into a 3D game.
[05:30.400 --> 05:32.480]  I was deeply obsessed with Marathon.
[05:33.120 --> 05:33.600]  Cool.
[05:33.600 --> 05:37.120]  And that was before the gaming part of my brain rotted away.
[05:37.120 --> 05:38.640]  Anyway, this sample kit.
[05:38.640 --> 05:39.440]  Highly recommend it.
[05:39.440 --> 05:40.640]  I will put it in the show notes.
[05:41.840 --> 05:48.160]  Very fun if you're curious about the different types of key caps, but it's also it makes a very fun, in my opinion, desk toy.
[05:48.160 --> 05:49.200]  I like to just have it here.
[05:49.200 --> 05:53.760]  Now I've got a keyboard where I can just sit here and click keys and I'm not doing anything on screen.
[05:54.960 --> 05:55.680]  That's cool.
[05:55.680 --> 06:05.440]  I think what I like if I were going to buy one of these keyboards, I think what I would get is the Cherry Brown switches, probably with the dampener in there.
[06:05.440 --> 06:07.200]  And it feels to me with the dampener.
[06:07.200 --> 06:07.840]  Interesting.
[06:07.840 --> 06:08.720]  I think so.
[06:08.720 --> 06:09.600]  It's very hard to tell.
[06:09.600 --> 06:12.320]  I almost wish that I didn't have to choose whether I got the dampener.
[06:12.320 --> 06:14.240]  Yeah, you know what I love about this?
[06:14.240 --> 06:16.800]  It's a real nerd connoisseur kind of thing.
[06:17.440 --> 06:21.760]  Like most people on Earth do not care.
[06:21.760 --> 06:25.120]  No, but the people who care, care a lot like that.
[06:25.120 --> 06:29.680]  You know, like you're going to be pulling your hair out trying to make a decision to go with the damper or not.
[06:29.680 --> 06:34.960]  You know, well, and the other thing I found that and this was the company has a very good fact on their website.
[06:34.960 --> 06:44.320]  So the other thing that I found out is that it's not quite the decision between these six key cap or key switch colors isn't quite as complex as you think.
[06:44.320 --> 06:53.840]  There's really only three types, the blue, the brown, and I forget what the other one to the default is.
[06:53.840 --> 07:01.840]  I think it might be the black, but the idea is that the or the red, I guess the three main ones are the blue, the brown and the red.
[07:01.840 --> 07:10.080]  And then the other three, each one of them corresponds to one of the other two and just requires a little bit more force to activate.
[07:10.080 --> 07:16.240]  It has it has like a spring that is more has more resistance.
[07:16.240 --> 07:23.360]  So it takes a little bit more force to push it and restore when you're done pushing it will push the key back up faster.
[07:23.360 --> 07:31.280]  Apparently gamers, a lot of gamers prefer the ones with more resistance because they feel like they can hit the key faster.
[07:31.280 --> 07:34.000]  Because it springs up a little bit faster.
[07:34.000 --> 07:34.800]  That's interesting.
[07:36.160 --> 07:39.440]  So the black one is the red with more resistance.
[07:39.440 --> 07:42.960]  The clear one is the brown with more resistance.
[07:42.960 --> 07:45.680]  And the green one is the blue with more resistance.
[07:47.280 --> 07:48.160]  So there you go.
[07:48.160 --> 07:49.440]  You've learned something every day.
[07:50.080 --> 07:54.400]  So what do you like about the like the travel, the sound?
[07:55.840 --> 08:01.040]  I feel the sound is like that's like an artifact of you actually liking to type on the thing, right?
[08:01.040 --> 08:05.040]  I it's just a tactile satisfaction.
[08:05.040 --> 08:09.280]  It just it's there's there's something satisfying to me about clicking an actual button.
[08:10.720 --> 08:11.200]  Yeah, okay.
[08:11.200 --> 08:16.480]  But more so than like, well, whatever I'm looking at now, like the Apple magic.
[08:16.480 --> 08:17.840]  Did they call a magic keyboard?
[08:18.800 --> 08:23.600]  Yeah, you know, the standard Apple keyboard, like, yeah, I think they're called the magic keyboard to now.
[08:24.240 --> 08:27.360]  Okay, which is not these guys have like very little travel.
[08:27.360 --> 08:29.520]  They're basically laptop keyboard, right?
[08:29.520 --> 08:36.000]  But, you know, with a little bit of extra travel, just because they can afford it in the space.
[08:36.000 --> 08:36.240]  Right.
[08:36.240 --> 08:40.160]  And I, you know, I will offer, you know, when I travel, I don't take a mechanical keyboard with me.
[08:40.160 --> 08:44.080]  I just type on a MacBook, you know, for as long as it takes.
[08:44.080 --> 08:48.480]  I mean, it's not like I'm a princess who can't sleep on a mattress if there's.
[08:51.200 --> 08:52.160]  But I do feel the P.
[08:54.240 --> 08:55.040]  I just still sleep.
[08:56.400 --> 08:57.680]  Like, okay, I'm gonna deal with it.
[08:57.680 --> 08:59.440]  But anyway, that's my follow up.
[08:59.440 --> 09:00.160]  I highly recommend.
[09:00.160 --> 09:05.920]  I hopefully hopefully this company will be overwhelmed with requests from talk show listeners
[09:05.920 --> 09:07.760]  buying these switch testers.
[09:07.760 --> 09:11.280]  And like I said, it's a very fun little desk tour, in my opinion.
[09:11.280 --> 09:13.360]  Yeah, I'm gonna probably check one out.
[09:13.360 --> 09:14.080]  That's cool.
[09:14.080 --> 09:14.320]  All right.
[09:14.320 --> 09:15.120]  I wanted to talk here.
[09:15.120 --> 09:19.120]  So here's a piece from earlier this month that I specifically wanted to talk to you about because
[09:19.120 --> 09:23.760]  I feel like your sensibility would might be you might have an interesting take on this earlier
[09:23.760 --> 09:32.640]  this month during I forget which beta release, but the betas for iOS and Mac, Sierra, macOS
[09:32.640 --> 09:34.800]  Sierra were updated.
[09:34.800 --> 09:39.600]  And one of the changes they made some changes to the emoji and the one that was controversial
[09:39.600 --> 09:40.320]  I wrote about it.
[09:40.320 --> 09:43.600]  A lot of people wrote about it is that Apple changed the it's called the pistol.
[09:44.400 --> 09:49.520]  I mean, most people maybe call it the gun, but like the official Unicode name is pistol.
[09:49.520 --> 09:57.920]  They changed it from a realistic revolver type gun to a toy like space water pistol.
[09:57.920 --> 09:58.240]  Oh, no.
[09:58.240 --> 09:59.280]  Is it a it's a water pistol.
[09:59.280 --> 09:59.600]  That's right.
[09:59.600 --> 10:00.080]  It's a water.
[10:00.080 --> 10:02.720]  Well, looks like a water pistol to me.
[10:02.720 --> 10:03.760]  I mean, whatever.
[10:03.760 --> 10:05.120]  Use your own interpretation.
[10:05.120 --> 10:06.000]  No, I think it definitely does.
[10:06.000 --> 10:08.080]  When you make it big, you can definitely see it's a water pistol.
[10:08.080 --> 10:09.920]  It's Microsoft that used to have his app gun.
[10:09.920 --> 10:10.400]  That's right.
[10:10.400 --> 10:10.800]  Yeah.
[10:10.800 --> 10:11.920]  So they made it a toy water.
[10:12.480 --> 10:13.200]  Oh, Microsoft.
[10:15.600 --> 10:17.840]  So what's the question?
[10:17.840 --> 10:19.920]  Oh, well, what do you what do you think about?
[10:19.920 --> 10:25.040]  I mean, the controversy is let me try to summarize it.
[10:25.040 --> 10:29.520]  I'd say one angle on it is this is the nanny state.
[10:29.520 --> 10:30.240]  This is caught.
[10:30.240 --> 10:35.120]  They're coddling us, you know, whatever problems there are with real guns in the world.
[10:35.120 --> 10:40.400]  The problem is when actual guns are fired and actual bullets rip through actual human
[10:40.400 --> 10:47.920]  flesh, a picture of a cartoon picture of a gun that you send as a text message is is an
[10:47.920 --> 10:48.640]  abstraction.
[10:48.640 --> 10:53.200]  And it's it would be, you know, what's the difference between not showing the emoji or
[10:53.200 --> 10:57.200]  not allowing you to type the character string gun in this?
[10:58.080 --> 11:02.960]  I think that would be the expression of the the the opposition to this that I've seen.
[11:02.960 --> 11:11.600]  And then the second opposition, which is less politically charged, it's more of a linguistic
[11:11.600 --> 11:18.880]  argument, is if all other major platforms render this this code point as a realistic
[11:18.880 --> 11:23.760]  gun and I send a string of emoji that includes the gun.
[11:24.960 --> 11:28.720]  It will have a different it could it could be interpreted as having a different semantic
[11:28.720 --> 11:33.200]  meaning on iOS and Mac now compared to these other platforms.
[11:33.760 --> 11:40.240]  Yeah, that I might think that everybody sees it as a squirt gun and I send it to you and
[11:40.240 --> 11:41.120]  which is harmless.
[11:41.120 --> 11:42.400]  And guess what?
[11:42.400 --> 11:42.640]  Right.
[11:43.360 --> 11:47.200]  Everybody else is an actual gun, which is not good.
[11:47.200 --> 11:47.700]  Right.
[11:49.520 --> 11:53.840]  So to the first argument, that's an argument for inaction.
[11:55.280 --> 11:56.160]  Yes, you're right.
[11:56.160 --> 12:02.160]  Like a stupid emoji is not going to change anything and the guns actually being fired
[12:02.160 --> 12:04.640]  in real life really do cause harm.
[12:06.240 --> 12:12.000]  But I don't see that as an argument for why you must keep the pistol emoji to be like
[12:12.000 --> 12:16.080]  a gun pistol, like a like a weapon rather than a squirt pistol.
[12:17.040 --> 12:17.600]  You know what I mean?
[12:17.600 --> 12:24.960]  Like it's the that argument is one that you're conflating two different things and a pistol
[12:24.960 --> 12:27.920]  is a perfectly fine thing that you may want to represent an emoji.
[12:28.880 --> 12:30.080]  Okay, maybe so.
[12:32.320 --> 12:35.520]  Also, a water pistol is something you may want to represent.
[12:35.520 --> 12:42.240]  Like there is no it's purely a politically charged argument, I think at least.
[12:43.680 --> 12:49.280]  And I think probably because this comes on the heels of the rifle emoji being.
[12:51.520 --> 12:52.400]  Rejected.
[12:52.400 --> 12:53.280]  Rejected.
[12:53.280 --> 12:57.760]  Right, there was a proposal in the, you know, like every year there's some sort of process
[12:57.760 --> 13:03.600]  that the Unicode Consortium goes through where new characters are suggested for emoji.
[13:03.600 --> 13:08.960]  I guess for all of Unicode, you know, that there might be, you know, some obscure language
[13:08.960 --> 13:15.040]  from a, you know, a small tribe in Asia or South America or something like that.
[13:15.040 --> 13:17.680]  And they'll add glyphs to support their language or something.
[13:17.680 --> 13:19.840]  You know, you can make all sorts of proposals.
[13:19.840 --> 13:26.720]  Unicode grows every year, and one of the proposals that I guess was pretty far along was the
[13:26.720 --> 13:27.520]  rifle.
[13:27.520 --> 13:32.160]  And some point last year, Apple said we are not going to implement this.
[13:32.160 --> 13:34.560]  Whether it passes or not, we're not going to implement it.
[13:34.560 --> 13:36.960]  And as soon as Apple said that, it was dropped.
[13:38.160 --> 13:40.240]  Yeah, was it Apple uniquely?
[13:41.120 --> 13:44.800]  Like Apple and Google and Microsoft are like, nah, we're not going to do it.
[13:44.800 --> 13:49.360]  Or maybe Apple said it first and everybody was like, yeah, you know what, we don't need
[13:49.360 --> 13:49.760]  this.
[13:49.760 --> 13:50.260]  Right.
[13:51.680 --> 13:52.640]  I'll have to look that up.
[13:55.200 --> 13:57.680]  Certainly, all the articles I read said it was Apple.
[13:57.680 --> 13:59.840]  But I don't know if it was just...
[13:59.840 --> 14:02.400]  Apple might have, at the very least, might have led the way.
[14:02.400 --> 14:03.280]  Yeah, yeah.
[14:03.280 --> 14:06.000]  That was my understanding at least, but that could be biased.
[14:08.080 --> 14:09.040]  I'm okay with that.
[14:09.040 --> 14:10.720]  Do we really need a rifle emoji?
[14:10.720 --> 14:18.480]  And look, just to expose myself, I'm clearly not a gun advocate.
[14:21.920 --> 14:24.160]  But I do understand why you may...
[14:26.320 --> 14:31.520]  There's a lot of really sensible and responsible gun owners out there.
[14:32.720 --> 14:34.000]  I don't think we need an emoji.
[14:35.280 --> 14:37.920]  It's kind of where it goes to.
[14:37.920 --> 14:42.400]  And one of the things that really bugged me about the pistol was like this smiley face
[14:42.400 --> 14:46.000]  with a pistol next to itself, like for suicide.
[14:46.800 --> 14:47.300]  Yeah.
[14:47.300 --> 14:48.000]  That's not cool.
[14:49.200 --> 14:50.880]  That's not funny.
[14:50.880 --> 14:51.380]  No.
[14:53.360 --> 14:54.240]  That's like a real...
[14:54.240 --> 14:55.760]  I mean, that happens a lot.
[14:55.760 --> 14:59.680]  There's what, 30,000 guns deaths in the US each year?
[14:59.680 --> 15:00.560]  Something like that?
[15:00.560 --> 15:01.920]  And a lot of those are suicides?
[15:02.960 --> 15:04.800]  I think suicide is the most common.
[15:04.800 --> 15:07.120]  Or at least it's very, very close.
[15:07.840 --> 15:09.440]  I'm almost certain it's the most common.
[15:09.440 --> 15:10.000]  Yeah.
[15:10.000 --> 15:14.400]  And I understand that these are goofy little things and you're cracking a joke.
[15:14.400 --> 15:16.480]  And you can do die in a fire.
[15:16.480 --> 15:18.000]  Casey List does this all the time.
[15:18.560 --> 15:22.160]  He's got like the little skull face in a fire.
[15:22.160 --> 15:22.660]  Right.
[15:23.040 --> 15:25.280]  And I'm like, that's horrible.
[15:26.080 --> 15:27.360]  That is a horrible notion.
[15:27.360 --> 15:28.320]  And why would you...
[15:28.320 --> 15:31.680]  I understand it's a phrase and then I look the other way.
[15:31.680 --> 15:35.120]  But since we're bringing up the topic, man, that's harsh.
[15:36.240 --> 15:37.760]  The suicide one is interesting.
[15:37.760 --> 15:40.240]  And I'm talking from memory here, so I might be wrong.
[15:40.240 --> 15:43.760]  But I'm very, very close to certain that I am correct here.
[15:43.760 --> 15:52.240]  That it is a leading form of suicide, or maybe the, and especially for men.
[15:52.240 --> 15:59.440]  Men overwhelmingly choose to, if they choose to, often choose to use the firearms.
[15:59.440 --> 16:02.960]  And in countries where firearms have...
[16:02.960 --> 16:06.720]  Australia is the great example because Australia used to have a gun culture very
[16:06.720 --> 16:10.560]  similar to the US in terms of guns per population.
[16:10.560 --> 16:11.600]  And after a mass...
[16:11.600 --> 16:14.640]  Outback, like the cowboy culture.
[16:14.640 --> 16:16.240]  Literally, like very much the same kind of thing.
[16:16.800 --> 16:24.160]  And after a mass shooting, terrible mass shooting, I think in 1997, they legislated,
[16:24.160 --> 16:28.880]  they did like a massive gun buyback where the government just bought back literally
[16:28.880 --> 16:29.840]  millions of guns.
[16:29.840 --> 16:30.800]  I don't know what they did with them.
[16:30.800 --> 16:32.400]  I don't know if they destroyed them or whatever.
[16:32.960 --> 16:37.840]  But it's a great, in terms of actually studying scientifically the effects of gun
[16:37.840 --> 16:41.920]  ownership, it's a tremendous case study because it used to have lots of guns and
[16:41.920 --> 16:45.360]  now they have very few and all sorts of guns are missing.
[16:45.360 --> 16:50.320]  And it's not obviously the suicide rate by firearms did go down, but actually this
[16:50.320 --> 16:57.200]  overall suicide rate went down because guns are a particularly easy way to do it.
[16:57.200 --> 16:59.280]  I mean, I don't want to get too dark here, but...
[17:00.320 --> 17:03.840]  But I mean, if you're drunk and having a bad day and you have access to something
[17:03.840 --> 17:06.400]  that you know is going to do the job...
[17:07.680 --> 17:11.600]  It doesn't hold water to say that if you ban guns, that suicide will stay the same
[17:11.600 --> 17:14.320]  because people who want to kill themselves will just find another way.
[17:14.320 --> 17:18.320]  It's actually, there is statistical proof that, I mean, obviously some will, but
[17:18.320 --> 17:20.560]  it's just too easy.
[17:20.560 --> 17:24.960]  And the other terrible problem with it is that they're very effective.
[17:24.960 --> 17:26.960]  They work very well.
[17:26.960 --> 17:30.960]  So a higher percentage of suicide attempts that are made with a firearm,
[17:32.480 --> 17:34.320]  actually you end up killing yourself.
[17:34.320 --> 17:39.840]  As compared to pills, for example, people who try to kill themselves by overdose,
[17:39.840 --> 17:44.480]  there's a tremendous number of them who survive because they just pass out and
[17:44.480 --> 17:46.560]  somebody finds them and they get medical attention.
[17:46.560 --> 17:51.680]  And it's a lot easier to recover from an overdose than it is to a gunshot.
[17:51.680 --> 17:52.080]  Yeah.
[17:52.080 --> 17:55.680]  Well, it turns out a device made to kill things is good at killing things.
[17:55.680 --> 17:57.280]  Yeah.
[17:57.280 --> 17:58.400]  Not to be too...
[17:58.400 --> 18:00.000]  Man, you're going to get some hate mail.
[18:00.000 --> 18:01.920]  Well, I don't see how that's...
[18:01.920 --> 18:03.760]  I don't see how what we're saying is...
[18:04.320 --> 18:05.440]  It shouldn't be controversial.
[18:05.440 --> 18:05.760]  Right.
[18:05.760 --> 18:07.280]  I'm not saying that we should ban guns.
[18:07.280 --> 18:09.840]  I'm not making that, you know...
[18:09.840 --> 18:13.280]  I'm just saying it's the truth, though, that if you want to accept the gun culture
[18:13.280 --> 18:17.600]  that we have, it's going to result in higher suicides and much more effective
[18:19.760 --> 18:20.640]  argument solving.
[18:20.640 --> 18:28.160]  And I mean, obviously, I do advocate for some kind of change, but I'm not like
[18:28.160 --> 18:29.680]  nobody should have any guns.
[18:29.680 --> 18:31.280]  In Canada, we have a lot of guns.
[18:31.280 --> 18:33.920]  We don't have the same kind of crazy gun culture.
[18:33.920 --> 18:36.000]  So, you know, you can do it.
[18:36.720 --> 18:42.240]  Just what the current state of the US gun laws is kind of bananas.
[18:43.040 --> 18:46.160]  I am kind of fascinated by emoji.
[18:47.840 --> 18:49.120]  At first, when they first...
[18:49.120 --> 18:50.240]  Thank you for getting us off.
[18:50.240 --> 18:54.320]  Well, when they first became a thing, I was a little skeptical.
[18:54.320 --> 18:57.280]  I mean, I think anybody who knows my style can tell I'm a little...
[18:58.720 --> 19:00.480]  I don't go for frivolous things.
[19:00.480 --> 19:01.680]  I was never a fan.
[19:01.680 --> 19:07.680]  I've never really made very extensive use of like ASCII smileys, you know, like
[19:07.680 --> 19:11.440]  colon dash parentheses to make a smiley.
[19:12.400 --> 19:15.840]  Even in text messages to me, you don't do that.
[19:15.840 --> 19:16.080]  Right.
[19:16.080 --> 19:16.880]  And I used to turn...
[19:16.880 --> 19:18.320]  Maybe an aubergine every now and then.
[19:18.320 --> 19:20.800]  Right. So I was never big on smileys.
[19:20.800 --> 19:21.840]  And the first...
[19:21.840 --> 19:26.720]  The way that emoji sort of crept up on me was like with iMessage or iChat,
[19:26.720 --> 19:30.880]  I guess it used to be called at the time, was I think by default, it would
[19:30.880 --> 19:34.400]  automatically turn certain character sequences into smileys.
[19:34.400 --> 19:35.920]  And this was before we called them emoji.
[19:35.920 --> 19:36.800]  And there was a limited set.
[19:36.800 --> 19:39.840]  I think that the set character set came from AIM, actually.
[19:39.840 --> 19:42.320]  Like it was like an AOL instant messenger thing.
[19:42.320 --> 19:45.280]  But different character sequences would turn into different smileys.
[19:45.280 --> 19:48.640]  And I turned that off.
[19:48.640 --> 19:51.040]  But you'd run into them accidentally sometimes.
[19:51.040 --> 19:53.280]  There were certain character sequences that you...
[19:53.280 --> 19:53.920]  Like if you were...
[19:53.920 --> 19:56.640]  I don't know if you were pasting like source code or something like that to
[19:56.640 --> 20:00.960]  somebody, you know, the semicolon and a thing would somehow turn into a smiley
[20:00.960 --> 20:02.000]  and it wouldn't make any sense.
[20:03.360 --> 20:08.400]  But once the full emoji set, I'm sort of fascinated because I feel like people
[20:08.400 --> 20:10.160]  are expressing themselves in a way.
[20:10.160 --> 20:14.160]  Like it must be like a field day to be like a linguistic researcher to study
[20:14.160 --> 20:17.520]  this because people take to them naturally, you know, and you've mentioned
[20:17.520 --> 20:23.760]  Casey Liss, you know, who's, you know, like an idiot, right?
[20:23.760 --> 20:24.960]  I mean, he's a very nice guy.
[20:24.960 --> 20:25.920]  But he's barely...
[20:25.920 --> 20:28.240]  And in written English, he's barely literate.
[20:28.240 --> 20:32.720]  I mean, he is very, you know, it's very tough to make any heads or tails out of
[20:32.720 --> 20:37.200]  his writing in English prose, but he can express himself fluently in emoji.
[20:37.200 --> 20:37.920]  That's true.
[20:37.920 --> 20:41.680]  That is the most true thing anybody's ever said about poor Casey Liss.
[20:41.680 --> 20:44.160]  And I think it's fascinating people who are good at it.
[20:44.160 --> 20:44.800]  And I use them.
[20:44.800 --> 20:45.680]  I like it.
[20:45.680 --> 20:47.120]  There's certain ones that are very fun.
[20:51.600 --> 20:56.400]  I do think, though, I think it's interesting and I think that it is a form of real
[20:56.400 --> 21:02.320]  communication and it conveys emotion much better than prose, especially in very
[21:02.320 --> 21:03.120]  short form.
[21:03.120 --> 21:06.800]  I mean, it's no surprise that they get mostly used in text messages.
[21:06.800 --> 21:08.800]  In short text messages and Twitter kind of thing.
[21:08.800 --> 21:10.640]  Yeah, right.
[21:10.640 --> 21:16.800]  And you can convey things like if somebody says, Hey, I got the job.
[21:16.800 --> 21:20.080]  They've been trying to get a job at a place and they got it.
[21:20.080 --> 21:22.560]  And you send them the two beers, clinking emoji.
[21:23.520 --> 21:29.360]  It's a very, very quick and efficient way of saying, Hey, congratulations.
[21:29.360 --> 21:32.560]  And maybe, Hey, let's meet up and have a beer and celebrate.
[21:32.560 --> 21:34.160]  You can convey that with one character.
[21:34.160 --> 21:37.440]  Congratulations and celebration, like all in one.
[21:37.440 --> 21:37.920]  Yeah.
[21:37.920 --> 21:38.400]  Yeah.
[21:38.400 --> 21:44.080]  But there is to me, although even though I think it's I do think it's a serious form
[21:44.080 --> 21:47.360]  of expression to me, they are inherently frivolous.
[21:48.240 --> 21:53.520]  And that to me is where to me, taking out the realistic pistol is to me.
[21:53.520 --> 21:54.080]  Okay.
[21:54.080 --> 21:58.720]  Because I think that there is an inherent frivolous to emoji and that they're best
[21:58.720 --> 21:59.680]  used for.
[22:00.240 --> 22:06.160]  And if you look at them, most of them overwhelmingly, they're they're mostly
[22:06.160 --> 22:11.200]  like expressing things that are either completely innocuous, like a strawberry or
[22:12.160 --> 22:18.560]  like surfing or some weird random like the woman dancing or.
[22:18.560 --> 22:19.060]  Yeah.
[22:19.760 --> 22:25.280]  Which is a little weird because, well, they're finally expanding the female representation.
[22:25.280 --> 22:25.920]  Right.
[22:25.920 --> 22:34.240]  But yeah, it's all happy and good and like a rifle and a pistol.
[22:34.960 --> 22:36.000]  It's an ill suited.
[22:36.000 --> 22:42.960]  It's an ill suited language for expressing negative things, in my opinion.
[22:43.600 --> 22:44.800]  I agree.
[22:44.800 --> 22:50.080]  Now that could just be because culturally I haven't grown up with guns and guns are
[22:50.080 --> 22:51.200]  not a thing in my life.
[22:51.200 --> 22:54.960]  Maybe maybe a goofy pistol is funny.
[22:54.960 --> 23:04.080]  And maybe and this is like maybe we're now doing the thing where eventually people look
[23:04.080 --> 23:11.440]  back at like Looney Tunes and like, oh, man, we got to cut a lot of these things, which
[23:11.440 --> 23:13.040]  I hated, by the way.
[23:13.040 --> 23:15.920]  But I mean, we don't need a pistol pistol.
[23:15.920 --> 23:17.040]  We got water pistols.
[23:17.040 --> 23:17.280]  Fine.
[23:17.280 --> 23:22.720]  Whatever you want to express with it as a joke with a pistol, you can you can express
[23:22.720 --> 23:23.220]  with the water.
[23:24.080 --> 23:25.200]  I loved the Looney Tunes.
[23:25.200 --> 23:25.700]  Looney Tunes.
[23:26.320 --> 23:26.880]  Me too.
[23:26.880 --> 23:28.960]  That was some horrible stuff.
[23:28.960 --> 23:31.600]  But they had an entire character, Yosemite Sam.
[23:31.600 --> 23:33.760]  The entire basis of his character was that.
[23:33.760 --> 23:35.200]  Yeah, yes.
[23:36.080 --> 23:38.560]  He was so gun crazy that he had two guns.
[23:38.560 --> 23:41.600]  Like one gun wasn't enough for Yosemite Sam.
[23:41.600 --> 23:42.960]  Man, I love that guy.
[23:42.960 --> 23:43.680]  Yeah.
[23:43.680 --> 23:47.440]  And Wally Coyote died in like every way possible.
[23:48.000 --> 23:48.720]  That was horrible.
[23:49.600 --> 23:50.240]  Who was your favorite?
[23:50.240 --> 23:51.200]  Who's your favorite Looney Tunes?
[23:51.200 --> 23:53.600]  Oh, I'm blanking.
[23:56.000 --> 23:57.120]  The giant chicken.
[23:57.120 --> 23:58.320]  Foghorn Leghorn.
[23:58.320 --> 23:59.360]  Foghorn Leghorn.
[23:59.360 --> 24:00.000]  This is why we're friends.
[24:00.000 --> 24:01.520]  Foghorn Leghorn is exact.
[24:01.520 --> 24:01.840]  Thank you.
[24:01.840 --> 24:02.800]  I forgot his name.
[24:02.800 --> 24:03.840]  This is why we're friends.
[24:03.840 --> 24:05.280]  He was my absolute favorite.
[24:07.280 --> 24:10.400]  I swear to God, like a year ago, maybe two years ago, I can't remember.
[24:10.400 --> 24:14.160]  I spent an entire night just watching Foghorn Leghorn on YouTube.
[24:14.160 --> 24:16.080]  I was like, he's the best.
[24:16.080 --> 24:17.440]  Why the hell was he so big?
[24:18.400 --> 24:19.760]  I don't know why he's so big.
[24:19.760 --> 24:21.280]  He was like seven feet tall.
[24:21.840 --> 24:22.560]  Yeah.
[24:22.560 --> 24:27.920]  And I love that he's like a total asshole to like the dog that's tied up.
[24:27.920 --> 24:32.240]  Like the dog, just basically, I guess mentally, you guard everything.
[24:32.880 --> 24:33.520]  It's tied up.
[24:33.520 --> 24:37.600]  And all he does is like, he wakes up in the morning and he goes and he stands just outside
[24:37.600 --> 24:40.640]  the line of where the dog's leash lets him go.
[24:40.640 --> 24:44.160]  And he just baits the dog into charging at him and then laughs.
[24:46.160 --> 24:47.680]  He's such an asshole.
[24:48.560 --> 24:49.040]  He is.
[24:50.800 --> 24:52.560]  I always loved Foghorn Leghorn.
[24:52.560 --> 24:53.840]  He was definitely my best.
[24:53.840 --> 24:54.400]  He's the best, yeah.
[24:54.400 --> 25:03.120]  And Chicken Hawk, who they added later was like teeny tiny, but he was like this, like,
[25:05.200 --> 25:08.480]  you know, like rough, like he always wanted to get in a scrap kind of guy.
[25:09.600 --> 25:10.080]  So good.
[25:11.120 --> 25:14.400]  The other thing about the dog was that the dog was a worthy adversary.
[25:15.440 --> 25:16.000]  Oh yeah.
[25:16.000 --> 25:16.560]  Yeah.
[25:16.560 --> 25:17.360]  He wasn't a dummy.
[25:17.360 --> 25:18.720]  He was just tied up half the time.
[25:18.720 --> 25:19.840]  Like, what are you going to do?
[25:19.840 --> 25:27.520]  Apparently his name, his name was just barnyard dog, but it was spelled D A W G dog.
[25:27.520 --> 25:30.400]  Oh, it's cause of the Southern drawl barnyard dog.
[25:31.600 --> 25:31.840]  Yeah.
[25:32.400 --> 25:33.200]  That was the other thing.
[25:33.200 --> 25:36.800]  I mean, just fucking Leghorn's voice was hilarious.
[25:38.800 --> 25:41.200]  And the dog sometimes got back delivery.
[25:41.200 --> 25:43.120]  Like, Oh God, it was God.
[25:43.120 --> 25:44.240]  Oh yeah, yeah, yeah.
[25:45.280 --> 25:46.960]  Not even sometimes like it.
[25:46.960 --> 25:47.200]  Yeah.
[25:47.200 --> 25:48.960]  It seemed like a fair fight to me.
[25:48.960 --> 25:49.440]  Yeah.
[25:49.440 --> 25:53.760]  As opposed to like, uh, the roadrunner and, and, uh, Wile E.
[25:53.760 --> 25:54.160]  Coyote.
[25:54.160 --> 25:54.640]  Yeah.
[25:54.640 --> 25:55.440]  Which was good too.
[25:55.440 --> 26:00.000]  Coyote is a bit of a tragic, you know, he's, he's kind of a tragedy though.
[26:00.000 --> 26:00.240]  Right.
[26:01.520 --> 26:03.600]  But the roadrunner would never do anything mean to him.
[26:04.720 --> 26:05.520]  I don't know.
[26:05.520 --> 26:05.840]  He did it.
[26:05.840 --> 26:06.720]  He always did it.
[26:06.720 --> 26:08.480]  Like it would just backfire, you know?
[26:08.480 --> 26:08.640]  Right.
[26:09.200 --> 26:10.400]  Did you ever read the rules?
[26:10.400 --> 26:14.960]  There were the, the, the written rules of, uh, the, the, uh, the roadrunner.
[26:14.960 --> 26:16.720]  I think I did years ago.
[26:16.720 --> 26:18.320]  I'll have to put it, I'll put it in the show notes,
[26:18.320 --> 26:19.440]  but the rules are brilliant.
[26:19.440 --> 26:24.960]  And it was, it was almost like, like writing the script for, uh, uh, roadrunner
[26:24.960 --> 26:31.680]  Coyote, uh, short was almost like a logic puzzle because you had to follow this
[26:31.680 --> 26:34.160]  six very, very specific list of rules.
[26:34.160 --> 26:37.440]  Like, and one of them, there are things that I never even really thought of was
[26:37.440 --> 26:41.920]  that one of them is that the roadrunner never leaves the road no matter what
[26:41.920 --> 26:42.640]  happened.
[26:42.640 --> 26:47.760]  Cause because he's a roadrunner, everything that ever happened in all of
[26:47.760 --> 26:51.840]  those Coyote, Wile E. Coyote roadrunner shorts, he never once left the road.
[26:52.880 --> 26:54.160]  That I hadn't even noticed that.
[26:54.160 --> 26:54.640]  That's great.
[26:54.640 --> 26:55.440]  That makes sense.
[26:55.440 --> 26:55.840]  Yeah.
[26:55.840 --> 26:56.400]  That's great.
[26:57.040 --> 27:01.840]  It's like a, well, it's like the cartoon version of Asimov's three rules, three
[27:01.840 --> 27:09.120]  robots, like you set up a structure and then you debug it basically by like,
[27:09.120 --> 27:12.160]  like your story is like, well, see how this went wrong.
[27:12.160 --> 27:12.400]  Yeah.
[27:12.400 --> 27:15.040]  And I think one of the rules is that every bad thing that happens to the
[27:15.040 --> 27:18.560]  Coyote has to be his own doing.
[27:18.560 --> 27:18.720]  Yeah.
[27:18.720 --> 27:21.600]  It seems that, I mean, that's what I took away from it.
[27:21.600 --> 27:27.200]  So because, and he's not even a bad guy really.
[27:28.880 --> 27:31.360]  Well, I guess he does want to eat the roadrunner, but I think he's just
[27:31.360 --> 27:31.840]  hungry.
[27:31.840 --> 27:32.720]  He's hungry.
[27:32.720 --> 27:33.040]  Yeah.
[27:33.040 --> 27:33.520]  I'm sorry.
[27:33.520 --> 27:34.480]  He's got to eat something.
[27:35.760 --> 27:38.240]  I don't, what is, I don't, yeah.
[27:38.240 --> 27:41.840]  And he falls off cliffs and gets blown up and it's like horrible.
[27:41.840 --> 27:43.680]  The things that happened to him are the worst.
[27:43.680 --> 27:47.520]  Like he falls off a cliff and then a giant boulder falls on it.
[27:47.520 --> 27:49.520]  It's like, as if that wasn't enough.
[27:52.160 --> 27:55.440]  Uh, let me take a break and thank our first sponsor.
[27:55.440 --> 27:57.120]  It's our good friends at Casper.
[27:57.120 --> 28:00.480]  Casper is an obsessively engineered mattress and they sell them at
[28:00.480 --> 28:01.680]  shockingly fair prices.
[28:01.680 --> 28:06.640]  Go to casper.com slash the talk show and just, uh, I think you automatically
[28:06.640 --> 28:09.760]  get it by going to that URL, but the code is the talk show and you will
[28:09.760 --> 28:12.240]  save 50 bucks towards your mattress.
[28:12.240 --> 28:12.960]  Towards your mattress.
[28:13.520 --> 28:16.160]  Casper created one perfect mattress.
[28:16.720 --> 28:20.720]  They don't have to choose like what type of a foam you want, what type
[28:20.720 --> 28:21.680]  of Springs you want.
[28:21.680 --> 28:22.320]  They've got one.
[28:22.320 --> 28:24.560]  They, they spent years, they spent a lot of money.
[28:24.560 --> 28:25.120]  They really do.
[28:25.120 --> 28:29.760]  They have engineers who just went into what is the perfect default
[28:29.760 --> 28:30.240]  mattress.
[28:30.240 --> 28:30.960]  It is a cut.
[28:30.960 --> 28:35.200]  They ended up with a combination of springy latex and supportive memory
[28:35.200 --> 28:38.400]  foam for a sleep surface with just the right sink, just the right
[28:38.400 --> 28:38.720]  bounce.
[28:38.720 --> 28:41.520]  So you don't have to choose who wants to, it's like, you don't have to
[28:41.520 --> 28:45.040]  get like one of those six key cap testers for six types of mattresses
[28:45.040 --> 28:45.600]  from Casper.
[28:45.600 --> 28:47.920]  They've got one type exactly what you want.
[28:47.920 --> 28:50.720]  It's not like buying one of these mechanical keyboards, one type of
[28:50.720 --> 28:51.280]  mattress.
[28:51.280 --> 28:56.960]  You just pick the size and because they make them and they manufacture
[28:56.960 --> 29:01.120]  them right here in, uh, in the United States, they make them and sell them
[29:01.120 --> 29:02.080]  directly to you.
[29:02.080 --> 29:07.440]  There is, this is how they, they get away with charging in a lot of
[29:07.440 --> 29:10.560]  comparisons, half the price of a premium mattress that you would buy at
[29:10.560 --> 29:11.760]  a mattress store.
[29:11.760 --> 29:15.840]  Um, most premium mattresses start at over 1500 bucks.
[29:15.840 --> 29:21.920]  Casper's started just 500 bucks for twin and they go up to just 950 for a
[29:21.920 --> 29:26.400]  king, 850 for a queen, and they're made right here in America.
[29:26.400 --> 29:27.360]  There's a cool thing too.
[29:27.360 --> 29:29.360]  If you live in New York City, I don't know if you've ever seen pictures
[29:29.360 --> 29:31.600]  of this, but if you live in New York City, they deliver them to you on a
[29:31.600 --> 29:32.240]  bicycle.
[29:32.240 --> 29:35.200]  There's just, I mean, it is a big box to be carrying around on your back
[29:35.200 --> 29:40.000]  on a bicycle, but you can get like same day delivery in Manhattan, maybe
[29:40.000 --> 29:43.280]  elsewhere in New York, uh, which is kind of amazing.
[29:43.280 --> 29:47.120]  Uh, they show up in your house in these ridiculously small boxes, big
[29:47.120 --> 29:49.920]  box, like probably the biggest box you'll get all year delivered to your
[29:49.920 --> 29:50.240]  house.
[29:50.240 --> 29:54.160]  But considering that it contains a mattress, it's remarkably small, simple
[29:54.160 --> 29:55.520]  instructions on the box.
[29:55.520 --> 29:58.240]  Bring it up to the room, the bedroom where you're going to put it, open the
[29:58.240 --> 30:01.440]  box the right way, and it just sucks all the oxygen out of the room.
[30:01.440 --> 30:05.280]  And, uh, next thing you know, you got a full-size mattress they have, and
[30:05.280 --> 30:08.880]  this is the whole key to buying a mattress without trying it in a store or,
[30:08.880 --> 30:12.000]  or just taking, you know, the word for me, John Q.
[30:12.000 --> 30:14.880]  Podcaster, that these are good mattresses and they are very good
[30:14.880 --> 30:15.840]  mattresses.
[30:15.840 --> 30:20.400]  Um, but they have a hundred night home trial, so you buy it, open it up,
[30:20.400 --> 30:22.080]  sleep on it for three months.
[30:22.080 --> 30:26.320]  And if you don't love it, you just go on the web, go back and, and with no
[30:26.320 --> 30:29.680]  questions asked, no hard sell, they don't like make you sit there and, and,
[30:29.680 --> 30:31.200]  and try to convince you to keep it.
[30:31.200 --> 30:34.000]  They'll just say, okay, and they'll come and pick it up and you get your
[30:34.000 --> 30:34.640]  money back.
[30:34.640 --> 30:36.400]  So can't lose.
[30:36.400 --> 30:40.480]  It is the easiest way to buy a mattress and you get a terrific mattress.
[30:40.480 --> 30:44.640]  So go to casper.com slash the talk show, and remember that code, the talk
[30:44.640 --> 30:48.560]  show, and you will save 50 bucks on their already amazing prices.
[30:50.320 --> 30:57.040]  So this is honestly not part of the pitch, but, uh, they, uh, they started
[30:57.040 --> 30:57.920]  selling dog beds.
[30:58.720 --> 30:59.280]  Is that true?
[30:59.280 --> 31:00.240]  I did not know that.
[31:00.240 --> 31:03.600]  I hope they're not mad at you because I'm muddying the water or something,
[31:03.600 --> 31:07.920]  but yeah, they started selling dog beds and that seems pretty cool to me.
[31:07.920 --> 31:08.420]  Yeah.
[31:08.640 --> 31:09.140]  Yeah.
[31:09.600 --> 31:13.360]  Well, that's, you know, similar kind of technology and, you know, like a good
[31:13.360 --> 31:13.680]  cover.
[31:13.680 --> 31:18.800]  So the dog doesn't just eat the whole thing, but yeah, no, it's pretty cool.
[31:18.800 --> 31:19.520]  Yeah.
[31:19.520 --> 31:20.800]  Your dog's got to sleep somewhere.
[31:21.680 --> 31:22.480]  Yeah.
[31:22.480 --> 31:24.160]  May as well sleep on the best.
[31:24.160 --> 31:24.660]  Yeah.
[31:28.080 --> 31:30.400]  Anything else on the, you don't want to go back to the emoji, do you?
[31:30.400 --> 31:31.120]  I think we covered it.
[31:31.120 --> 31:38.400]  Uh, yeah, no. Oh, the second point was that, uh, the, uh, enter OS operability.
[31:38.400 --> 31:38.900]  Yeah.
[31:39.600 --> 31:43.920]  Uh, yeah, we talked about that before, but we would talk about a smiley face,
[31:43.920 --> 31:45.120]  like the one with the teeth.
[31:45.120 --> 31:45.620]  Yeah.
[31:46.640 --> 31:52.240]  Apple has a, a there's a, it's like grimacing face, grinning, grinning face
[31:52.240 --> 31:56.000]  that looks almost exactly like they're grimacing face, except the eyes are
[31:56.000 --> 31:56.500]  different.
[31:56.500 --> 32:01.620]  And on other platforms, the grinning face is clearly somebody who is happy.
[32:01.620 --> 32:06.420]  Whereas the Apple one really looks like somebody who is grimacing for whatever
[32:06.420 --> 32:09.780]  reason, you know, like, like if I pick it out, I pick it out because it looks
[32:09.780 --> 32:10.900]  like it's sucking your teeth.
[32:10.900 --> 32:15.220]  Like, yeah, like, like the face, the face you would make if you just talked
[32:15.220 --> 32:18.100]  bad about somebody and you found out they're standing right behind you.
[32:18.100 --> 32:19.300]  Yes, exactly.
[32:19.300 --> 32:19.800]  Yeah.
[32:20.180 --> 32:24.260]  Uh, but that it's, you know, different platforms render them in different ways.
[32:24.260 --> 32:25.380]  So that, that sucks.
[32:25.380 --> 32:31.060]  So yeah, the water pistol doesn't convey the same notion.
[32:31.060 --> 32:34.020]  And the other, but it's, it's fine.
[32:34.020 --> 32:35.460]  I think it'll all get sorted out.
[32:36.100 --> 32:41.460]  The other thing is, uh, man, poor Microsoft, those guys, they had the
[32:41.460 --> 32:41.940]  right idea.
[32:41.940 --> 32:43.060]  They had a ray gun.
[32:43.060 --> 32:43.560]  Right.
[32:43.860 --> 32:48.020]  And now they changed it to a pistol the day that Apple changed it, like a
[32:48.020 --> 32:48.980]  water pistol.
[32:48.980 --> 32:51.940]  I actually think, and the worst part about that, not only did they change it
[32:51.940 --> 32:54.500]  the wrong way, or at least just keep up with Apple.
[32:54.500 --> 32:54.980]  To me.
[32:54.980 --> 32:55.480]  Yeah.
[32:56.020 --> 32:57.300]  To, to our tastes.
[32:57.300 --> 33:01.060]  Well, and not just to our tastes, but it is true that the iPhone is so
[33:01.060 --> 33:04.900]  singularly, uh, oh, dominant, popular control.
[33:04.900 --> 33:05.220]  Yeah.
[33:05.220 --> 33:05.540]  Yeah.
[33:05.540 --> 33:09.700]  That, that Apple, what Apple does, you know, they're, they're, they're user
[33:09.700 --> 33:15.460]  base is, you know, arguably the leading, or at least in Western, the Western
[33:15.460 --> 33:19.460]  world is the leading, um, use users of emoji.
[33:19.460 --> 33:22.580]  So it really does matter disproportionately what Apple does.
[33:24.500 --> 33:24.900]  Yeah.
[33:24.900 --> 33:26.100]  I, I agree with that.
[33:26.100 --> 33:26.600]  Right.
[33:26.820 --> 33:30.500]  I mean, for as big in it for as many, you know, tens of hundreds of millions
[33:30.500 --> 33:33.220]  of people are using windows and sending emoji on them.
[33:33.220 --> 33:35.620]  Uh, there's more people using iOS devices.
[33:36.980 --> 33:37.860]  Oh yeah.
[33:37.860 --> 33:41.860]  Android is splintered because, you know, like Samsung has their own set.
[33:41.860 --> 33:45.540]  Um, you know, different, different Android makers have their own sets of
[33:45.540 --> 33:45.940]  emoji.
[33:45.940 --> 33:48.420]  They don't all just use the default Google ones.
[33:48.420 --> 33:52.820]  So even though there might be more users, uh, of Android and, you know, quote
[33:52.820 --> 33:56.820]  unquote, Android, there's, Android is so splintered that it's, there's no
[33:56.820 --> 34:02.260]  single, um, uh, base the way that iOS does.
[34:02.820 --> 34:03.060]  Right.
[34:04.260 --> 34:11.220]  And Android, Android's splintering is not helping, not helping in like, pick,
[34:11.860 --> 34:15.540]  pick a metric, like pick some avenue that you want to talk about.
[34:15.540 --> 34:19.460]  And like, uh, almost always it's like, oh yeah, but Android is not one thing.
[34:19.460 --> 34:20.420]  It's just, right.
[34:20.420 --> 34:22.260]  That's the, that's the best way to think about it though.
[34:22.260 --> 34:25.940]  If you'd stop thinking about it as though it is one thing, it's, it's, you
[34:25.940 --> 34:27.860]  know, it makes more sense.
[34:27.860 --> 34:32.100]  I do think I also think I personally, I think Microsoft had a better idea.
[34:32.820 --> 34:33.220]  Yeah.
[34:33.220 --> 34:37.860]  Going with Ray gun than the water gun, because I think the water gun, I think
[34:37.860 --> 34:41.540]  90 some percent of cases, it won't make much difference, but a water gun is a
[34:41.540 --> 34:46.900]  little bit so more specific where you could combine it with like the
[34:46.900 --> 34:48.660]  splashing water drops.
[34:48.660 --> 34:48.980]  Yeah.
[34:48.980 --> 34:49.300]  Right.
[34:49.300 --> 34:54.580]  And then that won't make any sense at all with other platforms.
[34:54.580 --> 34:58.820]  Whereas if you went with the Ray gun, I don't really think there's any context
[34:58.820 --> 35:02.660]  where you could use it with other emoji where it changes things that much.
[35:02.660 --> 35:02.980]  Yeah.
[35:02.980 --> 35:07.140]  Just sort of puts a more frivolous spin on the idea of a, of a pistol.
[35:07.140 --> 35:08.740]  Yeah, I, I agree.
[35:09.300 --> 35:15.220]  And I, you know what, I'm going to say, I do know, but I'm not sure if I know,
[35:15.220 --> 35:20.500]  cause I'm pretty sure I saw it, but the, uh, the water pistol emoji used to be
[35:20.500 --> 35:21.540]  flipped the other way.
[35:21.540 --> 35:22.180]  Yeah.
[35:22.180 --> 35:25.140]  And apparently internally there was like before they shipped it, it was like
[35:25.140 --> 35:26.260]  going the other way.
[35:26.260 --> 35:29.300]  So which would have really broken everything.
[35:30.340 --> 35:30.580]  Yeah.
[35:30.580 --> 35:34.340]  Because it would matter if you were saying you want to shoot.
[35:35.460 --> 35:37.140]  Shoot to the left or shoot to the right.
[35:37.140 --> 35:37.460]  Right.
[35:37.460 --> 35:38.580]  And you're putting an emoji.
[35:38.580 --> 35:40.180]  That's what you want to shoot, you know?
[35:40.740 --> 35:41.060]  Yeah.
[35:41.060 --> 35:45.940]  And I kind of, I kind of liked the fact that they made it the other way, just
[35:45.940 --> 35:48.660]  cause it literally breaks any of that.
[35:48.660 --> 35:54.420]  Like you were shooting at the wrong thing and that's a very personal political
[35:54.420 --> 35:54.740]  thing.
[35:55.620 --> 35:59.380]  Uh, I think it is smarter that they probably flipped it back to the left at
[35:59.380 --> 35:59.780]  this point.
[35:59.780 --> 36:05.780]  So, so it at least faces the same way as all the other pistols and the, uh, I
[36:05.780 --> 36:10.100]  think, I think Craig, I think Craig Hockenberry pointed this out.
[36:10.100 --> 36:17.380]  Pointed this out is that the emoji, uh, the emoji, the Unicode spec specifically
[36:17.380 --> 36:19.620]  mentions that it should be pointing one way.
[36:19.620 --> 36:20.900]  Yeah, I think it does.
[36:20.900 --> 36:21.140]  Yeah.
[36:21.780 --> 36:23.540]  Um, we could say this a bit.
[36:23.540 --> 36:28.980]  Craig knows more about emoji than we'll ever know because the icon factory has
[36:28.980 --> 36:32.500]  done the emoji sets for, I think a couple of companies.
[36:33.300 --> 36:34.740]  Uh, yeah.
[36:34.740 --> 36:35.460]  Big companies.
[36:35.460 --> 36:35.700]  Yeah.
[36:35.700 --> 36:37.460]  Companies that everybody knows.
[36:37.460 --> 36:42.740]  Um, so they've done a lot of, you know, as you might expect from a company,
[36:42.740 --> 36:46.500]  this entire name is based on drawing icons.
[36:46.500 --> 36:48.020]  They've drawn a lot of emoji.
[36:50.500 --> 36:53.940]  And Craig, while he's not drawing the emoji is obviously the point person on
[36:53.940 --> 36:58.900]  making sure that all the, uh, yeah, the hexadecimal code points and et cetera
[36:58.900 --> 36:59.700]  are okay.
[36:59.700 --> 36:59.860]  Yeah.
[36:59.860 --> 37:02.260]  Well, he made his own internal awesome tool too.
[37:03.860 --> 37:05.300]  Of course he did make those fonts.
[37:05.300 --> 37:06.580]  Of course he did.
[37:06.580 --> 37:07.620]  Cause they're fonts, right?
[37:07.620 --> 37:08.500]  Like it's still a font.
[37:08.500 --> 37:09.220]  So yeah.
[37:09.220 --> 37:11.220]  So he made an awesome tool for it.
[37:11.220 --> 37:11.620]  Yeah.
[37:13.060 --> 37:15.220]  Um, all right, moving on.
[37:15.220 --> 37:17.300]  Uh, what else can we talk about?
[37:17.300 --> 37:22.500]  How about, did you read the, um, uh, the Steven Levy piece for back channel with
[37:22.500 --> 37:27.060]  a profile of Apple's, uh, AI and quote unquote machine learning work?
[37:28.100 --> 37:28.900]  I did a little bit.
[37:28.900 --> 37:29.300]  Yeah.
[37:29.300 --> 37:30.820]  I mean, like I read it.
[37:30.820 --> 37:35.380]  I haven't read all of the subsequent followups of like trying to frame it in
[37:35.380 --> 37:36.260]  different ways, you know?
[37:36.260 --> 37:42.260]  So the, the gist of it is that Steven Levy, um, I think it's Levy.
[37:42.260 --> 37:43.860]  I don't know if it's Levy, Steven Levy.
[37:43.860 --> 37:44.340]  I know him.
[37:44.340 --> 37:44.820]  I should know.
[37:44.820 --> 37:45.540]  I shouldn't know.
[37:45.540 --> 37:47.940]  Uh, yeah.
[37:47.940 --> 37:50.340]  Also seems like a smart guy to me.
[37:50.340 --> 37:52.260]  He's been in the racket forever.
[37:52.260 --> 37:53.460]  So, right.
[37:53.460 --> 37:53.940]  Yeah.
[37:53.940 --> 37:59.060]  Uh, has written some great, great books, including, uh, what was the name of the
[37:59.060 --> 38:01.860]  iPod book?
[38:01.860 --> 38:03.140]  The iPod book was amazing.
[38:03.140 --> 38:03.780]  Oh yeah.
[38:03.780 --> 38:05.780]  It was like, perfect.
[38:05.780 --> 38:06.980]  Horrible names, but yeah.
[38:07.860 --> 38:09.380]  Uh, he's written books.
[38:09.380 --> 38:11.620]  He has written about cryptography.
[38:11.620 --> 38:17.060]  He is, you know, um, again, he's smart guys been around for, right.
[38:17.860 --> 38:24.740]  I mean, as long as I've been following this stuff, he's been a go-to like a name
[38:24.740 --> 38:25.540]  worth trusting.
[38:25.540 --> 38:27.700]  Uh, the iPod book was called the perfect thing.
[38:27.700 --> 38:29.220]  Oh, cool.
[38:29.220 --> 38:30.260]  Man, that's a good name.
[38:30.260 --> 38:31.460]  Yeah, really was.
[38:32.100 --> 38:38.180]  Um, so he was somehow obtained, you know, whether it was offered to him or whether
[38:38.180 --> 38:41.460]  it was him asking, but it was probably a combination of the two through Apple PR
[38:41.460 --> 38:47.380]  was granted, uh, exclusive access to Apple's executive leadership in turn on,
[38:47.380 --> 38:52.980]  on, uh, AI and machine learning and Siri, uh, which is Eddie Q and Craig Federighi,
[38:52.980 --> 38:53.380]  of course.
[38:53.380 --> 39:00.420]  Um, and then two other guys who, uh, one of them, his name is, I do remember is
[39:01.060 --> 39:06.260]  Tom Gruber, which is, uh, just for the record, no, no relation.
[39:06.980 --> 39:11.860]  Um, and another guy whose name I, uh, escapes me, but he's like in charge of
[39:11.860 --> 39:13.620]  the voice Bob English.
[39:13.620 --> 39:18.580]  I think, uh, Alex, I missed your joke.
[39:18.580 --> 39:22.900]  Cause I'm looking for his name too funny, too funny for anybody to notice.
[39:22.900 --> 39:27.140]  Alex, a zero, uh, he's in charge of voice recognition.
[39:27.140 --> 39:31.780]  Um, I saw people complain that this was a quote unquote, a lot of people say it's
[39:31.780 --> 39:32.820]  a PR puff piece.
[39:32.820 --> 39:38.020]  I saw the words PR puff piece, at least, I don't know, 20 times in response to
[39:38.020 --> 39:38.340]  this.
[39:38.340 --> 39:46.180]  And of course there's a certain truth to that in terms of, it's not like Steven
[39:46.180 --> 39:51.540]  Levy got free access for a year to just be a fly on the wall and watch the team
[39:51.540 --> 39:59.460]  work. He, you know, he, he got like one day of access to what Apple had planned
[39:59.460 --> 40:03.380]  as almost, you know, like a presentation of here's what we will reveal to you and
[40:03.380 --> 40:04.180]  talk to you about.
[40:04.740 --> 40:08.260]  And so of course what Apple revealed and talked to about it was meant to, you
[40:08.260 --> 40:11.060]  know, make Apple look good, right?
[40:11.060 --> 40:12.100]  There's no other way around it.
[40:12.100 --> 40:19.220]  But I mean, the alternative is that Steven Levy declines to take, to do the
[40:19.220 --> 40:19.620]  story.
[40:19.620 --> 40:21.300]  And I feel like the world is a worst place.
[40:21.300 --> 40:27.460]  I'm not saying that this is inaccurate, you know, that it's not a slanted look at
[40:27.460 --> 40:27.620]  it.
[40:27.620 --> 40:31.540]  It's obviously what Apple was willing to reveal, but there's a lot of interesting
[40:31.540 --> 40:33.620]  stuff in the article, I thought.
[40:33.620 --> 40:35.540]  Yeah, I agree with you.
[40:35.540 --> 40:43.860]  There's a difference between being like a minion and reporting and letting
[40:43.860 --> 40:47.780]  everybody know the circumstances under which you sort of got the information or
[40:47.780 --> 40:49.060]  you had the conversations.
[40:49.060 --> 40:49.620]  Right.
[40:49.620 --> 40:50.180]  You know what I mean?
[40:50.180 --> 41:00.900]  It's not like I think there's a false equivalence between I'm very carefully
[41:00.900 --> 41:05.860]  trying to pick my words here, but between sort of like a press that is very
[41:05.860 --> 41:14.900]  politically aligned and a press that gets some kind of access and lets you know
[41:14.900 --> 41:19.300]  they had that kind of access and then tells you what was said.
[41:19.300 --> 41:19.700]  Right.
[41:19.700 --> 41:24.660]  It's the context of the access is right there in the story, and you can judge it,
[41:24.660 --> 41:26.900]  be a critical reader and judge it for what you will.
[41:26.900 --> 41:27.380]  Exactly.
[41:27.380 --> 41:28.020]  Yeah.
[41:28.020 --> 41:29.220]  I mean, that's the baseline.
[41:29.220 --> 41:30.420]  Always be a critical leader.
[41:30.420 --> 41:43.780]  But especially with this current political cycle going on in the US, gauging
[41:43.780 --> 41:48.900]  the press is like, no, it's not always easy, but you shouldn't just throw everybody
[41:48.900 --> 41:54.340]  in one bucket and be like, well, I don't believe anything that anybody says.
[41:55.380 --> 42:01.380]  And he's very upfront, and I think he makes it very clear exactly what the
[42:01.380 --> 42:09.460]  context was and that's what you need as an intelligent, critical reader to sort
[42:09.460 --> 42:10.740]  of make your own decision.
[42:10.740 --> 42:11.060]  Right.
[42:11.060 --> 42:15.380]  And it's not like if you read it, and I read it very thoroughly, but it's not
[42:15.380 --> 42:22.340]  like Steven Levy was trying to make the argument that Siri is perfect or even
[42:22.340 --> 42:25.300]  great or far ahead of the competition.
[42:25.860 --> 42:31.220]  Apple might be making that argument, and he might quote them saying it, but he's
[42:31.220 --> 42:31.460]  not.
[42:32.500 --> 42:37.460]  Again, Steven Levy has been around the block before, and he's very, very well
[42:37.460 --> 42:40.180]  sourced at Google in particular.
[42:40.180 --> 42:47.940]  And also, Steven Levy is the type of guy who writes stuff that really stands
[42:47.940 --> 42:48.980]  up over time.
[42:48.980 --> 42:52.980]  Like the value of this article might be better 10, 15, 20 years from now than
[42:52.980 --> 42:57.380]  it is today in terms of looking at either where things went wrong for Apple
[42:57.380 --> 43:00.500]  or the beginning of where things went right in their AI.
[43:00.500 --> 43:04.500]  And it's written for the long term.
[43:04.500 --> 43:04.820]  Yeah.
[43:04.820 --> 43:12.020]  And you write about it, he wrote In the Plex, like a book about and if anybody
[43:12.980 --> 43:17.540]  is looking for a book to read on a hot summer day, In the Plex is definitely
[43:17.540 --> 43:18.660]  worth reading.
[43:18.660 --> 43:18.900]  Right.
[43:18.900 --> 43:24.500]  That's his look inside Google with extensive and long term access that he
[43:24.500 --> 43:24.740]  was.
[43:24.740 --> 43:25.220]  Oh, yeah.
[43:25.220 --> 43:29.780]  Like it's like years, years worth of reporting in that.
[43:29.780 --> 43:31.380]  Like that's hard work.
[43:31.380 --> 43:32.340]  And he did it.
[43:32.340 --> 43:38.900]  So this interview or piece carries all the more weight because he's familiar
[43:38.900 --> 43:39.860]  with both companies.
[43:40.340 --> 43:45.380]  And I think among people who read our stuff, listen to our shows, people
[43:45.380 --> 43:50.260]  who are listening to us talk right now, I feel like, hey, is Siri good, bad,
[43:50.260 --> 43:53.220]  mixed bag, whatever is probably one of the most contentious.
[43:53.940 --> 43:54.820]  I worry a lot.
[43:54.820 --> 43:55.300]  I do.
[43:55.300 --> 44:01.060]  That me in particular and the type of people I have on the show, that we're
[44:01.060 --> 44:06.340]  all just preaching to the choir and that we agree on so much of what's going
[44:06.340 --> 44:08.900]  on that what's the point.
[44:08.900 --> 44:12.580]  I feel like that Siri and Apple's machine learning efforts and stuff like
[44:12.580 --> 44:15.780]  that is a great point where there's, I know that there are people listening
[44:15.780 --> 44:17.860]  right now who think Siri is a big pile of dog shit.
[44:19.860 --> 44:22.740]  And those are, I think some of the people who are most frustrated with
[44:22.740 --> 44:25.460]  this article and think that it's a quote unquote PR puff piece because
[44:25.460 --> 44:28.980]  how can this article keep going on and on and not say that Siri is garbage
[44:28.980 --> 44:32.820]  because they, for whatever reason, they think Siri is garbage, which I
[44:32.820 --> 44:33.380]  disagree with.
[44:34.340 --> 44:35.380]  Well, there's two things here.
[44:39.380 --> 44:41.860]  I don't think you can just unequivocally say that.
[44:43.060 --> 44:44.580]  That's a value judgment, right?
[44:44.580 --> 44:45.620]  It's up to everybody else.
[44:47.780 --> 44:51.860]  Which, man, that sounds like wishy-washy because, yeah, it could be garbage,
[44:51.860 --> 44:52.900]  but it's not.
[44:54.100 --> 44:54.900]  It's in the field.
[44:54.900 --> 44:55.460]  It works.
[44:55.460 --> 44:57.220]  I think people use it all the time.
[44:57.220 --> 45:00.980]  It's in everything from the watch to now the Mac.
[45:02.580 --> 45:07.460]  Soon, the Mac, it's in beta, the Apple TV, all the iOS stuff.
[45:09.460 --> 45:10.740]  Working pretty well.
[45:10.740 --> 45:12.820]  Now, does it answer everything perfectly?
[45:12.820 --> 45:13.320]  No.
[45:15.300 --> 45:17.060]  But I think it's more audacious.
[45:17.060 --> 45:22.180]  Like it has, the aspirational goal is higher than I think something like
[45:22.180 --> 45:27.460]  the Amazon Echo is, which is what it often gets compared to.
[45:27.460 --> 45:32.100]  Or you know what I don't hear a lot about now is Google Now.
[45:32.100 --> 45:38.420]  I just read a story that Google made a change somehow recently and made
[45:39.140 --> 45:41.460]  something that they changed in Google Now has a lot of people upset.
[45:42.660 --> 45:45.140]  I don't hear as much about that, and I don't know why that is.
[45:45.140 --> 45:47.940]  I don't know if it's because I don't read enough Android stuff or...
[45:48.740 --> 45:49.220]  Maybe.
[45:49.220 --> 45:50.500]  We should talk to it, hey?
[45:50.500 --> 45:53.700]  But here's what I think.
[45:54.900 --> 45:59.060]  This goes unsaid in this article, but I do feel that the disadvantage
[45:59.060 --> 46:03.620]  that Google has with Now, and this might change coming up later this year
[46:03.620 --> 46:08.900]  because they preannounced their Echo-like device, the little home speaker system.
[46:12.340 --> 46:18.740]  This whole AI bot assistant type thing, it makes intuitive sense.
[46:18.740 --> 46:23.860]  This is not a very profound observation, but as we go on and we live with
[46:23.860 --> 46:26.420]  these things, it's shown to be more and more true.
[46:26.420 --> 46:27.540]  It can't be part of an app.
[46:27.540 --> 46:30.020]  It has to be part of the system on the device.
[46:32.180 --> 46:35.300]  You have to be able to say, hey dingus, to your thing.
[46:35.300 --> 46:38.900]  It's like going to open the Google app on your iPhone first and then
[46:38.900 --> 46:39.700]  speaking into it.
[46:41.940 --> 46:42.820]  What's the point?
[46:42.820 --> 46:45.220]  The whole point of the voice-driven interface is that you don't have to
[46:45.220 --> 46:46.260]  fish an app out.
[46:46.260 --> 46:49.620]  Yeah, I'm coming to think that maybe apps are...
[46:53.620 --> 46:55.140]  Not a dead end, but it's like...
[46:56.180 --> 46:57.940]  It's not a path for this sort of voice.
[46:57.940 --> 47:00.500]  It's certainly not a path for this kind of thing.
[47:01.220 --> 47:04.900]  And we've had it for what, 30 years now?
[47:06.900 --> 47:09.460]  Well, we've envisioned it since 1968 with Howl.
[47:10.020 --> 47:10.500]  Yeah.
[47:10.500 --> 47:11.700]  Oh, oh, sorry.
[47:11.700 --> 47:13.140]  You mean, I just mean apps.
[47:13.780 --> 47:14.500]  Oh, apps.
[47:14.500 --> 47:17.940]  I'm like, you know, maybe apps are like, maybe that shouldn't be the focus,
[47:17.940 --> 47:20.340]  you know, and not necessarily do the open doc thing.
[47:21.140 --> 47:22.740]  But when people talk to...
[47:22.740 --> 47:24.100]  We are totally right with Howl.
[47:24.100 --> 47:27.780]  It's like, Howl doesn't run apps.
[47:27.780 --> 47:28.260]  Right.
[47:28.260 --> 47:29.540]  You don't ask Howl to like...
[47:30.180 --> 47:32.260]  Howl, launch the Podbador app.
[47:32.260 --> 47:32.580]  Right.
[47:32.580 --> 47:36.020]  Or launch the Howl app and then talk to Howl.
[47:36.020 --> 47:37.860]  No, it's just, he's just there.
[47:37.860 --> 47:38.360]  Right.
[47:41.300 --> 47:44.420]  That stupid Podbador app should have been updated though.
[47:44.420 --> 47:44.980]  Yeah.
[47:44.980 --> 47:48.580]  Before they went off to Jupiter, they really should have updated that sucker.
[47:51.620 --> 47:53.380]  But I'll just read an example.
[47:53.380 --> 47:57.060]  Here's in my tweet, in my Twitter replies to me.
[47:57.060 --> 47:59.860]  I won't call the guy out because I think he's not asking to be called out.
[47:59.860 --> 48:00.500]  It's not rude.
[48:00.500 --> 48:02.660]  But there's a guy who sent me a tweet.
[48:02.660 --> 48:07.860]  What's Gruber, what's with Apple doing a press victory lap, I think he meant,
[48:07.860 --> 48:09.860]  about how great they think Siri is?
[48:09.860 --> 48:12.580]  It's laughably poor compared to anything else.
[48:12.580 --> 48:15.620]  I really disagree with that.
[48:15.620 --> 48:19.700]  I think there are clearly areas where, you know, I think what's interesting
[48:19.700 --> 48:22.420]  about this is that the big players in this are all better.
[48:23.380 --> 48:26.020]  They have different strengths and weaknesses.
[48:26.020 --> 48:26.580]  Yeah.
[48:26.580 --> 48:27.220]  Oh, yeah.
[48:27.220 --> 48:27.460]  Yeah.
[48:28.180 --> 48:29.620]  Which makes it cool, right?
[48:29.620 --> 48:30.120]  Right.
[48:31.140 --> 48:34.500]  I keep going back to a couple of examples.
[48:34.500 --> 48:39.060]  I have an Amazon Echo here in the kitchen and I barely use it.
[48:39.060 --> 48:42.580]  But I think I'd use it more if we had more of the home automation stuff
[48:42.580 --> 48:44.580]  that you can hook up to it, like turning the lights on and stuff.
[48:45.300 --> 48:46.660]  Did you buy that or did you?
[48:46.660 --> 48:47.540]  No, I bought it.
[48:47.540 --> 48:48.040]  Okay.
[48:49.380 --> 48:49.620]  Sorry.
[48:49.620 --> 48:54.740]  That's a weird question, but I'm trying to gauge your engagement with it, I guess.
[48:54.740 --> 48:55.220]  Yeah.
[48:55.220 --> 48:55.460]  Yeah.
[48:55.460 --> 49:02.580]  But for example, if you ask the Echo and Alexa anything about the weather,
[49:02.580 --> 49:06.580]  all you get is the exact same canned weather report for where you are.
[49:06.580 --> 49:12.740]  So if you say, um, what's, what's the weather you get, you get a weather
[49:12.740 --> 49:16.340]  report with like the expected highs and lows and whether it's going to rain.
[49:16.340 --> 49:19.060]  And if you say, what is the current temperature?
[49:19.060 --> 49:22.340]  Instead of giving you the temperature, you get the exact same weather report.
[49:22.340 --> 49:24.500]  If you say, you just can't let temperature go, man.
[49:24.500 --> 49:26.020]  I know you can't let it go.
[49:26.020 --> 49:27.700]  It's in Celsius or Fahrenheit.
[49:27.700 --> 49:28.900]  It's in Fahrenheit.
[49:28.900 --> 49:31.860]  Oh, well, so at least it's, you know, it's on the good side.
[49:31.860 --> 49:37.700]  Although I wonder what would happen if, if, if I just said to, you know,
[49:37.700 --> 49:43.220]  Hey, dingus, uh, please, please give me the temperature in Celsius instead of
[49:43.220 --> 49:44.100]  Fahrenheit from now on.
[49:44.100 --> 49:44.980]  I wonder if that would work.
[49:44.980 --> 49:46.260]  I'll have to try that.
[49:46.260 --> 49:51.140]  Um, but I, if you ask for the humidity, you get the weather report and it, the,
[49:51.140 --> 49:53.700]  the weather report doesn't even include the humidity.
[49:53.700 --> 49:54.500]  Yeah.
[49:54.500 --> 49:58.180]  So it understands that you asking about the humidity is you asking about the
[49:58.180 --> 50:01.940]  weather, but the answer is just the same exact word for word canned weather
[50:01.940 --> 50:02.500]  report.
[50:02.500 --> 50:06.260]  If you ask Siri those questions, you get the actual answer.
[50:06.260 --> 50:08.980]  If you ask for the temperature, you just get the temperature.
[50:08.980 --> 50:11.140]  If you ask for the weather, you get a full weather report.
[50:11.140 --> 50:14.820]  And I even tried asking for the humidity and it, and Siri can tell you the
[50:14.820 --> 50:15.620]  current humidity.
[50:16.660 --> 50:20.340]  So there's an area where I could say unambiguously, Siri is better than
[50:20.340 --> 50:21.140]  Alexa.
[50:21.140 --> 50:25.860]  And on sports is another example where Alexa can tell you some basic stuff
[50:25.860 --> 50:26.420]  about sports.
[50:26.420 --> 50:30.180]  I think like scores and stuff like that, but Siri can tell you things like the
[50:30.180 --> 50:32.260]  Vegas betting odds and who's favored in a game.
[50:34.100 --> 50:37.780]  I mean, is that a big difference?
[50:37.780 --> 50:38.660]  I mean, for me it is.
[50:38.660 --> 50:46.340]  Cause I'm a gambling junkie.
[50:46.340 --> 50:47.140]  What's your tweet?
[50:47.140 --> 50:47.940]  I don't drink.
[50:47.940 --> 50:48.580]  I don't gamble.
[50:49.220 --> 50:49.700]  I don't.
[50:49.700 --> 50:50.180]  Yeah.
[50:50.180 --> 50:56.260]  My only vice is buying a new iPhone every year and that and lying about
[50:56.260 --> 50:57.460]  drinking and gambling.
[50:59.700 --> 51:01.060]  That's still the funniest one.
[51:02.020 --> 51:03.860]  It's a pretty clever, a little logical.
[51:03.860 --> 51:04.180]  Yeah.
[51:04.180 --> 51:07.060]  Like I was like, Oh man, I was cracking up when I read that.
[51:09.300 --> 51:19.140]  Yeah, no, I think Siri is seems to have a broader area that it aspires to
[51:19.140 --> 51:19.540]  cover.
[51:19.540 --> 51:27.860]  And perhaps in some places it doesn't cover it as well as what the more
[51:27.860 --> 51:29.860]  focused things do.
[51:31.780 --> 51:40.660]  Which is interesting because Apple typically narrows things down to the
[51:40.660 --> 51:42.020]  solvable problems, right?
[51:42.020 --> 51:42.260]  Right.
[51:43.940 --> 51:47.380]  But in the case of Siri, it seems like they've gone deep.
[51:47.380 --> 51:53.780]  Like it's interesting because they also bought the company that made Siri.
[51:53.780 --> 52:00.260]  So there could be a cultural divide a little bit there, which I don't know,
[52:00.260 --> 52:05.940]  but it's possible because you would think that Apple would be shipping
[52:05.940 --> 52:08.820]  something like the Echo, which does way less.
[52:09.540 --> 52:11.780]  But when you ask it to do something, does it?
[52:11.780 --> 52:12.020]  Right.
[52:12.020 --> 52:18.020]  And instead they've got this thing that when you ask it to do something, it
[52:18.020 --> 52:28.340]  will make a best effort to answer any spoken question and give you like a
[52:28.340 --> 52:28.900]  good answer.
[52:30.500 --> 52:32.660]  Can you wrap your head around how hard that is?
[52:32.660 --> 52:33.140]  It is.
[52:33.140 --> 52:33.860]  I couldn't do that.
[52:33.860 --> 52:38.100]  Well, I mean, I think like five of the things that Siri could help you with
[52:38.100 --> 52:39.540]  and be like, I have no idea.
[52:39.540 --> 52:43.140]  I think all of us who've ever programmed, or at least if you started
[52:43.140 --> 52:48.580]  programming as a kid, have written, tried to write like a choose your own
[52:48.580 --> 52:54.020]  adventure type thing, at least in the days when starting the program
[52:54.020 --> 52:56.820]  meant you were around like a little command line and you just build up
[52:56.820 --> 53:02.180]  a list of if-then statements for what the input was, right?
[53:02.180 --> 53:03.620]  And that just doesn't work.
[53:03.620 --> 53:07.780]  Like you'd have to have like an exact match for every single input.
[53:07.780 --> 53:11.620]  You can do that, it's tedious, but that's not how Siri works at all.
[53:11.620 --> 53:12.100]  Yeah.
[53:12.100 --> 53:15.300]  Well, and they're, you know, they're very, very ambitious about it.
[53:15.300 --> 53:18.740]  I mean, and they can have examples of things that work where in this
[53:18.740 --> 53:22.500]  story, the Steven Levy story, Eddy Cue shows that with integrating with
[53:22.500 --> 53:28.980]  Square Cash, where he says, use Square Cash to send Jane $20 and Siri
[53:28.980 --> 53:33.060]  interprets it and opens the Square Cash app to send his wife $20.
[53:33.940 --> 53:35.380]  And he says it differently.
[53:35.380 --> 53:38.420]  He says, shoot $20 to my wife.
[53:38.420 --> 53:39.700]  You know, he can call her Jane.
[53:39.700 --> 53:41.140]  He can call her his wife.
[53:41.140 --> 53:42.660]  He can say, send $20.
[53:42.660 --> 53:43.780]  He can say, shoot $20.
[53:44.900 --> 53:48.660]  I mean, shoot $20 is actually, linguistically, is pretty advanced.
[53:48.660 --> 53:53.300]  Yeah, I would never say that, but I could see somebody, like, I would
[53:53.300 --> 53:54.100]  understand it.
[53:54.100 --> 53:56.820]  If somebody told me that, I'd be like, yeah, I get it.
[53:56.820 --> 53:58.500]  Like, send them some money.
[53:58.500 --> 54:00.100]  I don't even know how many of those things work.
[54:00.100 --> 54:05.540]  Like, even me as being generally on the, you know, I'm on the positive
[54:05.540 --> 54:07.700]  end of the spectrum of where I think Siri is.
[54:07.700 --> 54:09.460]  And I know that a lot of people aren't, but I am.
[54:09.460 --> 54:11.300]  I'm a fan, and I think they're doing well.
[54:11.300 --> 54:12.740]  Even I might be underestimating.
[54:12.740 --> 54:16.660]  Like, I wonder if you can, like, tell Siri, like, to get my wife on the
[54:16.660 --> 54:16.980]  horn.
[54:18.740 --> 54:21.380]  Like, would it know that you want to make a phone call?
[54:21.380 --> 54:24.980]  Yeah, that's like, that's like Trappi John in MASH.
[54:24.980 --> 54:27.140]  Because I would never think that I would never think to try that with
[54:27.140 --> 54:27.640]  a computer.
[54:27.640 --> 54:29.960]  Oh, well, no.
[54:29.960 --> 54:31.160]  My dad says that all the time.
[54:31.160 --> 54:34.120]  My dad probably says to get somebody on the horn more than he even
[54:34.120 --> 54:35.560]  says I talk to him on the phone.
[54:35.560 --> 54:36.680]  I love that expression.
[54:37.560 --> 54:39.080]  I really love that expression.
[54:39.080 --> 54:39.800]  That's old school.
[54:40.520 --> 54:41.400]  You would like my dad.
[54:41.960 --> 54:42.600]  I'm sure.
[54:42.600 --> 54:46.920]  Yeah, we should come to a family gathering.
[54:46.920 --> 54:47.240]  Exactly.
[54:47.240 --> 54:49.400]  Yeah, no, like, yeah, that is awesome.
[54:51.000 --> 54:55.240]  Especially because it evokes the old school headsets, right?
[54:55.240 --> 54:57.720]  We have to pick it up and like, there's no buttons on it.
[54:57.720 --> 55:00.280]  It's just a horn kind of stick to your head.
[55:00.840 --> 55:01.160]  All right.
[55:01.160 --> 55:01.640]  Why?
[55:01.640 --> 55:05.000]  Here's the big question I have is, why does this article exist?
[55:05.000 --> 55:10.040]  Why did Apple agree to give Levy access to write this article?
[55:11.320 --> 55:11.720]  I don't know.
[55:11.720 --> 55:14.440]  They seem to have been on a PR blitz recently.
[55:14.440 --> 55:15.480]  Yeah, definitely.
[55:15.480 --> 55:19.560]  I mean, it's definitely a bit, you know, big picture answer is this
[55:19.560 --> 55:22.040]  is part of the new, more open Tim Cook's Apple.
[55:22.040 --> 55:25.640]  This is part of the Apple where Craig Federighi and
[55:25.640 --> 55:27.720]  Phil Schiller go on this show.
[55:27.720 --> 55:31.960]  And Craig Federighi goes deep on stage in front of a live audience
[55:31.960 --> 55:36.520]  on the differential privacy, which is a big part of the same story.
[55:36.520 --> 55:37.000]  Oh, yeah.
[55:37.000 --> 55:37.640]  No, no, yeah.
[55:37.640 --> 55:43.080]  The differential privacy is a huge part of this AI learning thing.
[55:43.960 --> 55:44.520]  I don't know.
[55:44.520 --> 55:47.960]  Old Apple, but old Apple not only wouldn't show up on Joe
[55:47.960 --> 55:51.800]  Random podcast and talk about it in front of a live audience.
[55:51.800 --> 55:54.200]  They wouldn't talk about differential privacy period, right?
[55:54.200 --> 55:56.120]  At this point, you're not Joe Random podcast.
[55:56.120 --> 55:56.520]  I know.
[55:56.520 --> 55:57.080]  I know.
[55:57.080 --> 56:00.840]  But they wouldn't have gone on my podcast six, seven, eight years ago
[56:01.400 --> 56:02.360]  and talked about this.
[56:02.360 --> 56:05.640]  And they wouldn't have talked in detail about how it worked.
[56:05.640 --> 56:09.560]  You know, that they didn't talk about how anything works.
[56:10.600 --> 56:10.920]  Right.
[56:10.920 --> 56:11.160]  Right.
[56:11.720 --> 56:13.480]  That would have just been part of the black box.
[56:14.040 --> 56:14.520]  Yes.
[56:14.520 --> 56:16.680]  No, they would never talk about that.
[56:16.680 --> 56:17.960]  That shocked me, actually.
[56:17.960 --> 56:22.280]  That you're not in a bad way, I was happy for you, but the access
[56:22.280 --> 56:25.960]  that you got was pretty surprising.
[56:25.960 --> 56:26.760]  It's definitely.
[56:26.760 --> 56:28.040]  But maybe it shouldn't be.
[56:28.040 --> 56:30.200]  And I think that the fact that they're talking to Steven Levy
[56:30.200 --> 56:31.160]  shouldn't be surprising.
[56:32.440 --> 56:38.920]  I think that one of the aspects of Tim Cook's Apple, the new open
[56:38.920 --> 56:45.080]  Apple, that is different from Steve Jobs' old Apple, isn't just
[56:45.080 --> 56:47.640]  that they're open for the sake of openness.
[56:47.640 --> 56:51.800]  I think it is very specific.
[56:51.800 --> 56:56.760]  And I think it is that they wish to be better understood as a company.
[56:57.400 --> 57:02.840]  And when they perceive that they are being misunderstood or that
[57:02.840 --> 57:09.720]  the conventional wisdom about X within Apple is wrong, they want
[57:09.720 --> 57:13.320]  to do what they can to correct that.
[57:13.320 --> 57:17.080]  Whereas I feel like with Jobs, it was like, if I really do, I mean,
[57:17.080 --> 57:20.120]  this is a little flippant, but I really think that with Steve
[57:20.120 --> 57:23.720]  Jobs, it was like, well, everybody thinks we're blank, but we're
[57:23.720 --> 57:24.360]  not.
[57:24.360 --> 57:27.080]  And I think Jobs' attitude was, well, screw him.
[57:27.080 --> 57:27.640]  I don't care.
[57:27.640 --> 57:30.440]  Who gives a crap if they understand us or not?
[57:30.440 --> 57:33.480]  Or maybe it's even better if we're misunderstood because, you know.
[57:34.200 --> 57:35.720]  Nobody's going to see us coming.
[57:35.720 --> 57:37.960]  Everybody wants to treat us like the dummy.
[57:37.960 --> 57:39.640]  Well, we'll just take it.
[57:39.640 --> 57:40.200]  We'll show them.
[57:40.200 --> 57:40.920]  Yeah, we'll show them.
[57:40.920 --> 57:46.200]  Whereas I feel like Tim Cook's Apple is frustrated by being
[57:46.200 --> 57:48.200]  misunderstood and seeks to correct it.
[57:48.200 --> 57:54.280]  And in this case, I believe that they are frustrated with the
[57:54.280 --> 58:00.120]  conventional wisdom that Apple doesn't get AI, may not even care
[58:00.120 --> 58:06.200]  about it, and that they are, while the rest of the industry, led by
[58:06.200 --> 58:11.480]  Facebook and Google and perhaps Microsoft, are racing ahead on
[58:11.480 --> 58:15.160]  this stuff, Apple is going to be left behind with, you know, pieces
[58:15.160 --> 58:18.680]  of glass that you touch, whereas everybody else is moving towards
[58:18.680 --> 58:19.560]  these AI bots.
[58:19.560 --> 58:23.000]  And I think Apple is saying, no, we are deadly serious.
[58:23.000 --> 58:23.880]  We are different.
[58:23.880 --> 58:27.720]  We are different in two big regards, which I'll get to, but we
[58:27.720 --> 58:28.920]  are deadly serious about this.
[58:28.920 --> 58:30.760]  And we think we're doing pretty well.
[58:32.920 --> 58:33.960]  Yeah, I agree with that.
[58:33.960 --> 58:35.480]  I feel like they want to color that.
[58:35.480 --> 58:38.200]  So here's a paragraph from the story.
[58:38.200 --> 58:41.800]  I don't want to play off, but one of the differences between
[58:41.800 --> 58:44.360]  Apple and other companies here, here's a read from Levy.
[58:44.360 --> 58:46.360]  Though Federighi doesn't say that this approach might be a
[58:46.360 --> 58:49.960]  necessity, Apple's penchant for secrecy puts it at a disadvantage
[58:49.960 --> 58:53.080]  against competitors who encourage their star computer scientists
[58:53.080 --> 58:55.720]  to widely share research with the world.
[58:55.720 --> 58:58.840]  Quote, our practices tend to reinforce, this is Federighi talking,
[58:58.840 --> 59:02.280]  our practices tend to reinforce a natural selection bias.
[59:02.280 --> 59:05.720]  Those who are interested in working as a team to deliver
[59:05.720 --> 59:09.720]  a great product versus those whose primary motivation is publishing.
[59:11.320 --> 59:14.040]  So back to Steven Levy, if while improving an Apple product,
[59:14.040 --> 59:17.800]  scientists, product, scientists happen to make breakthroughs
[59:17.800 --> 59:18.840]  in the field, that's great.
[59:19.800 --> 59:24.600]  But, says EdiQ, but we are driven by a vision of the end result.
[59:25.800 --> 59:28.360]  And I think that what they're getting at here is that
[59:28.360 --> 59:33.800]  the researchers in the larger community who are largely focused on publishing,
[59:33.800 --> 59:37.480]  see Apple as out of it because Apple is, nobody from Apple is publishing.
[59:38.680 --> 59:38.920]  Yeah.
[59:41.880 --> 59:46.520]  I think the security area had this at one point.
[59:46.520 --> 59:46.920]  Yes.
[59:46.920 --> 59:48.200]  Yes, definitely.
[59:48.200 --> 59:54.040]  That Apple was outside the mainstream in the security industry.
[59:54.040 --> 59:55.560]  Because they weren't participating in.
[59:55.560 --> 59:55.880]  Right.
[59:55.880 --> 59:56.120]  Yeah.
[59:56.120 --> 59:59.240]  And then they don't, they didn't answer, you know, you'd send in,
[01:00:00.840 --> 01:00:03.880]  they didn't give, they, they, they were even, they were even dinged
[01:00:03.880 --> 01:00:07.320]  for not giving credit to people for when they'd fix the bugs, you know?
[01:00:07.320 --> 01:00:07.560]  Yeah.
[01:00:08.280 --> 01:00:12.440]  On which probably they should have, and they do now.
[01:00:13.000 --> 01:00:14.600]  And that's another example that's changed.
[01:00:14.600 --> 01:00:17.560]  The head, Apple's head chief engineer for security.
[01:00:17.560 --> 01:00:19.240]  Yeah, he's had Black Hat recently.
[01:00:19.240 --> 01:00:19.560]  Right.
[01:00:19.560 --> 01:00:21.400]  And gave a very well-regarded talk.
[01:00:21.400 --> 01:00:25.240]  Like it's been a couple of years since Apple had spoken at Black Hat.
[01:00:25.240 --> 01:00:29.160]  And the last time they did, it was sort of panned because it was deemed
[01:00:30.440 --> 01:00:34.840]  insufficiently detailed, you know, that it was just sort of painting in broad strokes.
[01:00:34.840 --> 01:00:40.440]  Whereas this talk that the guy gave, you know, last month at Black Hat was very detailed about
[01:00:40.440 --> 01:00:40.840]  some things.
[01:00:40.840 --> 01:00:45.320]  And that's where they introduced the new bug bounty program, you know, which, but
[01:00:45.320 --> 01:00:48.520]  Talked about unencrypted kernel caches.
[01:00:48.520 --> 01:00:54.040]  Like, I mean, whatever topic was on the table for Apple security.
[01:00:54.040 --> 01:00:55.480]  They were, he was on it.
[01:00:55.480 --> 01:00:57.640]  He was like, explained it great.
[01:00:57.640 --> 01:00:58.760]  Like these people are brilliant.
[01:00:58.760 --> 01:01:01.880]  Like they're in, they're not dummies.
[01:01:04.840 --> 01:01:11.880]  With the proviso that I really do think that like serious academic research is best shared
[01:01:11.880 --> 01:01:15.160]  so that it can be checked.
[01:01:15.160 --> 01:01:15.400]  Right.
[01:01:16.600 --> 01:01:19.080]  Because that's how science works.
[01:01:19.080 --> 01:01:25.000]  You know, I kind of agree with the fact that like, say, well, we're going to build something
[01:01:25.000 --> 01:01:26.040]  and then we're going to ship it.
[01:01:26.040 --> 01:01:28.600]  And then you can judge it by its merits.
[01:01:29.480 --> 01:01:35.000]  I, I, I appreciate that approach because all of the mistakes and stuff along the way may
[01:01:35.000 --> 01:01:41.720]  be interesting, but it's what you actually get to that, that is the, it's the goal.
[01:01:41.720 --> 01:01:47.960]  And it is the, you know, it's the thing that everybody should be thinking about rather
[01:01:47.960 --> 01:01:49.160]  than all the mistakes.
[01:01:49.160 --> 01:01:53.160]  Levi's article even mentions that Apple is making an exception to the, the general, you
[01:01:53.160 --> 01:01:55.640]  know, we don't really publish papers about the work we do.
[01:01:55.640 --> 01:01:57.080]  We just use it to make great products.
[01:01:57.080 --> 01:02:01.880]  They're making an exception on differential privacy, which they consider to be such a
[01:02:01.880 --> 01:02:06.120]  breakthrough and such a big part of what they're doing that they don't, you know, they're,
[01:02:06.120 --> 01:02:10.040]  they're, they're, they are having their research is behind it published what they're doing
[01:02:10.040 --> 01:02:13.160]  because they want everybody else to get on board with it as well.
[01:02:13.160 --> 01:02:16.440]  It's not just that it's the compression thing that they did last year.
[01:02:16.440 --> 01:02:22.040]  It's, they've got so much open source stuff going on, like WebKit's open source, Chrome,
[01:02:22.760 --> 01:02:24.520]  the OS, did they call it Chrome?
[01:02:24.520 --> 01:02:25.160]  What do they call it?
[01:02:26.040 --> 01:02:27.320]  Look, there is Chrome OS.
[01:02:27.320 --> 01:02:27.960]  I don't, I mean, I don't know.
[01:02:27.960 --> 01:02:28.280]  Yeah.
[01:02:28.280 --> 01:02:30.680]  Chrome OS, Chrome browser, it's all WebKit.
[01:02:31.400 --> 01:02:34.760]  It's being hacked a lot, but I mean, that's Apple's stuff.
[01:02:35.640 --> 01:02:42.520]  Since 97, 97, Apple has been releasing huge chunks of open source software.
[01:02:42.520 --> 01:02:52.200]  Well, Chrome is a perfect example of why some people would argue, you know, against open
[01:02:52.200 --> 01:02:57.800]  sourcing stuff because it's, you know, it, it, it, is it the, you know, quote unquote,
[01:02:57.800 --> 01:03:02.920]  worst case scenario where here's this thing that Apple did WebKit and put all this work
[01:03:02.920 --> 01:03:09.240]  into, and Google used to be an active participant in, in submitting patches to WebKit.
[01:03:09.240 --> 01:03:13.400]  And at a certain point, Google and Apple had enough differences on the future of WebKit
[01:03:13.400 --> 01:03:15.320]  where Google said, we're going to fork this.
[01:03:15.320 --> 01:03:16.280]  And what do they call the new one?
[01:03:16.280 --> 01:03:22.920]  Blink is, is there, but Blink was at, you know, when it Blink started was just a copy
[01:03:22.920 --> 01:03:23.880]  and paste of WebKit.
[01:03:23.880 --> 01:03:28.840]  And then it, you know, when it's, they went there different ways, but here, well, I mean,
[01:03:28.840 --> 01:03:31.880]  the process models were wanting to be different, like the whatever.
[01:03:31.880 --> 01:03:37.480]  But so a thing that, you know, but a thing that was an Apple led project WebKit now serves
[01:03:37.480 --> 01:03:43.080]  as the foundation for an entire competing operating system, you know, that, that, and
[01:03:43.080 --> 01:03:46.920]  it really does compete against Apple, like in education where, where I think Chrome is,
[01:03:46.920 --> 01:03:52.520]  you know, Chromebooks are probably the dominant device in education, which is the argument
[01:03:52.520 --> 01:03:57.000]  that somebody would make against participating, you know, a corporation participating in open
[01:03:57.000 --> 01:04:00.600]  source is that, Hey, our competitors can take our work and use it against us.
[01:04:00.600 --> 01:04:05.960]  And that, you know, yeah, I think Melton has heard both sides of that.
[01:04:05.960 --> 01:04:11.240]  So Don Melton, a mutual friend, he's been on my show a couple of times.
[01:04:11.240 --> 01:04:20.600]  He started WebKit and he's told me that it can go either way, like one, one month, they're
[01:04:20.600 --> 01:04:26.680]  like, what the fuck, man, why like these people are just taking our work.
[01:04:26.680 --> 01:04:29.560]  And then like another month, it's like, Oh, that's brilliant.
[01:04:29.560 --> 01:04:30.440]  Good, good choice.
[01:04:30.440 --> 01:04:32.600]  So I don't, I really don't know.
[01:04:32.600 --> 01:04:41.000]  It's probably somewhere in the middle, but I mean Avi Tvenian and like wrote the mock
[01:04:41.000 --> 01:04:49.080]  kernel and he came over with Next and Apple has been open sourcing a lot of their OS stuff
[01:04:49.080 --> 01:04:54.440]  for years, like at this point, 20 years.
[01:04:56.600 --> 01:05:00.440]  And I think it's kind of the right thing to do.
[01:05:00.440 --> 01:05:02.520]  I think they're making the right choice.
[01:05:02.520 --> 01:05:08.600]  It's, it's weird because there's a new Apple kind of thing that came in with, you know,
[01:05:08.600 --> 01:05:17.160]  like when Next came in that had a fair amount of academic or academia feeling to it, at
[01:05:17.160 --> 01:05:18.120]  least.
[01:05:18.120 --> 01:05:20.760]  Certainly they were selling into the academic market.
[01:05:23.160 --> 01:05:27.720]  I mean, they shipped, they shipped the collective works of Shakespeare for crying out loud.
[01:05:27.720 --> 01:05:34.280]  Like nobody wants that on their home computer unless you're in academia.
[01:05:37.480 --> 01:05:42.200]  But I think that has kind of permeated the culture to a certain extent.
[01:05:43.880 --> 01:05:48.600]  But what they don't do is share user facing work, right?
[01:05:49.160 --> 01:05:53.160]  Like the, you know, the Windows Server app kit, UI kit.
[01:05:53.160 --> 01:05:56.920]  Well, none of that is like open to the public.
[01:05:56.920 --> 01:06:03.720]  And that's because that's where their value is like, and they are right to protect it.
[01:06:03.720 --> 01:06:08.520]  And so with Siri, I think that they're putting that in the same bucket.
[01:06:09.640 --> 01:06:12.760]  That's, that's where the interface with the user, right?
[01:06:12.760 --> 01:06:13.720]  What's Apple good at?
[01:06:13.720 --> 01:06:15.480]  What's the value interfacing with the user?
[01:06:16.920 --> 01:06:22.600]  Why, you know, why are they going to write up all the papers about exactly how they do
[01:06:22.600 --> 01:06:23.320]  it?
[01:06:23.320 --> 01:06:24.040]  Yeah.
[01:06:24.040 --> 01:06:27.960]  So one of the things that the Levy article mentions, and there's even a quote from somebody
[01:06:27.960 --> 01:06:31.960]  is that the people like leading, leading minds in the AI community are like, well, who are
[01:06:31.960 --> 01:06:36.680]  the top five, you know, who among the top five brains and AI does Apple have on their
[01:06:36.680 --> 01:06:37.160]  staff?
[01:06:37.160 --> 01:06:38.760]  And, you know, show me.
[01:06:38.760 --> 01:06:39.960]  And there's a lot of skepticism.
[01:06:41.000 --> 01:06:47.240]  One of the internet to me, one of the interesting things was that Federighi said that a lot
[01:06:47.240 --> 01:06:50.920]  of their people who are doing this machine learning don't really come from the AI background.
[01:06:50.920 --> 01:06:51.400]  Here's the quote.
[01:06:51.400 --> 01:06:55.640]  We hire people who are very smart in fundamental domains of mathematics, statistics, programming
[01:06:55.640 --> 01:06:57.240]  languages, cryptography.
[01:06:57.240 --> 01:07:01.400]  It turns out a lot of these kinds of core talents translate beautifully to machine learning.
[01:07:01.400 --> 01:07:06.760]  So it's people, you know, that, and, you know, if you're smart and you're a good programmer,
[01:07:06.760 --> 01:07:08.920]  you could be, you can do all sorts of things, right?
[01:07:08.920 --> 01:07:14.200]  Like, you know, I know a guy who, you know, used to do a lot of graphics programming for
[01:07:14.200 --> 01:07:15.720]  games, right?
[01:07:15.720 --> 01:07:16.280]  Yeah.
[01:07:16.280 --> 01:07:16.600]  Yeah.
[01:07:16.600 --> 01:07:19.000]  And then he, you know, does other things as well.
[01:07:19.000 --> 01:07:25.160]  That was seems like a career, but so I think you would agree with me that, you know, firsthand
[01:07:25.160 --> 01:07:30.120]  that, you know, you, you can come at, you can enter a new field in programming and be
[01:07:30.120 --> 01:07:33.880]  good at it, get up to speed just because it's a lot of this stuff.
[01:07:33.880 --> 01:07:35.960]  It doesn't have to be its own domain.
[01:07:35.960 --> 01:07:36.840]  Yes, I agree.
[01:07:37.640 --> 01:07:43.160]  I think, and I really, because I actually really do agree with you, but I'm going to
[01:07:43.160 --> 01:07:44.760]  do the devil's advocate thing.
[01:07:44.760 --> 01:07:52.520]  I think the idea is that the backend knowledge and the way to structure a machine learning
[01:07:52.520 --> 01:08:01.480]  from a system, accepting input from billions of sources, and then kind of learning from
[01:08:01.480 --> 01:08:08.280]  that is not knowledge that is internal to Apple at this point.
[01:08:08.280 --> 01:08:09.400]  And I think that's the argument.
[01:08:09.400 --> 01:08:10.200]  I don't know if it's true.
[01:08:10.200 --> 01:08:16.920]  And I do know that this differential privacy thing is probably going to make it harder.
[01:08:16.920 --> 01:08:23.720]  And I like that it's going to make it harder because they're trying to, like, they're
[01:08:23.720 --> 01:08:26.040]  prioritizing privacy.
[01:08:26.040 --> 01:08:32.200]  Yeah, I think, and that's, I think that secondarily, I think that is one of the reasons Apple wanted
[01:08:32.200 --> 01:08:37.400]  this, you know, participated in this article is that they want to push back hard on the
[01:08:37.400 --> 01:08:45.320]  notion that the one way to do this machine learning style features, you know, that are
[01:08:45.320 --> 01:08:53.480]  exposed to end users is by collecting tons of data and doing it all server side that
[01:08:53.480 --> 01:08:58.520]  you can, you know, Apple is that this is one way that Apple is clearly going against the
[01:08:58.520 --> 01:09:00.360]  way that Facebook and Google work.
[01:09:00.360 --> 01:09:04.840]  But of course, that's the way Facebook and Google work is because they are fundamentally
[01:09:04.840 --> 01:09:07.560]  server side companies, right?
[01:09:07.560 --> 01:09:10.280]  Yeah, and Apple is fundamentally a device company.
[01:09:10.280 --> 01:09:15.800]  But Apple is effectively doing a lot of this stuff in parallel by having each and every
[01:09:15.800 --> 01:09:18.440]  individual device do the work.
[01:09:18.440 --> 01:09:24.600]  And, you know, the explicit in the article with Levy where a lot of this data is staying
[01:09:24.600 --> 01:09:31.800]  on the device, and therefore all of the the, you know, AI style analysis of it is doing
[01:09:31.800 --> 01:09:32.600]  it on the device.
[01:09:32.600 --> 01:09:35.480]  So, like, the face detection in the photos happens on the device.
[01:09:35.480 --> 01:09:40.680]  Yeah, I mean, I think the obvious assumption is that if you had a personal assistant, they
[01:09:40.680 --> 01:09:48.680]  could do everything that Siri or like the the ultimate version of Siri, like the best
[01:09:48.680 --> 01:09:50.120]  personal assistant you could ever have.
[01:09:50.760 --> 01:09:56.360]  Obviously, they're going to know everything about you because they need to in order to
[01:09:56.360 --> 01:09:57.400]  do their job.
[01:09:57.400 --> 01:10:04.680]  And that's true for a person, but I don't know if that needs to be true for, like, a
[01:10:04.680 --> 01:10:07.560]  system or like an artificial intelligence.
[01:10:10.200 --> 01:10:15.080]  It seems like the way to go, just because we can rationalize about that.
[01:10:15.080 --> 01:10:21.400]  It's like, okay, well, if I tell this person every little detail, they can, you know, try
[01:10:21.400 --> 01:10:21.880]  to help me.
[01:10:21.880 --> 01:10:25.880]  But I don't I don't know if that's the only way they're like this.
[01:10:25.880 --> 01:10:32.120]  Honestly, there's probably some hardcore mathematical proof that you could that you could work out
[01:10:32.120 --> 01:10:32.680]  this, right?
[01:10:32.680 --> 01:10:41.240]  Like, you could throw information at a thing that is obscured in some way, and it could
[01:10:41.240 --> 01:10:47.240]  come back with answers that are like incredibly accurate, but they still can't reasonably
[01:10:47.240 --> 01:10:52.280]  about you as a whole, which is where I think Apple's trying to go.
[01:10:52.280 --> 01:10:52.760]  Yeah.
[01:10:52.760 --> 01:10:55.720]  And, you know, we're skating to where the puck is going.
[01:10:55.720 --> 01:11:00.920]  I mean, it's not like Apple is going to stick with the A9 system on a chip and that there's
[01:11:00.920 --> 01:11:06.360]  not going to be an A10, an A11, A12, and that these chips aren't going to keep getting faster
[01:11:06.360 --> 01:11:07.160]  and faster and faster.
[01:11:07.160 --> 01:11:11.320]  I mean, five, six years from now, we're going to have iPhones that make the current iPhones
[01:11:11.320 --> 01:11:16.680]  look like, you know, like, you know, like, you know, like, you know, like, you know,
[01:11:16.680 --> 01:11:20.360]  like, you know, a joke in terms of the computational power.
[01:11:20.360 --> 01:11:24.120]  And it's just one of those things that the phone is going to have, you know, it's going
[01:11:24.120 --> 01:11:27.960]  to be easier and easier, I think, to do advanced computational work.
[01:11:29.560 --> 01:11:30.840]  Unless you needed a headphone jack.
[01:11:35.080 --> 01:11:39.160]  Anyway, I don't think I have anything else on this Steven Levy article, but I don't think
[01:11:39.160 --> 01:11:40.120]  it should be dismissed.
[01:11:40.120 --> 01:11:40.440]  Yes.
[01:11:40.440 --> 01:11:45.160]  Read it with a, you know, read it with an open mind and understand that, you know, this
[01:11:45.160 --> 01:11:47.560]  is exactly what Apple presented to Steven Levy.
[01:11:47.560 --> 01:11:50.360]  But I think there's a lot of interesting stuff to grok from that.
[01:11:50.360 --> 01:11:52.040]  Yes, I totally agree with you.
[01:11:53.240 --> 01:11:55.000]  All right, let me take a break and thank our next sponsor.
[01:11:55.000 --> 01:11:57.640]  It's our good friends, old time, longtime sponsors of the show.
[01:11:57.640 --> 01:11:58.600]  Warby Parker.
[01:11:58.600 --> 01:12:01.640]  Warby Parker makes buying glasses online easy and risk free.
[01:12:01.640 --> 01:12:08.280]  Go to warbyparker.com slash the talk show and order your free home try ons today.
[01:12:08.280 --> 01:12:12.760]  Warby Parker offers contemporary eyeglasses that are extremely affordable and fashion
[01:12:12.760 --> 01:12:13.480]  forward.
[01:12:13.480 --> 01:12:16.440]  They believe glasses should not cost as much as an iPhone.
[01:12:16.440 --> 01:12:21.160]  They offer prescription eyeglasses, prescription eyeglasses at just 95 bucks.
[01:12:21.720 --> 01:12:23.480]  And that includes the prescription lenses.
[01:12:23.480 --> 01:12:26.200]  They don't upsell you on the coatings and stuff like that.
[01:12:26.200 --> 01:12:27.720]  The anti glare and the anti scratch.
[01:12:27.720 --> 01:12:28.440]  You just get them.
[01:12:28.440 --> 01:12:29.720]  You get anything you want.
[01:12:29.720 --> 01:12:30.600]  There's no upsell.
[01:12:30.600 --> 01:12:33.160]  I last time I bought glasses on a glasses store.
[01:12:33.160 --> 01:12:37.160]  It's like you end up spending twice the money from the starting point just to get the coatings
[01:12:37.160 --> 01:12:38.360]  that you want on the glasses.
[01:12:38.360 --> 01:12:45.080]  Uh, they also have a titanium collection that starts at just $145 including lenses with
[01:12:45.080 --> 01:12:49.400]  premium Japanese titanium and French non rocking screws.
[01:12:49.400 --> 01:12:52.680]  They even sweat the detail down to what type of screws they use.
[01:12:52.680 --> 01:12:56.920]  All Warby Parker glasses include the anti reflective and anti glare coatings.
[01:12:56.920 --> 01:12:58.920]  They also include excellent cases.
[01:12:58.920 --> 01:13:00.280]  I really vouch for the case.
[01:13:00.280 --> 01:13:00.760]  It's great.
[01:13:01.640 --> 01:13:04.280]  Cleaning cloth cloth, no extra charge.
[01:13:04.280 --> 01:13:08.280]  So whether your eyesight is pretty good or absolutely abysmal, Warby Parker has you covered.
[01:13:08.280 --> 01:13:12.600]  You can get eyeglasses, reading glasses, sunglasses, whatever kind of glasses you need.
[01:13:12.600 --> 01:13:13.480]  You just go there.
[01:13:13.480 --> 01:13:16.440]  You pick like five of the ones that you that you're interested in out.
[01:13:17.080 --> 01:13:18.520]  Uh, give me your address.
[01:13:18.520 --> 01:13:23.400]  And like in two days there's a box at your door and you try them on at home.
[01:13:23.400 --> 01:13:24.760]  Now they don't have your lenses in yet.
[01:13:24.760 --> 01:13:26.920]  They're just, you know, like dummy lenses.
[01:13:27.720 --> 01:13:28.680]  You have five pairs.
[01:13:28.680 --> 01:13:32.840]  You can try them on, look in the mirror, uh, you know, get the people in your family to
[01:13:32.840 --> 01:13:34.280]  tell you which ones look good.
[01:13:34.280 --> 01:13:37.000]  Uh, pick the one you like, order it.
[01:13:37.560 --> 01:13:41.080]  Uh, they'll get it to you within 10 business days, usually even faster.
[01:13:41.080 --> 01:13:42.440]  And then they have free return label.
[01:13:42.440 --> 01:13:46.520]  You just put the samples back in the box, put the return label on and boom, I'll back
[01:13:46.520 --> 01:13:47.560]  off to Warby Parker.
[01:13:47.560 --> 01:13:53.640]  It goes, so it's easy to buy them easy to shop, no pressure and, uh, couldn't be easier.
[01:13:53.640 --> 01:13:57.640]  So go to warbyparker.com slash the talk show.
[01:13:57.640 --> 01:14:02.360]  I am, I'm reading this, these notes while I'm wearing a pair of Warby Parker eyeglasses.
[01:14:02.360 --> 01:14:04.040]  As, as we speak.
[01:14:05.080 --> 01:14:05.800]  Very good stuff.
[01:14:07.080 --> 01:14:08.840]  Uh, I need glasses, man.
[01:14:08.840 --> 01:14:13.240]  I have glasses, but they look me, they make me look like a serial killer from like the
[01:14:13.240 --> 01:14:13.880]  1980s.
[01:14:13.880 --> 01:14:14.440]  They're horrible.
[01:14:15.000 --> 01:14:16.760]  You've been saying this to me for years though.
[01:14:16.760 --> 01:14:19.640]  We'll be out, but I'm going to do it.
[01:14:19.640 --> 01:14:20.440]  I'm going to do it.
[01:14:20.440 --> 01:14:25.560]  And I, this is, I feel like I'm pimping your ads a little bit too much, but like Warby
[01:14:25.560 --> 01:14:29.320]  Parker is making me be like, Oh yeah, I should just actually go on that website and get
[01:14:29.320 --> 01:14:30.120]  some glasses.
[01:14:30.120 --> 01:14:33.960]  You know, I would say this about the Warby Parker thing about them having to load these
[01:14:33.960 --> 01:14:39.800]  $95 starting point is that you can buy without feeling, you know, you go to like a regular
[01:14:39.800 --> 01:14:41.560]  eyeglass store and they're like five or $600.
[01:14:41.560 --> 01:14:44.760]  You feel like, okay, I'm going to buy a pair of eyeglasses and then these are my glasses
[01:14:44.760 --> 01:14:46.680]  for the next few years with Warby Parker.
[01:14:46.680 --> 01:14:51.640]  It is so much easier to buy like two or three pairs and not feel like you're a profligate
[01:14:52.200 --> 01:14:56.280]  and you can either buy two or three pairs and have them so that they are different and
[01:14:56.280 --> 01:15:01.480]  you can have like, you know, minimal glasses and thick black glasses, whatever, different
[01:15:01.480 --> 01:15:05.720]  looks or just to have them laying around so that if you, you know, if they're more like
[01:15:05.720 --> 01:15:10.200]  reading glasses, you can keep a pair in the office and keep a pair downstairs.
[01:15:10.200 --> 01:15:13.080]  And it's so much better at that price.
[01:15:13.080 --> 01:15:15.960]  But it used to be like when I was growing up, when I first got glasses, it was like,
[01:15:15.960 --> 01:15:17.800]  I got one pair of glasses and that was it.
[01:15:17.800 --> 01:15:18.520]  And don't break.
[01:15:18.520 --> 01:15:19.000]  That was it.
[01:15:19.000 --> 01:15:19.720]  Yeah, me too.
[01:15:20.280 --> 01:15:25.800]  I look like a serial killer and I picked them myself and I thought they were like silver
[01:15:25.800 --> 01:15:30.200]  and they kind of, they were East St. Laurent, but they kind of like lean in a little bit.
[01:15:30.200 --> 01:15:31.480]  Like I look crazy.
[01:15:31.480 --> 01:15:34.600]  I look like I'm going to murder you more than usual.
[01:15:35.480 --> 01:15:37.480]  And I just, I got to let it go.
[01:15:37.480 --> 01:15:42.600]  I had, but yeah, so I bought these one pair of glasses and I can do my job fine.
[01:15:42.600 --> 01:15:46.200]  But I mean, distance is like, I can barely read my TV at this point.
[01:15:47.480 --> 01:15:52.440]  Like I don't, like I guess what shows are on, like I guess what the names of shows or
[01:15:52.440 --> 01:15:59.320]  episodes are based on like what's most likely, which is probably not the way most people
[01:16:00.040 --> 01:16:02.280]  actually read the world.
[01:16:03.240 --> 01:16:06.920]  I'm like, this is probably the most likely.
[01:16:06.920 --> 01:16:09.320]  You should probably get your eyes checked a little bit.
[01:16:10.120 --> 01:16:15.640]  So Tim Cook has been CEO now for five years as of two days ago, he has been the CEO of
[01:16:15.640 --> 01:16:16.520]  Apple for five years.
[01:16:16.520 --> 01:16:20.120]  So there's a couple of people commemorating that with, you know, what's, what are the
[01:16:20.120 --> 01:16:24.520]  five years of Tim Cook like, I think that that was the basis.
[01:16:24.520 --> 01:16:29.000]  There was a really long interview with Tim Cook in the Washington Post that I think the
[01:16:29.000 --> 01:16:30.360]  date was the 13th.
[01:16:30.360 --> 01:16:31.880]  So that was about two weeks ago, actually.
[01:16:32.760 --> 01:16:38.200]  Not quite sure that that was time to be with the five year thing, but might as well be.
[01:16:39.080 --> 01:16:40.600]  I will put a link to that interview.
[01:16:40.600 --> 01:16:41.160]  Yeah, I think so.
[01:16:41.160 --> 01:16:41.960]  I like that interview.
[01:16:41.960 --> 01:16:42.520]  It's really good.
[01:16:43.080 --> 01:16:43.960]  Yeah, it's so long.
[01:16:43.960 --> 01:16:49.480]  And I was actually, I was actually on a brief vacation with my folks at the time.
[01:16:49.480 --> 01:16:53.880]  And so I actually didn't finish reading it until today, actually, which is why I haven't
[01:16:53.880 --> 01:16:55.480]  linked to it on Daring Fireball.
[01:16:55.480 --> 01:16:56.760]  Yeah, you should.
[01:16:57.640 --> 01:16:59.240]  I know, but now I'm two weeks late.
[01:16:59.880 --> 01:17:01.080]  Okay, you're always late.
[01:17:01.080 --> 01:17:02.040]  Yeah, it's typical for me.
[01:17:03.240 --> 01:17:03.880]  It wasn't.
[01:17:03.880 --> 01:17:04.920]  It was very interesting.
[01:17:04.920 --> 01:17:10.360]  And it's a lot of it is stuff that I already knew about Tim Cook, but some of it was insightful.
[01:17:10.360 --> 01:17:15.240]  And they asked one of the questions they asked that I've seen people ask about, but nobody
[01:17:15.240 --> 01:17:24.840]  asked him was whether or not he thinks that growing up gay in a, the US South, in Alabama,
[01:17:24.840 --> 01:17:30.680]  did that make him is that did that fuel his focus on privacy?
[01:17:30.680 --> 01:17:31.080]  Right.
[01:17:31.080 --> 01:17:33.960]  You know, and that he was a great question.
[01:17:33.960 --> 01:17:35.000]  It is a great question.
[01:17:35.000 --> 01:17:36.120]  It was very well worded.
[01:17:36.120 --> 01:17:38.680]  And in short, I don't want to, you know, you should read his article.
[01:17:38.680 --> 01:17:39.560]  I don't want to read the whole thing.
[01:17:39.560 --> 01:17:45.880]  But in short, he says no, that it's two separate things that it that obviously his upbringing
[01:17:46.440 --> 01:17:49.320]  was, you know, everybody's upbringing informs who they are as an adult.
[01:17:49.320 --> 01:17:55.480]  But in this particular case, on the issue of privacy, he believes that it is fundamental
[01:17:55.480 --> 01:18:01.080]  to the United States, and that it's as much a part of, you know, the founding of this
[01:18:01.080 --> 01:18:05.960]  country is the freedom of speech and freedom of religion, that you have a right to privacy,
[01:18:05.960 --> 01:18:09.240]  and that he believes that so strongly that it has, you know, but who knows?
[01:18:09.240 --> 01:18:12.520]  Maybe he's, you know, you know, I don't know.
[01:18:12.520 --> 01:18:13.320]  I don't know.
[01:18:13.320 --> 01:18:15.640]  But I would agree with that 100%.
[01:18:16.120 --> 01:18:16.360]  Yeah.
[01:18:17.080 --> 01:18:21.560]  And just to get a manic hit him that I'm going to do this, but just to get back to the gun
[01:18:21.560 --> 01:18:25.400]  rights thing is like, first, you should be concerned about privacy.
[01:18:27.000 --> 01:18:31.080]  Then you won't need a gun to protect yourself from whatever the hell you think you're going
[01:18:31.080 --> 01:18:32.040]  to protect yourself from.
[01:18:33.080 --> 01:18:37.640]  But yeah, no, I, I totally agree with them.
[01:18:37.640 --> 01:18:39.480]  And for a long time, I did.
[01:18:41.000 --> 01:18:42.440]  I had my own narrative though.
[01:18:42.440 --> 01:18:45.240]  I'm like, well, he's like a gay guy growing up in the south.
[01:18:45.240 --> 01:18:46.440]  That's got to suck.
[01:18:47.160 --> 01:18:49.960]  I've given his age and all that, like, things are different now.
[01:18:51.400 --> 01:18:51.720]  I hope.
[01:18:53.480 --> 01:18:54.760]  Well, they're certainly better.
[01:18:54.760 --> 01:18:56.600]  I think I don't think anybody would deny.
[01:18:56.600 --> 01:19:01.320]  I think that, you know, that no matter how, whether it still is problematic or not, probably
[01:19:01.320 --> 01:19:03.560]  I would guess that be probably really problematic.
[01:19:03.560 --> 01:19:08.200]  And like, hopefully, hopefully the worst that's happening is arguing about who's going to
[01:19:08.200 --> 01:19:09.400]  make your wedding cake.
[01:19:09.400 --> 01:19:09.640]  Right.
[01:19:11.480 --> 01:19:14.280]  When it used to be like, oh, you just may get murdered.
[01:19:14.280 --> 01:19:14.520]  Right.
[01:19:15.800 --> 01:19:22.280]  So hopefully, but, you know, you know, just kind of change, take some kind of time.
[01:19:22.280 --> 01:19:29.160]  So so yeah, that, that would have been what I would have thought, but I like this answer
[01:19:29.160 --> 01:19:30.680]  a lot.
[01:19:30.680 --> 01:19:34.600]  It's just like, no, this is a fundamental, fundamental freedom.
[01:19:35.960 --> 01:19:39.160]  And, you know, it's hard to not get behind that.
[01:19:39.160 --> 01:19:39.660]  Right.
[01:19:40.680 --> 01:19:44.280]  You know, and you have to, he's a very careful speaker.
[01:19:44.280 --> 01:19:46.040]  It's, you know, as he needs to be.
[01:19:46.680 --> 01:19:51.720]  And they even address that, that he was, one of the things he's surprised by is he thought
[01:19:51.720 --> 01:19:56.280]  he would operate a little under the radar because he thought that the attention Steve
[01:19:56.280 --> 01:19:58.520]  Jobs got was because he was Steve Jobs.
[01:19:58.520 --> 01:19:59.480]  I love that quote.
[01:19:59.480 --> 01:20:03.560]  And that it didn't come with the job, but that it was wrong that being the CEO of Apple
[01:20:04.680 --> 01:20:09.080]  brings an intense scrutiny to everything you say and do that, that he didn't quite anticipate
[01:20:09.080 --> 01:20:13.560]  because he really thought it was Steve and not the chair as he calls it.
[01:20:13.560 --> 01:20:13.800]  Yeah.
[01:20:14.520 --> 01:20:15.960]  I think he's partially right.
[01:20:15.960 --> 01:20:19.960]  Like a lot of it was just because Jobs, like if Jobs had quit Apple and went somewhere
[01:20:19.960 --> 01:20:26.680]  else, which I can't even imagine happening, but if he had, people would still be following
[01:20:26.680 --> 01:20:27.240]  Jobs.
[01:20:27.240 --> 01:20:30.200]  Right.
[01:20:30.200 --> 01:20:33.080]  At this point, Apple is huge.
[01:20:33.080 --> 01:20:34.360]  Like, yeah.
[01:20:35.880 --> 01:20:39.320]  Like the hot seat is not just Steve anymore.
[01:20:39.320 --> 01:20:41.800]  It's it, you won.
[01:20:41.800 --> 01:20:42.520]  It worked.
[01:20:42.520 --> 01:20:48.840]  You're now you're, you know, you know, now you're going to have weird pieces written
[01:20:48.840 --> 01:20:54.360]  about you that you don't, like you are unsure of their sourcing or like you say something
[01:20:54.360 --> 01:20:55.720]  and somebody is going to take it the wrong way.
[01:20:55.720 --> 01:20:57.240]  Yeah.
[01:20:57.240 --> 01:21:01.720]  I really don't envy that kind of scrutiny.
[01:21:01.720 --> 01:21:02.600]  It is weird though.
[01:21:02.600 --> 01:21:08.840]  I mean, and you know, I don't do, I don't write like the five year commemorative piece.
[01:21:08.840 --> 01:21:12.760]  You know, I tend not to do those sort of anniversary type things.
[01:21:13.880 --> 01:21:15.640]  But it is still fun to think about.
[01:21:15.640 --> 01:21:19.800]  And it is weird to me to think that he's been CEO for five years now, just as a point of
[01:21:19.800 --> 01:21:25.080]  reference, like the thing that made me go like, Whoa, is I've been writing during fireball
[01:21:25.080 --> 01:21:28.120]  since 2002, actually August, 2002.
[01:21:28.120 --> 01:21:29.880]  So exactly 14 years.
[01:21:31.960 --> 01:21:37.480]  So over a third of the time I've been doing during fireball has been Apple has been under
[01:21:37.480 --> 01:21:38.040]  Tim Cook.
[01:21:38.680 --> 01:21:39.960]  That's kind of crazy to me.
[01:21:39.960 --> 01:21:43.080]  Like in my gut, it doesn't feel that way.
[01:21:43.080 --> 01:21:47.640]  It doesn't feel like it still feels like the Tim Cook era is new and that I've spent most,
[01:21:47.640 --> 01:21:48.440]  you know, and that's true.
[01:21:48.440 --> 01:21:53.400]  I've still spent two thirds of the time, but yeah, give it another five years and it'll
[01:21:53.400 --> 01:21:55.480]  be half the time, half the time I've been doing this.
[01:21:55.480 --> 01:21:56.600]  Tim Cook's been in charge.
[01:21:57.320 --> 01:21:57.880]  Yeah.
[01:21:57.880 --> 01:21:58.280]  Yeah.
[01:21:58.280 --> 01:22:03.160]  I feel the same way about, well, first of all, when Tim Cook was there for five years,
[01:22:03.880 --> 01:22:09.080]  I realized that like, I've known you way too long and I should spend some time finding
[01:22:09.080 --> 01:22:17.880]  better friends because I like we'd been friends for a long time when Tim Cook took over.
[01:22:17.880 --> 01:22:19.880]  It's just, I feel like I'm wasting my life here.
[01:22:19.880 --> 01:22:34.840]  The other thing is his tenure was so questioned at first.
[01:22:34.840 --> 01:22:40.040]  But I mean, if you look at, was it Horace that posted the charts recently?
[01:22:40.040 --> 01:22:42.520]  Like, oh, I'm sure he's posted some charts recently.
[01:22:43.880 --> 01:22:49.320]  Horace has always posted some charts recently.
[01:22:49.320 --> 01:22:57.160]  But no, Tim Cook's been like killing it for the first five years of his tenure as CEO
[01:22:57.800 --> 01:22:58.360]  of Apple.
[01:23:01.160 --> 01:23:07.400]  And I don't think he's doing it in the same way that Ballmer did because Ballmer also
[01:23:07.400 --> 01:23:08.440]  had great results.
[01:23:08.440 --> 01:23:08.680]  Yes.
[01:23:11.000 --> 01:23:17.480]  But it was more like doubling down on what already existed and in a way kind of riding
[01:23:17.480 --> 01:23:26.280]  out the wave of success of Microsoft for a while, who I honestly these days, I just do
[01:23:26.280 --> 01:23:26.840]  better guys.
[01:23:27.960 --> 01:23:28.840]  It might have been.
[01:23:28.840 --> 01:23:31.960]  I'm actually like a Microsoft cheerleader at this point.
[01:23:32.840 --> 01:23:33.800]  I want them to do well.
[01:23:33.800 --> 01:23:34.360]  I really do.
[01:23:35.080 --> 01:23:39.160]  I think that the biggest mistake under Ballmer, I mean, again, we could probably do a whole
[01:23:39.160 --> 01:23:44.200]  show about that, but the biggest mistake was missing out on mobile.
[01:23:44.200 --> 01:23:47.400]  And again, I've said this many times.
[01:23:47.400 --> 01:23:50.760]  And he laughed about it, which I think is unfair, like that thing where he's laughing
[01:23:50.760 --> 01:23:51.720]  off the iPhone.
[01:23:51.720 --> 01:23:52.220]  Right.
[01:23:53.560 --> 01:23:55.400]  That's what he's doing in an interview.
[01:23:55.400 --> 01:23:57.880]  And he's a boisterous, over-the-top kind of guy.
[01:23:57.880 --> 01:24:02.360]  I kind of get the feeling, though, that in that video where he laughs about the iPhone,
[01:24:02.360 --> 01:24:05.160]  that it doesn't have a keyboard and it's $600.
[01:24:05.160 --> 01:24:08.280]  And how are you ever going to do work without a keyboard?
[01:24:08.280 --> 01:24:09.960]  You know, he laughs.
[01:24:09.960 --> 01:24:11.480]  I know it is his personality.
[01:24:11.480 --> 01:24:14.040]  And of course, he's not going to say very good things about it.
[01:24:14.680 --> 01:24:23.880]  But I do feel, though, that the way his attitude in that video, to me, indicates that he didn't,
[01:24:23.880 --> 01:24:25.800]  even privately, didn't get it.
[01:24:25.800 --> 01:24:31.400]  He didn't look at the iPhone and think, oh, fuck, this is amazing.
[01:24:31.400 --> 01:24:33.240]  And we don't have anything.
[01:24:33.240 --> 01:24:33.740]  We are.
[01:24:35.800 --> 01:24:40.840]  And I do believe that the CEO of Microsoft should have been able to look at the iPhone
[01:24:40.840 --> 01:24:45.640]  and say, that first iPhone, and say, oh, we are screwed.
[01:24:45.640 --> 01:24:46.760]  But it's true.
[01:24:46.760 --> 01:24:56.280]  If you read the great book by the guy from the original Macintosh team.
[01:24:56.280 --> 01:24:57.080]  Andy Hertzfeld?
[01:24:57.080 --> 01:24:57.560]  Andy Hertzfeld.
[01:24:57.560 --> 01:24:58.760]  I was going to say Andy Anatko.
[01:24:58.760 --> 01:25:01.400]  I know that that was Andy Hertzfeld's book.
[01:25:01.400 --> 01:25:03.080]  Andy Anatko is a great guy.
[01:25:03.080 --> 01:25:04.520]  Revolution in the Valley.
[01:25:04.520 --> 01:25:09.640]  And then most of those stories are also on his great website, folklore.org.
[01:25:09.640 --> 01:25:11.400]  Yeah, that's a great site.
[01:25:11.400 --> 01:25:12.440]  Oh, my God, it's amazing.
[01:25:12.440 --> 01:25:13.720]  But I like it in the book.
[01:25:13.720 --> 01:25:14.600]  I like the book better.
[01:25:14.600 --> 01:25:16.920]  But if you want to be a cheapskate, you can read it for free.
[01:25:19.880 --> 01:25:21.320]  He tells the story.
[01:25:21.320 --> 01:25:26.600]  He was there in the room when Bill Gates first saw a Macintosh.
[01:25:26.600 --> 01:25:27.880]  I think it was still a prototype.
[01:25:28.520 --> 01:25:35.880]  And what Gates was specifically obsessed about was the way that the mouse pointer moving
[01:25:35.880 --> 01:25:40.120]  on screen was so smooth that the animation was so smooth.
[01:25:40.120 --> 01:25:46.600]  Because all other previous attempts at that, I don't know what the details of how Apple
[01:25:46.600 --> 01:25:47.960]  did that, what the trick was.
[01:25:47.960 --> 01:25:50.520]  But there was some serious trickery going on.
[01:25:51.240 --> 01:25:52.600]  These days it's done in hardware.
[01:25:54.360 --> 01:26:01.320]  Back then, you'd have to redraw the thing underneath your mouse was there.
[01:26:01.320 --> 01:26:08.680]  Then you would move it, and then you'd have to redraw it where it was on those kind of
[01:26:08.680 --> 01:26:09.160]  computers.
[01:26:09.160 --> 01:26:11.160]  At that time, that was hard.
[01:26:11.160 --> 01:26:13.400]  It's a big deal.
[01:26:13.400 --> 01:26:17.400]  If you didn't do something special, the mouse movement on all other systems that are mouse,
[01:26:17.400 --> 01:26:19.240]  the mouse moved very jerkily.
[01:26:19.240 --> 01:26:20.760]  It was just real jerky.
[01:26:20.760 --> 01:26:26.120]  And on the Macintosh, even though the hardware was, by today's standards, almost laughably
[01:26:26.120 --> 01:26:30.680]  minimal, what was it, 128 kilobytes of RAM?
[01:26:30.680 --> 01:26:31.880]  Yeah.
[01:26:31.880 --> 01:26:35.160]  Or was the 128K one the fat one?
[01:26:35.160 --> 01:26:36.600]  I think that might have been the Fat Mac.
[01:26:36.600 --> 01:26:39.320]  That might have been the Fat Mac.
[01:26:39.320 --> 01:26:41.560]  It's just a laughably slow processor.
[01:26:41.560 --> 01:26:43.320]  So the other one would have been like 64K.
[01:26:45.320 --> 01:26:46.280]  We could be wrong on that.
[01:26:46.280 --> 01:26:47.080]  Syracuse.
[01:26:47.080 --> 01:26:49.080]  I think the Fat Mac was 512.
[01:26:49.080 --> 01:26:51.160]  I think the Fat Mac was 512.
[01:26:51.160 --> 01:26:53.000]  And I think the original was 128.
[01:26:53.000 --> 01:26:53.160]  Yeah.
[01:26:53.160 --> 01:26:54.840]  I don't think they ever shipped a 64K Mac.
[01:26:54.840 --> 01:26:56.920]  It was about 128, but it was ridiculous.
[01:26:56.920 --> 01:27:01.960]  But Gates saw the mouse movement and accused them of having dedicated hardware to do it,
[01:27:01.960 --> 01:27:03.640]  because otherwise it would be impossible.
[01:27:03.640 --> 01:27:11.640]  And I think, as the story goes, that Jobs told Andy Hertzfeld to shut up, because Hertzfeld
[01:27:11.640 --> 01:27:14.200]  was going to tell Gates exactly how they did it.
[01:27:14.200 --> 01:27:18.600]  Of course he would, which goes back to the previous point about scientists and dudes
[01:27:18.600 --> 01:27:21.320]  want to just tell everybody all the stuff all the time.
[01:27:21.320 --> 01:27:27.080]  But Gates is the type of guy who could look at the Mac and see something like that and
[01:27:27.080 --> 01:27:29.080]  say, whoa, this is something.
[01:27:29.080 --> 01:27:36.360]  Whereas Balmer, because he's so outside the product development and not really a software
[01:27:36.360 --> 01:27:44.200]  guy, really is just a true businessman CEO, didn't look at the iPhone and see, whoa, this
[01:27:44.200 --> 01:27:46.120]  is not something to laugh at.
[01:27:46.120 --> 01:27:49.720]  There is a way to answer that question where he doesn't look so bad in hindsight.
[01:27:49.720 --> 01:27:54.520]  And the keyboard thing is a fine answer that I know that I've made hay over that over the
[01:27:54.520 --> 01:27:59.480]  years, but at the time, because all people with business phones had BlackBerry style
[01:27:59.480 --> 01:28:04.440]  devices or the Windows mobile device was BlackBerry style where it had these hardware keyboards.
[01:28:04.440 --> 01:28:06.440]  That was a fine part of the answer.
[01:28:07.080 --> 01:28:12.840]  But Joanna Stern, who's been on the show a lot, she should be more often, because she's
[01:28:12.840 --> 01:28:20.280]  hilarious, huge BlackBerry physical keyboard fan, you know, she loves it.
[01:28:20.280 --> 01:28:20.840]  Right.
[01:28:20.840 --> 01:28:22.920]  But, you know, it's kind of sailed at this point.
[01:28:22.920 --> 01:28:23.080]  Right.
[01:28:23.080 --> 01:28:24.040]  But that was a fine answer.
[01:28:24.040 --> 01:28:25.560]  But the laughing at it was inappropriate.
[01:28:25.560 --> 01:28:28.120]  You could just see I could just see that he just didn't have that.
[01:28:28.120 --> 01:28:30.280]  I feel like Tim Cook doesn't have that problem.
[01:28:30.280 --> 01:28:36.440]  He may not be a product guy, but he is absolutely, to my mind, not focused solely on milking
[01:28:36.440 --> 01:28:37.880]  what Apple's got.
[01:28:37.880 --> 01:28:42.840]  Okay, so two things.
[01:28:42.840 --> 01:28:45.320]  Steve Jobs also crapped on products.
[01:28:46.840 --> 01:28:47.640]  Right.
[01:28:47.640 --> 01:28:48.440]  Competing products.
[01:28:48.440 --> 01:28:51.240]  But yeah, competing products like Ballmer did.
[01:28:52.520 --> 01:28:57.560]  So why do you think he managed to pull it off and Ballmer didn't?
[01:28:57.560 --> 01:29:01.080]  I think his Ballmer was so profoundly wrong on that particular issue.
[01:29:01.080 --> 01:29:06.600]  I mean, it's not like Steve Jobs saying like Blu-ray is a bag of hurt, which
[01:29:06.600 --> 01:29:10.360]  it is, and we still don't have Blu-ray on any Mac.
[01:29:10.360 --> 01:29:10.680]  Right.
[01:29:10.680 --> 01:29:14.200]  It literally became I mean, this is no exaggeration, no hyperbole.
[01:29:14.200 --> 01:29:18.520]  The iPhone is the most successful product in the history of consumer electronics.
[01:29:18.520 --> 01:29:23.480]  It's maybe the most successful product period, like more successful than the Model T Ford.
[01:29:24.040 --> 01:29:30.920]  You know, it's unfathomable how much money Apple has made on and makes every day on the
[01:29:30.920 --> 01:29:31.400]  iPhone.
[01:29:31.400 --> 01:29:36.440]  Would I have predicted that when I first saw it, when I was in that audience at Macworld
[01:29:36.440 --> 01:29:41.160]  Expo, when he showed that Steve Jobs took the iPhone out of his pocket?
[01:29:41.160 --> 01:29:44.840]  Would I have predicted that it would be the single most successful product in the world
[01:29:44.840 --> 01:29:46.280]  and would propel Apple to become...
[01:29:47.000 --> 01:29:50.920]  I think Apple's just, if they only sold the iPhone and they had no other business, they
[01:29:50.920 --> 01:29:54.280]  would still be the biggest company in the world by revenue and profit.
[01:29:54.280 --> 01:29:55.880]  Would I have predicted that that would be true?
[01:29:55.880 --> 01:29:56.440]  No.
[01:29:56.440 --> 01:30:01.400]  But if you told me I'm from the future and that is true, I would have believed it.
[01:30:01.400 --> 01:30:05.720]  I would have said, yeah, this is so amazing that I can believe that it's going to be that
[01:30:05.720 --> 01:30:06.280]  big.
[01:30:06.280 --> 01:30:06.760]  Yeah.
[01:30:06.760 --> 01:30:11.320]  I mean, I've told you this story before, and I'm sure I've said it before, but I bought
[01:30:11.320 --> 01:30:12.680]  an iPhone when I couldn't even use it.
[01:30:12.680 --> 01:30:17.560]  All I could do was swipe and call 911.
[01:30:17.560 --> 01:30:21.560]  That's all I could do, and I bought it, and I bought it just because of that.
[01:30:21.560 --> 01:30:22.840]  I'm like, I want this thing.
[01:30:22.840 --> 01:30:24.520]  I think you told this story on the show before.
[01:30:24.520 --> 01:30:26.840]  You told this story on the show before, which is amazing.
[01:30:26.840 --> 01:30:30.680]  And the thing that I forgot, you got halfway through the story last time, and I had totally
[01:30:30.680 --> 01:30:31.400]  forgotten.
[01:30:31.400 --> 01:30:34.920]  I still assume, though, okay, you couldn't make phone calls because you were in Canada,
[01:30:34.920 --> 01:30:38.760]  but you could still use notes and get on Safari and do email.
[01:30:39.960 --> 01:30:43.640]  But you couldn't because those original iPhones had to be activated.
[01:30:43.640 --> 01:30:48.920]  You take it out of the box and you had to activate with AT&T before you could get past
[01:30:48.920 --> 01:30:49.160]  the...
[01:30:49.160 --> 01:30:50.600]  I had the lock screen.
[01:30:50.600 --> 01:30:51.480]  That's what I had.
[01:30:51.480 --> 01:30:55.080]  And swipe was not swipe to unlock.
[01:30:55.080 --> 01:30:57.080]  It was swipe to call 911.
[01:30:57.080 --> 01:30:57.800]  That was it.
[01:30:57.800 --> 01:30:59.480]  That's the only thing I could do.
[01:30:59.480 --> 01:31:03.880]  And I thought about doing it, but I'm a good citizen, so I didn't do it.
[01:31:03.880 --> 01:31:07.400]  But I still bought that phone and loved it.
[01:31:08.600 --> 01:31:10.040]  That was a great phone.
[01:31:10.040 --> 01:31:13.080]  Eventually it got unlocked and things worked out okay.
[01:31:13.080 --> 01:31:13.720]  I've still got it.
[01:31:13.720 --> 01:31:14.680]  It's on my desk here.
[01:31:14.680 --> 01:31:16.120]  I'm not giving that thing up.
[01:31:16.120 --> 01:31:21.880]  But yeah, that first iPhone, a little bit of a...
[01:31:21.880 --> 01:31:23.080]  That's a cultural moment.
[01:31:24.840 --> 01:31:26.120]  I don't know if you read it.
[01:31:26.120 --> 01:31:27.240]  I linked to it the other day.
[01:31:28.920 --> 01:31:30.120]  A guy on Medium.
[01:31:30.680 --> 01:31:32.680]  I've heard him before, but never really noticed.
[01:31:32.680 --> 01:31:36.920]  A guy named Jan Dawson wrote a big, long Medium post.
[01:31:36.920 --> 01:31:41.640]  It was five years of Tim Cook in charts, and he had all sorts of information.
[01:31:41.640 --> 01:31:42.840]  I just pasted it.
[01:31:42.840 --> 01:31:47.960]  It will be in the show notes, I swear, but I thought it was really interesting.
[01:31:47.960 --> 01:31:50.920]  And he makes a very interesting observation.
[01:31:50.920 --> 01:31:55.640]  I'm sure Horace has noticed it, and I probably should have, but Dawson points this out in
[01:31:55.640 --> 01:32:02.360]  a way that makes it very clear is that under the five years of Tim Cook, Apple's profit
[01:32:02.360 --> 01:32:04.520]  margins have gone down slightly.
[01:32:05.720 --> 01:32:10.440]  They're high enough that a 2% drop in profit margins is not that big, but it's kind of
[01:32:10.440 --> 01:32:19.080]  gone from just dropped 2%, but that their spending on R&D has gone up as a percentage
[01:32:19.080 --> 01:32:25.240]  of revenue, has almost doubled, gone from 2% to 4%, and that extra 2% correlates pretty
[01:32:25.240 --> 01:32:31.480]  much exactly with the 2% drop in profit margin that Apple has taken a little bit of a hit
[01:32:31.480 --> 01:32:38.840]  on profit margin to pump into R&D, which again, they can well afford to do because the profit
[01:32:38.840 --> 01:32:44.440]  margins have gone from extremely high to very high, or ever so slightly less extremely high.
[01:32:46.040 --> 01:32:51.720]  And to me, again, the proof will be in the pudding as to what pans out of this increase
[01:32:51.720 --> 01:32:52.760]  in R&D spending.
[01:32:56.040 --> 01:33:02.840]  But to me, it's evidence that he's, as a leader, he's not focused on milking the past
[01:33:02.840 --> 01:33:03.320]  products.
[01:33:03.320 --> 01:33:11.880]  Oh, no, I don't want to just be like an Apple cheerleader, a Tim Cook cheerleader here,
[01:33:11.880 --> 01:33:18.760]  but I think that this is a sign that what Tim Cook is doing is very different than what
[01:33:18.760 --> 01:33:20.360]  Bonner was doing at Microsoft.
[01:33:20.360 --> 01:33:28.520]  Microsoft doubled down on their existing assets, Windows and Office.
[01:33:28.520 --> 01:33:33.400]  I don't think that that was a problem, though.
[01:33:33.400 --> 01:33:37.000]  I feel like, like I said before, I think the only big mistake he made was missing out on
[01:33:37.000 --> 01:33:41.160]  mobile and that the mobile plan they had was a bad idea.
[01:33:41.160 --> 01:33:47.000]  So yeah, I see that as a symptom of doubling down Windows.
[01:33:47.000 --> 01:33:49.640]  But I think Ben Thompson has made this case.
[01:33:49.640 --> 01:33:51.560]  I'm just parroting Ben Thompson, frankly.
[01:33:51.560 --> 01:33:56.440]  But the fact that that Bonner made Windows and Office so much more profitable than they
[01:33:56.440 --> 01:34:01.480]  were when he took over from Gates, it really did help strengthen Microsoft as a company
[01:34:01.480 --> 01:34:02.520]  that they made.
[01:34:02.520 --> 01:34:08.920]  He did such a good job of taking two products that were already incredibly profitable and
[01:34:08.920 --> 01:34:13.560]  incredibly strong in the market and made them even more so.
[01:34:13.560 --> 01:34:19.240]  It really strengthened Microsoft so that the fact that they frankly missed out on mobile.
[01:34:19.960 --> 01:34:24.440]  Well, so when you say frankly missed out, I say at the expense of missing out.
[01:34:24.440 --> 01:34:26.760]  I don't think that they're exclusive, though.
[01:34:26.760 --> 01:34:29.560]  I think they could have done the same thing and had a better strategy.
[01:34:29.560 --> 01:34:30.280]  Oh, they could have.
[01:34:30.280 --> 01:34:38.200]  But I mean, their focus was on deriving revenue from their two key assets.
[01:34:39.480 --> 01:34:42.120]  And so I think they got blindsided, frankly.
[01:34:42.840 --> 01:34:46.360]  And they had Windows CE, and they thought they were good.
[01:34:48.840 --> 01:34:49.640]  It was not good.
[01:34:49.640 --> 01:34:55.400]  It's literally wince, like W-I-N-C-E.
[01:34:55.400 --> 01:34:58.520]  It was the joke since they wanted it.
[01:34:58.520 --> 01:34:59.480]  They shipped it.
[01:35:00.520 --> 01:35:03.400]  And it looked like Windows 95 on a phone.
[01:35:03.400 --> 01:35:04.920]  It even had a start menu.
[01:35:04.920 --> 01:35:06.120]  It had a start menu.
[01:35:06.120 --> 01:35:06.680]  Right.
[01:35:06.680 --> 01:35:07.320]  Come on, guys.
[01:35:09.560 --> 01:35:10.440]  Bad idea.
[01:35:10.440 --> 01:35:15.000]  It would be like if the iPhone had in the top, starting at the top left, Apple.
[01:35:15.960 --> 01:35:16.280]  Right.
[01:35:16.280 --> 01:35:16.760]  Yeah.
[01:35:16.760 --> 01:35:22.920]  Remember those rumors that were like, remember the phone rumors that every time you'd see
[01:35:22.920 --> 01:35:25.880]  like a rendering, you'd be like, that is garbage.
[01:35:25.880 --> 01:35:27.080]  That's not going to happen.
[01:35:27.080 --> 01:35:27.720]  Yeah.
[01:35:27.720 --> 01:35:36.040]  And during the iPhone launch, those rumors were so popular that Steve put up a photo
[01:35:36.600 --> 01:35:43.000]  of an iPod with a rotary dial and some other whatever, like a list of names to make phone
[01:35:43.000 --> 01:35:45.160]  calls, which is hilarious.
[01:35:45.160 --> 01:35:52.680]  But yeah, so I think Microsoft, at the expense of getting into mobile, focused on getting
[01:35:52.680 --> 01:35:55.640]  the most revenue out of their existing assets.
[01:35:57.320 --> 01:36:01.880]  I do think and looking back at Tim Cook's five years and these interviews and the stories
[01:36:01.880 --> 01:36:03.480]  and stuff like that, I feel like part of it.
[01:36:03.480 --> 01:36:06.680]  And he reiterates it over and over in that Washington Post interview that he's focused
[01:36:06.680 --> 01:36:08.360]  on the long term, not the short term.
[01:36:08.360 --> 01:36:11.400]  And he said something about like the question was something to the effect of what do you
[01:36:11.400 --> 01:36:15.880]  say to short term investors who are frustrated because like, for example, if you're in Apple's
[01:36:15.880 --> 01:36:21.000]  on the short term right now, for this calendar year, they're down year over year for the
[01:36:21.000 --> 01:36:21.500]  first time.
[01:36:22.040 --> 01:36:25.480]  And his answer is we welcome investors of all sorts, whether you're in for the short
[01:36:25.480 --> 01:36:26.120]  term or long term.
[01:36:26.120 --> 01:36:31.800]  But we're very clear that our strategic plans are solely and only focused on the long term.
[01:36:32.440 --> 01:36:36.600]  So if you want to ride us for three months and try to make a quick buck, you're welcome
[01:36:36.600 --> 01:36:37.080]  to try.
[01:36:37.080 --> 01:36:38.680]  But we're not playing that game.
[01:36:38.680 --> 01:36:40.760]  Yeah, I love that question.
[01:36:40.760 --> 01:36:42.120]  I love that quote, by the way.
[01:36:42.120 --> 01:36:43.800]  Yeah, everybody's welcome.
[01:36:44.600 --> 01:36:45.880]  We're thinking long term.
[01:36:45.880 --> 01:36:48.600]  So you should know about it right now.
[01:36:48.600 --> 01:36:50.040]  Come in with your eyes open.
[01:36:50.040 --> 01:36:51.160]  Yeah, right.
[01:36:51.160 --> 01:36:54.440]  And that I'm not going to worry about, you know, one 90 day blip.
[01:36:55.240 --> 01:36:55.740]  Right.
[01:36:56.760 --> 01:37:04.520]  So just to be the Dennis Leary to your Jon Stewart, you want to talk about Vesper?
[01:37:04.520 --> 01:37:06.200]  Yeah, let me take a break.
[01:37:06.200 --> 01:37:07.960]  That was the last topic I wanted to talk about.
[01:37:07.960 --> 01:37:08.520]  Oh, you did.
[01:37:08.520 --> 01:37:08.760]  Okay.
[01:37:08.760 --> 01:37:11.160]  I thought I was going to have to, like, twist your arm.
[01:37:11.160 --> 01:37:13.880]  No, but I figured let's, you know, let's not be self indulgent.
[01:37:13.880 --> 01:37:15.080]  Let's talk about the real news first.
[01:37:15.640 --> 01:37:16.520]  Let me take a breakdown.
[01:37:16.520 --> 01:37:18.680]  Thank our third and final sponsor of the show.
[01:37:18.680 --> 01:37:20.280]  Longtime friends of the show.
[01:37:20.280 --> 01:37:21.480]  Great company.
[01:37:21.480 --> 01:37:22.200]  Fracture.
[01:37:22.200 --> 01:37:27.320]  Fracture is a photo decor company that is out to rescue your favorite images from the digital
[01:37:27.320 --> 01:37:28.040]  ether.
[01:37:28.040 --> 01:37:29.960]  You've heard if you listen to the show, you know what they do.
[01:37:29.960 --> 01:37:33.240]  They take your phone, you send them digital photos, they print them directly on glass.
[01:37:33.240 --> 01:37:37.720]  If you haven't, if you're new to the show, if you if you haven't heard the factor thing
[01:37:37.720 --> 01:37:39.240]  before, I mean it.
[01:37:39.240 --> 01:37:40.280]  I don't know how they do it.
[01:37:40.280 --> 01:37:44.280]  I would actually, I almost am tempted to go down there and see the factory and see how
[01:37:44.280 --> 01:37:45.800]  they do it because I don't understand it.
[01:37:45.800 --> 01:37:50.920]  They don't print photo on paper and then like glue it or seal it to glass.
[01:37:50.920 --> 01:37:54.680]  Somehow they actually print directly on glass.
[01:37:54.680 --> 01:37:55.640]  I don't know how they do it.
[01:37:55.640 --> 01:37:57.400]  I've never seen anything else like it.
[01:37:57.400 --> 01:37:59.240]  I never heard of anything else like it.
[01:37:59.240 --> 01:38:01.640]  I think it's like it's some kind of proprietary process.
[01:38:01.640 --> 01:38:02.200]  I don't know.
[01:38:02.200 --> 01:38:03.480]  But it is amazing.
[01:38:03.480 --> 01:38:09.080]  It really does make the color and the contrast of your photos really pop.
[01:38:09.080 --> 01:38:12.760]  It looks better than printed photos in a glass frame.
[01:38:12.760 --> 01:38:14.200]  I don't know why, but it does.
[01:38:15.480 --> 01:38:20.200]  And because it's right there on the glass, you get, you could just use the actual piece
[01:38:20.200 --> 01:38:23.240]  of glass and it comes with everything you need to hang it up on the wall.
[01:38:23.240 --> 01:38:26.360]  It's got like cardboard on the back, but you don't have a frame.
[01:38:26.360 --> 01:38:27.720]  It just goes edge to edge.
[01:38:27.720 --> 01:38:33.480]  So it ends up looking like, uh, like the cell phones from, um, uh, what was that?
[01:38:33.480 --> 01:38:37.320]  Ryan Johnson movie with a looper or where it's just like a piece of glass where it just
[01:38:37.320 --> 01:38:40.840]  goes edge to edge and there is no bezel around it or anything, any kind of frame.
[01:38:40.840 --> 01:38:42.360]  It, it looks futuristic.
[01:38:42.360 --> 01:38:43.160]  It is amazing.
[01:38:43.160 --> 01:38:46.520]  It is a really cool look to not have any border at all.
[01:38:46.520 --> 01:38:50.280]  You, when you get your fracture, you don't have to then put it in a frame or something
[01:38:50.280 --> 01:38:51.080]  to hang it up.
[01:38:51.080 --> 01:38:54.760]  You just open the little cardboard thing that comes with and it's ready to go right up there.
[01:38:54.760 --> 01:38:55.400]  Everything you need.
[01:38:55.400 --> 01:38:56.920]  It's really, really great.
[01:38:56.920 --> 01:38:58.520]  It is just, just fill your house with these things.
[01:38:58.520 --> 01:39:02.680]  Take your pictures of your kids, your family, whoever else you got, your dog, uh, sleeping
[01:39:02.680 --> 01:39:04.520]  on his, uh, on his new mattress.
[01:39:04.520 --> 01:39:08.120]  Take a cool picture of your dog, get a fractured print of it, hang it up on the wall.
[01:39:08.120 --> 01:39:11.880]  They, they do it right in Gainesville, Florida from U S source materials.
[01:39:11.880 --> 01:39:14.280]  Their factory is carbon neutral.
[01:39:14.280 --> 01:39:16.920]  Uh, can't say enough good things about this.
[01:39:16.920 --> 01:39:19.480]  Take some summer vacation photos, get them printed it.
[01:39:19.480 --> 01:39:20.440]  You won't regret it.
[01:39:20.440 --> 01:39:24.760]  So here's where you go for more information and take a look at it.
[01:39:24.760 --> 01:39:26.760]  And 10% off your first order.
[01:39:26.760 --> 01:39:28.200]  You'll save some bucks.
[01:39:28.200 --> 01:39:31.880]  Go to fracture me.com slash podcast.
[01:39:32.840 --> 01:39:34.680]  Uh, they're going to give you a survey.
[01:39:34.680 --> 01:39:36.680]  It is a one question survey.
[01:39:36.680 --> 01:39:38.280]  That is, where did you hear about them?
[01:39:38.280 --> 01:39:41.480]  And then you can, that's where you just say you heard about it on the talk show.
[01:39:41.480 --> 01:39:42.440]  Uh, it couldn't be easier.
[01:39:43.240 --> 01:39:45.880]  Fracture me.com slash podcast.
[01:39:46.680 --> 01:39:47.000]  All right.
[01:39:47.000 --> 01:39:47.480]  Vesper.
[01:39:47.480 --> 01:39:47.960]  We shut down.
[01:39:47.960 --> 01:39:48.280]  What?
[01:39:48.280 --> 01:39:48.520]  Wait.
[01:39:48.520 --> 01:39:51.320]  One just because I did it for the other two.
[01:39:51.320 --> 01:39:53.160]  Uh, I've used fracture.
[01:39:53.160 --> 01:39:54.120]  I like them.
[01:39:54.120 --> 01:39:54.920]  It's good.
[01:39:54.920 --> 01:39:58.360]  Like I, I loved the product.
[01:39:58.360 --> 01:40:04.360]  Uh, I would recommend it and I'm, this is totally unsolicited and kind of just jumping
[01:40:04.360 --> 01:40:07.320]  in the middle of your show to say that anyway.
[01:40:07.960 --> 01:40:10.040]  What, what's up with Vesper, man?
[01:40:10.040 --> 01:40:15.560]  Well, uh, yeah.
[01:40:16.200 --> 01:40:16.520]  Okay.
[01:40:16.520 --> 01:40:19.480]  So Vesper ran for what?
[01:40:19.480 --> 01:40:21.800]  Two, three years, three years.
[01:40:21.800 --> 01:40:24.280]  We shipped in June of 2013.
[01:40:24.280 --> 01:40:25.080]  And okay.
[01:40:25.080 --> 01:40:30.120]  And you've, you've wrapped it up now, like you're, uh, by the end of, uh, I believe this
[01:40:30.120 --> 01:40:34.680]  month, uh, you're shutting off the sync service, right?
[01:40:34.680 --> 01:40:36.360]  At this point, we really only have two things.
[01:40:36.360 --> 01:40:41.720]  We have an iOS app and we have a sync service and we, for various reasons, we need to shut
[01:40:41.720 --> 01:40:42.840]  down the sync service.
[01:40:42.840 --> 01:40:48.440]  Uh, uh, there's some changes coming to Azure mobile services.
[01:40:48.440 --> 01:40:53.800]  We might, it's possible that after these changes that it would, if we had left it running,
[01:40:53.800 --> 01:40:57.240]  would keep running, but there's also possible, we just don't know yet until they make the
[01:40:57.240 --> 01:40:57.480]  change.
[01:40:57.480 --> 01:41:00.680]  It's also possible that it would require engineering to fix.
[01:41:00.680 --> 01:41:05.000]  And the effort that we don't have because Brent is not working on Vesper anymore.
[01:41:05.000 --> 01:41:07.160]  So we don't have the engineering to keep them running.
[01:41:07.160 --> 01:41:10.680]  So since we can't guarantee it and we were thinking that we should shut it down anyway,
[01:41:10.680 --> 01:41:11.960]  now is a good time to do it.
[01:41:11.960 --> 01:41:13.720]  So we're shutting down the sync service.
[01:41:13.720 --> 01:41:19.560]  So what we did is we shipped a new version of Vesper that has, uh, two changes.
[01:41:19.560 --> 01:41:23.960]  One, you can no longer sign up for a sync account because it really doesn't make any
[01:41:23.960 --> 01:41:27.480]  sense to allow people to sign up for a sync account that is only going to last for five
[01:41:27.480 --> 01:41:27.800]  days.
[01:41:29.640 --> 01:41:35.160]  And two, it adds an export feature, which we probably should have had all along, but
[01:41:35.160 --> 01:41:36.920]  didn't for various reasons.
[01:41:36.920 --> 01:41:44.040]  But the way that we're doing, uh, export is really, to me, it's, it's ideal is, and it's,
[01:41:44.040 --> 01:41:46.120]  yeah, if checks it out, you did a good job.
[01:41:46.120 --> 01:41:47.160]  There's confusion.
[01:41:47.160 --> 01:41:51.480]  And I think, I don't think that if you read what we wrote about it at various places,
[01:41:51.480 --> 01:41:56.360]  either in the release notes for this new version of the app or like Brent's blog or my blog,
[01:41:57.240 --> 01:42:02.360]  I don't think that what we wrote is confusing, but I think because of the way so many other
[01:42:02.360 --> 01:42:06.280]  services work, people just come at it with the wrong impression and are confused.
[01:42:06.280 --> 01:42:10.040]  The one source of confusion people have is, Hey, wait, if you're shutting down the sync
[01:42:10.040 --> 01:42:12.760]  service at the end of August, this is like too short of a notice.
[01:42:12.760 --> 01:42:14.040]  How am I going to export my notes?
[01:42:15.000 --> 01:42:17.640]  Because you're setting it down, you know, like what if I'm not, what if somebody is on
[01:42:17.640 --> 01:42:21.800]  vacation for the last week of August and they don't get it and the sync server is already
[01:42:21.800 --> 01:42:26.040]  off and they haven't been able to export their notes and the confusion is that export doesn't
[01:42:26.040 --> 01:42:27.000]  go from the cloud.
[01:42:27.000 --> 01:42:33.000]  It's not, we, in fact, we can't like the way that the sync services is worked is that I
[01:42:33.000 --> 01:42:37.720]  guess we could, but it, the data's on the device, right?
[01:42:37.720 --> 01:42:42.680]  And it's exported through iOS document pickers.
[01:42:42.680 --> 01:42:43.320]  Is that what it's called?
[01:42:43.320 --> 01:42:44.120]  Document pickers.
[01:42:45.560 --> 01:42:50.280]  So the one that's there by default for anybody who has iCloud is you can export to iCloud
[01:42:50.280 --> 01:42:50.780]  drive.
[01:42:51.720 --> 01:42:57.880]  But if you have any other app that has a document picker extension, Dropbox is a obvious one.
[01:42:57.880 --> 01:43:03.560]  Another one that is very cool that I've tried is Transmit from our friends at Panic.
[01:43:03.560 --> 01:43:09.640]  So if you have Transmit on your phone, you can export your Vesper notes from your device
[01:43:09.640 --> 01:43:13.720]  to any web server that you have configured in Transmit.
[01:43:13.720 --> 01:43:16.520]  Yeah, that's really weird that Panic did a great job.
[01:43:16.520 --> 01:43:18.040]  That's shocking.
[01:43:20.200 --> 01:43:24.360]  But anyway, export goes from the device, not from the, not, not from the cloud.
[01:43:24.360 --> 01:43:30.920]  So we can shut down the sync server and anything that notes that you already have on your device,
[01:43:30.920 --> 01:43:33.400]  you can export, including the pictures.
[01:43:34.600 --> 01:43:38.040]  And then what we're going to do is we're probably going to take Vesper out of the app store
[01:43:38.040 --> 01:43:38.540]  soon.
[01:43:40.200 --> 01:43:40.700]  Yeah.
[01:43:41.880 --> 01:43:42.380]  How do you feel?
[01:43:43.560 --> 01:43:44.440]  Well, I wrote about it.
[01:43:44.440 --> 01:43:45.240]  I mean, I'm sad.
[01:43:45.240 --> 01:43:49.800]  I mean, I really love the app and I liked, you know, I liked working with Brent and Dave.
[01:43:49.800 --> 01:43:53.800]  I really did have a lot of fun, but the truth is that once, you know, we just never made
[01:43:53.800 --> 01:43:54.280]  enough money.
[01:43:54.280 --> 01:43:55.000]  I mean, I wrote about it.
[01:43:55.000 --> 01:43:58.280]  We never made enough money, so we couldn't really, we needed to make enough money to
[01:43:58.280 --> 01:43:59.320]  keep Brent full time.
[01:43:59.320 --> 01:43:59.880]  And we didn't.
[01:43:59.880 --> 01:44:01.000]  We never made that much money.
[01:44:02.040 --> 01:44:04.920]  So Brent, when was that?
[01:44:04.920 --> 01:44:05.640]  2014?
[01:44:05.640 --> 01:44:06.520]  At some point in 2014.
[01:44:06.520 --> 01:44:07.960]  He's been in Omni for a while now.
[01:44:07.960 --> 01:44:09.320]  Yeah, so it might be like two years.
[01:44:09.320 --> 01:44:10.600]  18 months, maybe two years.
[01:44:10.600 --> 01:44:11.560]  Yeah, I think it's like two years.
[01:44:11.560 --> 01:44:13.000]  I think two years come September.
[01:44:14.440 --> 01:44:19.320]  Brent went to work at the Omni group, which, you know, again, it's like working for Panic.
[01:44:19.320 --> 01:44:22.360]  It's like, kind of like an all-star team.
[01:44:22.360 --> 01:44:23.960]  Oh, yeah.
[01:44:23.960 --> 01:44:32.840]  You know, it's like Kevin Drant going to the already great Golden State Warriors.
[01:44:32.840 --> 01:44:34.680]  Like, oh, yeah, now they just picked up Brent Simmons.
[01:44:36.200 --> 01:44:37.560]  Yeah, sure, that's great.
[01:44:37.560 --> 01:44:40.040]  Brent has an awesome three-pointer shot, by the way.
[01:44:40.040 --> 01:44:46.200]  But the truth is that once Brent went to work for Omni full time, there was, you know, the
[01:44:46.200 --> 01:44:48.520]  writing was on the wall that there was no way for us to continue.
[01:44:48.520 --> 01:44:52.280]  I mean, in theory, we could have hired somebody else or found somebody else to take over
[01:44:52.280 --> 01:44:54.120]  for Brent, and I'd be blessed.
[01:44:54.120 --> 01:44:56.200]  Man, if only you knew another programmer.
[01:45:01.000 --> 01:45:07.480]  But it's, you know, I guess part of the whole thing wasn't really that we wanted a programmer.
[01:45:07.480 --> 01:45:10.040]  The whole point was that I wanted to work with Brent Simmons.
[01:45:10.040 --> 01:45:13.000]  Yeah, that makes me feel a lot better.
[01:45:13.000 --> 01:45:13.960]  Well, you know what I mean?
[01:45:13.960 --> 01:45:14.520]  I'm joking.
[01:45:14.520 --> 01:45:15.640]  I mean, it's all, whatever.
[01:45:17.640 --> 01:45:19.160]  For the sake of comedy.
[01:45:19.160 --> 01:45:20.360]  I mean, no, it's true.
[01:45:20.360 --> 01:45:21.320]  I mean, well, I'll just say it.
[01:45:21.320 --> 01:45:25.480]  I mean, it's not like I asked you if you wanted to do it, but I said, would you think of,
[01:45:25.480 --> 01:45:26.920]  you know, we did talk about it a while.
[01:45:26.920 --> 01:45:30.840]  Yeah, that's, well, I didn't even want to bring that up, but yeah, it's all a joke.
[01:45:31.640 --> 01:45:32.920]  Just as a maybe, as a what if.
[01:45:32.920 --> 01:45:35.400]  Working with Brent is like a life goal.
[01:45:35.400 --> 01:45:37.160]  That guy is amazing.
[01:45:37.160 --> 01:45:40.840]  I would love to have, like, work conversations with him.
[01:45:42.040 --> 01:45:43.960]  He's, man, he's good.
[01:45:44.520 --> 01:45:45.000]  Really good.
[01:45:48.040 --> 01:45:49.560]  One of the smartest guys I know.
[01:45:49.560 --> 01:45:51.880]  Yeah, he is.
[01:45:51.880 --> 01:45:53.000]  It was great working with him.
[01:45:53.000 --> 01:45:53.880]  I really enjoyed it.
[01:45:53.880 --> 01:46:00.120]  And I personally feel very, I feel responsible for the failure of Vesper as a business because
[01:46:00.120 --> 01:46:02.360]  that was really, that was the part that was, yeah, I do.
[01:46:02.360 --> 01:46:06.040]  I think Brent would disagree and Dave would disagree.
[01:46:06.040 --> 01:46:06.360]  Maybe.
[01:46:06.360 --> 01:46:07.800]  Yeah, I also disagree.
[01:46:08.520 --> 01:46:10.040]  Because I feel like that was my job.
[01:46:10.040 --> 01:46:13.400]  Brent's job was to make the app to do all the, all of the engineering.
[01:46:13.400 --> 01:46:19.480]  And Dave's job was to do the design and make it look great and work great and have a logic
[01:46:19.480 --> 01:46:19.880]  to it.
[01:46:20.440 --> 01:46:26.920]  And I definitely work, certainly worked a lot on the design with Dave, but I feel like
[01:46:26.920 --> 01:46:33.560]  fundamentally my role as the director, as we called it, was to make sure what we're
[01:46:33.560 --> 01:46:38.760]  doing is, if anybody was responsible for coming up with an idea and a business model that
[01:46:38.760 --> 01:46:41.800]  makes enough that we would be a success, that was me.
[01:46:42.680 --> 01:46:46.920]  Well, it's admirable that you think that, but I think you're an idiot.
[01:46:46.920 --> 01:46:51.400]  It's not your fault.
[01:46:51.400 --> 01:46:52.920]  I feel, let me put it this way.
[01:46:52.920 --> 01:46:56.440]  I feel responsible for the failure, but I'm not losing sleep over it.
[01:46:59.640 --> 01:47:00.440]  Does that make sense?
[01:47:00.440 --> 01:47:03.960]  Like, I'm not trying to be a martyr about it.
[01:47:03.960 --> 01:47:07.880]  I'm not trying to say, Oh, you know, poor me, you know, you know, feel bad for me that
[01:47:07.880 --> 01:47:09.320]  I'm, that I'm blaming myself.
[01:47:09.320 --> 01:47:10.680]  But I do think that I should have known it.
[01:47:10.680 --> 01:47:15.400]  I feel like in hindsight, like I wrote about, I really feel like what we wanted to do.
[01:47:15.400 --> 01:47:17.320]  I mean, number one, there's all sorts of things.
[01:47:18.200 --> 01:47:22.680]  Like one thing we agreed from the outset was that we didn't want to raise money.
[01:47:22.680 --> 01:47:27.720]  We did not want to, you know, be funded in any way we wanted to effectively self-fund
[01:47:27.720 --> 01:47:35.080]  with, as they call it, sweat equity, where Brent could afford to spend, you know, the
[01:47:35.080 --> 01:47:40.360]  good part of the first year working on it before we made any money, you know, that he
[01:47:40.360 --> 01:47:45.480]  was coming from, from glassboard and, you know, had the luxury of being able to work
[01:47:45.480 --> 01:47:46.440]  for a while without making money.
[01:47:46.440 --> 01:47:51.720]  And the idea was we would self-fund by doing the iPhone version, selling it, making enough
[01:47:51.720 --> 01:47:56.920]  money from the iPhone version to, you know, sort of bootstrap the company financially
[01:47:56.920 --> 01:48:01.800]  while we worked on the next stuff, which was to do a sync service or figure out a way to,
[01:48:01.800 --> 01:48:05.160]  you know, whether it was building our own, which is what we wound up doing or using iCloud
[01:48:05.160 --> 01:48:10.440]  or Dropbox or something, and then doing a Mac version and selling that and then going
[01:48:10.440 --> 01:48:15.960]  forward from there with effectively a system where you could be at your Mac or you could
[01:48:15.960 --> 01:48:21.080]  be on your phone and maybe, depending on how we did the sync service, you could be just
[01:48:21.080 --> 01:48:22.840]  on the web and you could do it from anywhere.
[01:48:24.440 --> 01:48:27.960]  And I really do feel like, in hindsight, I should have known better and we should have
[01:48:27.960 --> 01:48:29.080]  done the Mac version first.
[01:48:29.080 --> 01:48:38.120]  That's an interesting choice. And it's atypical is the word I'll use. Most people don't
[01:48:38.120 --> 01:48:44.520]  even think of doing the Mac app. I tend to agree with you, but I'm kind of a Mac advocate.
[01:48:44.520 --> 01:48:45.960]  I really love the Mac.
[01:48:45.960 --> 01:48:49.320]  Right. And you're, you know, at Aged and Distilled, you're a product.
[01:48:49.320 --> 01:48:51.400]  We have a Mac app. Yeah, we did it.
[01:48:51.400 --> 01:49:01.720]  Right, Napkin. And for the same reason that you and Chris, you know, did Napkin as a Mac
[01:49:01.720 --> 01:49:06.360]  app first and so far only, you know, I think we should have done the same thing with Vesper.
[01:49:06.360 --> 01:49:10.200]  And I wrote about this. I mean, I'm just repeating it. You can go read the article on
[01:49:10.200 --> 01:49:14.200]  Daring Fireball. But I do think that Dave and I did the right thing, where the schedule
[01:49:14.200 --> 01:49:19.160]  that we had was that Dave and I, you know where we agreed to create the company? It
[01:49:19.160 --> 01:49:19.880]  was at Singleton.
[01:49:19.880 --> 01:49:23.640]  I had heard that actually at the bar.
[01:49:23.640 --> 01:49:32.440]  Yeah. So at Singleton 2012, Brent said he wanted to talk to me and Dave. And I even
[01:49:32.440 --> 01:49:35.880]  remember who was speaking at the time. It was a friend of the show, Glenn Fleishman.
[01:49:39.880 --> 01:49:47.720]  You snuck out on Glenn. Singleton was a conference I used to run for the audience. But yeah,
[01:49:47.720 --> 01:49:50.520]  you totally ducked out on Glenn.
[01:49:50.520 --> 01:49:55.400]  So during Glenn Fleishman's talk, Brent and Dave and I went to the bar, which was right
[01:49:55.400 --> 01:50:01.160]  next door. So I mean, we could vaguely hear Glenn's talk, but it was held in a nice hotel
[01:50:01.160 --> 01:50:06.520]  and there was a bar right next door. And we had a couple of beers. And Brent said, here's
[01:50:06.520 --> 01:50:10.920]  what I'm thinking. I'm, you know, I'm leaving Glassboard soon. I want to make, you know,
[01:50:10.920 --> 01:50:14.520]  I want to go back to doing indie apps. What I would like to do is make an app with you
[01:50:14.520 --> 01:50:18.600]  two guys. I think that we would make a good team. I don't even know what the idea is.
[01:50:18.600 --> 01:50:22.600]  What do you guys think? And we went from there. But that's where Dave and I instantly were
[01:50:22.600 --> 01:50:27.800]  like, yeah, I'm in. Let's figure this out. Let's make it happen. But the timeline was
[01:50:27.800 --> 01:50:32.520]  that Brent wasn't, he had months to go at Glassboard yet. He was going to give notice
[01:50:32.520 --> 01:50:37.240]  and wind down, you know, very gracefully, you know, so we lead time.
[01:50:37.240 --> 01:50:38.440]  That guy's a professional.
[01:50:38.440 --> 01:50:43.960]  Yeah. And he left on, you know, perfectly amicable terms. But he had, there were going
[01:50:43.960 --> 01:50:50.040]  to be months in advance where Brent wasn't spending any time on Vesper, which was fine.
[01:50:50.040 --> 01:50:53.560]  And in fact, we thought this works out great, because once we decided on the idea of this
[01:50:53.560 --> 01:51:02.760]  notes app concept, Dave and I spent months going over the design before Brent wrote anything.
[01:51:02.760 --> 01:51:07.000]  And I think in hindsight, I still think we did the exact right thing by designing the
[01:51:07.000 --> 01:51:11.480]  iPhone app first. But I, but I think that we should have, as soon as we were done designing
[01:51:11.480 --> 01:51:15.800]  the iPhone app should have designed the Mac app and then had Brent build that first. And
[01:51:15.800 --> 01:51:21.160]  the reason I say that is that I really do think that in today's world, if you plan to
[01:51:21.160 --> 01:51:24.920]  have an iPhone app or a mobile app in general, if you want to include Android, you should
[01:51:24.920 --> 01:51:29.080]  design that first, because that's where all the constraints are going to be. That's where
[01:51:29.080 --> 01:51:33.640]  the screen size is most limited. That's where the features are less limited. I mean, we're
[01:51:33.640 --> 01:51:37.000]  all plain text guys. One of the things I love about Vesper is that it's a plain text app,
[01:51:37.000 --> 01:51:41.400]  meaning there's no italics, no bold, you don't get to change the font, you don't get to make
[01:51:41.400 --> 01:51:45.960]  it bigger. Or if you do, it's system wide. So all your notes, if you make it bigger,
[01:51:45.960 --> 01:51:52.520]  all your notes are bigger. And I love plain text. I think plain text has won the war. I think,
[01:51:52.520 --> 01:51:56.680]  you know, I have a rant in me about that. But I think the way that like Facebook and Twitter
[01:51:56.680 --> 01:52:03.400]  don't have fonts, you know, that it's just plain text is, is a better system. I feel like email
[01:52:03.400 --> 01:52:10.600]  got ruined as soon as email changed from being a plain text medium. I agree. But I'm old. So
[01:52:10.600 --> 01:52:14.920]  whatever. But so we were never we were always there was never any question that we're that
[01:52:14.920 --> 01:52:18.840]  Vesper was going to be plain text. But as an example, one of the things that would be easy
[01:52:18.840 --> 01:52:26.600]  to do if you went Mac first, is there's a fantastic, what is it NS text field?
[01:52:26.600 --> 01:52:35.480]  Well, on, okay, on Mac, on iOS, it's on Mac. Yeah, right. You get a full word processor for free.
[01:52:36.680 --> 01:52:42.280]  Yeah, right. You can make like, Hello World app without writing any code. And just, you know,
[01:52:42.280 --> 01:52:48.520]  in in Xcode, you can just use interface builder. And it was a Steve Jobs demo. Yeah, like drag one
[01:52:48.520 --> 01:52:53.720]  of those out. It's one of the things next to the product stuff. But there's an RTF rich text
[01:52:53.720 --> 01:53:00.440]  format, text editor, you know, you can effectively build minutes of what RTF stands for. I mean,
[01:53:00.440 --> 01:53:04.360]  the actual text edit app has a bunch of other features. There's, you know, the autosave and
[01:53:04.360 --> 01:53:08.760]  a whole bunch of nice stuff. But you can effectively build text edit for free and
[01:53:08.760 --> 01:53:13.560]  are a version that's very close to where you get also, they give you the code. Yeah, they give you
[01:53:13.560 --> 01:53:18.280]  the code, like the demo code that you get. But if you may still do at least back in the day.
[01:53:18.280 --> 01:53:25.640]  But if you made a notes app, and there's plenty of them using that field, which would be very
[01:53:25.640 --> 01:53:30.520]  natural to do if you go Mac first, you're up Schitt's Creek trying to make that go to the
[01:53:30.520 --> 01:53:38.600]  iPhone because the iPhone doesn't have a RTF editing field. Right. Yes. I think you can I
[01:53:38.600 --> 01:53:45.800]  don't know. I think you can render it now as of iOS seven. Yeah, it's not quite you don't. Yeah,
[01:53:45.800 --> 01:53:50.680]  I believe there's there's cases that you can't but you know, because he shipped an app with that's
[01:53:50.680 --> 01:53:54.440]  just one. It's just one example, though, of the type of thing where you can do all sorts of more
[01:53:54.440 --> 01:54:00.920]  powerful stuff on the Mac than you can do on the iOS. Yeah, but I think that that serves your point
[01:54:00.920 --> 01:54:07.800]  is like get designed for mobile first. And then maybe like do a Mac app. Yeah, that chargeable
[01:54:07.800 --> 01:54:12.360]  money for right. But the only way you can make a Mac app where you're aware of the constraints of
[01:54:12.360 --> 01:54:18.600]  the iOS version is to design the iOS version first. Yes. I agree. And I really think we could
[01:54:18.600 --> 01:54:23.160]  have done that. I think that we definitely could have sold it for a lot more money because I think
[01:54:23.160 --> 01:54:27.320]  we would have sold it for $20 a copy. And the counter I could be wrong. The counter argument
[01:54:27.320 --> 01:54:32.680]  is obviously that there are way more I iPhone users than Mac users. But I don't think there
[01:54:32.680 --> 01:54:38.280]  are that many more iPhone users who pay for productivity apps like no tabs than there are.
[01:54:38.280 --> 01:54:44.680]  Yeah, this is one of the things it's like, yeah, at one point, there were so many Windows
[01:54:44.680 --> 01:54:54.680]  machines out there that it was like, it was crazy. But nobody was buying software on them.
[01:54:56.600 --> 01:55:01.720]  Yeah, matters a lot. Like that's all you care about is how many people out of this install
[01:55:01.720 --> 01:55:13.560]  bays are actually buying software. And if on iOS, it's really low, it's less of an appealing
[01:55:13.560 --> 01:55:18.200]  target than the Mac, where maybe it's like a little bit higher, right? And people are willing
[01:55:18.200 --> 01:55:23.240]  to pay a little bit more money. So there was a notion in the early years of the App Store that
[01:55:23.240 --> 01:55:27.320]  you know, and certainly a lot of the people in our circle, people we know,
[01:55:27.320 --> 01:55:35.160]  indie Mac developers started making indie iOS apps. And there was a feeling like maybe that
[01:55:35.160 --> 01:55:41.560]  the iOS market would be a lot like the Mac market, which has a long term, you know, for, you know,
[01:55:41.560 --> 01:55:46.440]  back when we used to call it shareware supported independent software where independent developers
[01:55:46.440 --> 01:55:53.400]  could create apps, sell them at a price and a quantity that multiplied by each other would equal
[01:55:53.400 --> 01:55:59.480]  enough money to be to do this full time and call it a job. And that that iOS would work out
[01:55:59.480 --> 01:56:04.360]  similarly. And then it was very clear very quickly that the prices on iOS were going to be a lot
[01:56:04.360 --> 01:56:09.640]  lower. And the thought was, well, maybe the quantity will be so much higher that the multi
[01:56:09.640 --> 01:56:16.120]  multiply the price by the quantity and it'll be equivalent. And it's hasn't worked out that way.
[01:56:16.120 --> 01:56:20.440]  I mean, that's, again, I'm not assigning blame. I'm not saying you know, we could we could maybe
[01:56:20.440 --> 01:56:25.000]  make an argument that Apple had some blame, but I'm just stating the fact that the way it's worked
[01:56:25.000 --> 01:56:31.080]  out is that with rare exceptions, and there are exceptions, but it is a lot less of a feasible
[01:56:31.080 --> 01:56:37.640]  platform for that idea, the idea of you'll make an app, sell it for x dollars to y people, and then
[01:56:37.640 --> 01:56:45.560]  you'll have x times y revenue minus, minus 30%. And it just didn't work out that way. Whereas
[01:56:45.560 --> 01:56:51.320]  the Mac is still thriving for stuff like that. And I think ultimately, it's better to look at iOS as
[01:56:51.320 --> 01:56:57.320]  something more akin to the web where you can't make daring fireball.net. And then when you load
[01:56:57.320 --> 01:57:01.720]  it, you say you have to pay $5 before you can read it like the web just doesn't work that way.
[01:57:01.720 --> 01:57:05.880]  I mean, the closest the web comes to that is paywalls. And everybody knows paywalls suck.
[01:57:07.960 --> 01:57:12.280]  So I think for application software, I think in general, and again, there are exceptions and
[01:57:12.280 --> 01:57:20.520]  fantastic. Cal Cal is a great example. Tweetbot is a great example. Where they are iOS apps that
[01:57:20.520 --> 01:57:25.560]  sell for a couple of bucks and sell in sufficient quantities that the developers can afford to do
[01:57:25.560 --> 01:57:29.640]  work on them full time. But for the most part, I was doesn't work that way. And I think most
[01:57:29.640 --> 01:57:35.080]  people should approach it as being more akin to the web where the app is free. And maybe there's
[01:57:35.080 --> 01:57:41.080]  an in app purchase to unlock better features or themes or something like that. But that
[01:57:41.080 --> 01:57:46.520]  fundamentally, it has to be a free download or else you just get lost. Yeah, I largely agree
[01:57:46.520 --> 01:57:50.840]  with that. You know, and the demo thing is the one area where you can complain that Apple doesn't
[01:57:50.840 --> 01:57:57.000]  allow you to have iOS app demos. And the Mac you can I mean, even there are even apps like I just
[01:57:57.000 --> 01:58:03.800]  tried it because the guys at Ulysses Ulysses is a text editor, great text editor, or project based
[01:58:03.800 --> 01:58:10.440]  writing editor, sort of like an Xcode for writing type thing. They released a very nifty tool
[01:58:10.440 --> 01:58:14.920]  specific for the Vesper export format where you can just drag the folder onto this tool that they
[01:58:14.920 --> 01:58:23.240]  just released yesterday and it will translate your Vesper export into a format that is exactly
[01:58:23.800 --> 01:58:29.560]  imported into Ulysses. So Ulysses on the Mac, I thought this is really interesting. The only way
[01:58:29.560 --> 01:58:33.560]  to buy it is to get it through the App Store. It's one and only way but they still have a demo
[01:58:33.560 --> 01:58:38.760]  version on their website that you can download so that you can try it before you buy it. But the
[01:58:38.760 --> 01:58:44.280]  demo, unlike a lot of other developers, the demo, there's no way to do it in app and circumvent it.
[01:58:44.280 --> 01:58:49.480]  They are, you know, apparently so happy with the App Store in terms of using it for all the
[01:58:49.480 --> 01:58:54.120]  processing and everything. There's a bunch of technical issues for that. Right. There are and
[01:58:54.120 --> 01:58:58.120]  that they can do iCloud, you know, and they can count on iCloud. Yeah, like, because you can't
[01:58:58.120 --> 01:59:05.640]  change your entitlements. That's entitlements means it's technical term. But there's, yeah,
[01:59:05.640 --> 01:59:09.640]  but long story short, there still is a demo version that you can try. And that really,
[01:59:09.640 --> 01:59:15.480]  to me, is fundamental to getting people to part with $20, $30, $40 for an app. Yeah,
[01:59:16.520 --> 01:59:22.440]  I agree. As a guy that sells a $40 app. Right. I think it's a great idea. Yeah.
[01:59:23.880 --> 01:59:28.360]  How many people do you think for napkin? How many people do you think try the demo before they buy?
[01:59:28.360 --> 01:59:32.200]  I have no demo. Oh, you guys don't have a demo? Are you guys App Store only?
[01:59:32.200 --> 01:59:39.640]  Yeah. Wow. Yeah. You guys should have a demo. Yeah, we're, we want to. I didn't know that.
[01:59:40.200 --> 01:59:46.840]  Well, I know a guy. I know a guy and he hooked me up with a free copy of napkin. So I'm not familiar
[01:59:46.840 --> 01:59:52.680]  with that purchase. That's good. Did we give you a free one? I don't know. Maybe I bought it.
[01:59:53.640 --> 02:00:01.320]  I don't remember. Maybe I owe you for the bucks. I don't know. But yeah, no, we don't have a demo.
[02:00:01.320 --> 02:00:09.640]  And the original reason was that like one of the key features we had was sharing the graphic that
[02:00:09.640 --> 02:00:17.080]  you create on iCloud. And we couldn't do that without selling through the App Store.
[02:00:18.360 --> 02:00:21.720]  And it wasn't worth having two versions that were different, you know?
[02:00:21.720 --> 02:00:25.880]  Yeah, that's, that's changed. And, you know, like given our,
[02:00:25.880 --> 02:00:30.840]  now that we know the audience a little bit, that's not necessarily the primary use case.
[02:00:30.840 --> 02:00:36.200]  It's sort of the opposite of what Rich Siegel did with BB Edit, where Rich had BB Edit on both,
[02:00:36.200 --> 02:00:41.160]  you know, as an independent download and in the Mac App Store, and in fact, gave a terrific
[02:00:41.160 --> 02:00:47.160]  talk at Singleton. Yeah, it was really one of my favorite Singleton talks ever was about why
[02:00:47.160 --> 02:00:52.840]  he was leaving the Mac App Store and just go and I think to make a very, it was a 40 minute talk,
[02:00:52.840 --> 02:00:57.880]  and it was great to boil it down to a nut. It was, you know, just a lot less stress to have
[02:00:57.880 --> 02:01:05.720]  one version that wasn't in the Mac App Store. Yeah, because of BB Edit and barebone software,
[02:01:07.240 --> 02:01:11.480]  not a dummy. They've been in business for like a long time.
[02:01:11.480 --> 02:01:15.960]  I, you know, it'll be a surprise when it happens. But I was just talking with Rich. I'm gonna have,
[02:01:15.960 --> 02:01:20.600]  he's gonna be a guest on the show very soon. Oh, cool. Oh, man. That's awesome. He's great.
[02:01:20.600 --> 02:01:29.320]  He's pretty good. Anyway, Vesper. So anyway, we didn't make enough money. We went iPhone first.
[02:01:29.320 --> 02:01:34.360]  I think it was foolish to go iPhone first and expect to make money from selling a paid app
[02:01:34.360 --> 02:01:39.480]  to justify the company. Whereas I think if we've gone Mac first, it would have been,
[02:01:39.480 --> 02:01:44.120]  we would have made at least as much money and I think we would have made more. And therefore,
[02:01:44.120 --> 02:01:48.600]  Brent could have worked on it full time more and we would have gotten off the ground.
[02:01:48.600 --> 02:01:55.800]  Would you do another app? Oh, absolutely. If the situation were right. I mean,
[02:01:55.800 --> 02:01:59.080]  it's not like I'm going to do an app period, but if the right, you know.
[02:01:59.960 --> 02:02:04.280]  Yeah, given the circumstance. Yeah. It would depend on who it was. If I wanted, you know,
[02:02:04.280 --> 02:02:08.120]  if I like them, I wanted to work with them and whether the idea appealed to me. I mean,
[02:02:08.120 --> 02:02:13.240]  Vesper was a perfect storm for me because I really have always wanted to work with Brent.
[02:02:13.240 --> 02:02:20.840]  Dave and I really did have a fantastic, uh, uh, design process. We really did. I mean,
[02:02:21.400 --> 02:02:28.280]  and we, we disagreed in the best possible way. And yeah, that's, yeah. Sometimes he would change
[02:02:28.280 --> 02:02:33.320]  my mind and sometimes I would change his mind, but we both would listen to each other and we
[02:02:33.320 --> 02:02:38.680]  would be able to sort of say, I kind of feel like it should be this instead of that. But if I said,
[02:02:38.680 --> 02:02:44.280]  or he or I said, I feel incredible, I'm convinced that I'm right. And even if you, you know, and,
[02:02:44.280 --> 02:02:48.040]  and we would pull that card, we would listen to each other. Like, even if I disagreed,
[02:02:48.040 --> 02:02:51.400]  thought it should be this. And he said that, but he said, I'm convinced it should be that.
[02:02:52.040 --> 02:02:57.480]  Then I would say, okay, because I'm not convinced the best. It was a great working relationship you
[02:02:57.480 --> 02:03:02.840]  can have. And I love the app. I really, I still love it. So yeah, me too. It was, it was good
[02:03:02.840 --> 02:03:10.840]  work. It was a perfect storm. It was worth putting a lot of time into, but I don't know what else to
[02:03:10.840 --> 02:03:19.960]  say about it. Yeah. Remember when we want to do a fart app? This is way back in the first year.
[02:03:19.960 --> 02:03:26.920]  We could talk about it 2007. Yeah. No, 2009. Right. Or 2008. 2008. I guess. Yeah. Yeah.
[02:03:28.600 --> 02:03:32.600]  The idea was just cracking a joke. We don't need to actually share this story. All right. Maybe
[02:03:32.600 --> 02:03:38.280]  not. Cause I still think it's a good enough idea. Yeah. I want to keep that, but I think I still
[02:03:38.280 --> 02:03:49.320]  have the domain name. I love the idea of you renewing that all the time. It's pathological.
[02:03:49.320 --> 02:03:54.280]  It's probably going to bankrupt me eventually, but eventually bankrupt me or is the, my, my,
[02:03:54.280 --> 02:04:00.360]  the, the annual, let me know, maybe I'll, you know, I'll toss some money away. The annual bill
[02:04:00.360 --> 02:04:07.320]  for unused domain names. Oh, the, uh, yeah. Well, I'm not paying for all the other ones
[02:04:07.960 --> 02:04:15.560]  I have. You know what? I have so many dumb domain names. I think I have common fireball.net
[02:04:17.240 --> 02:04:23.160]  Almond fireball. Something like that. Just to be a Dick. And I can't even remember what the joke
[02:04:23.160 --> 02:04:26.280]  was. It's probably had something to do with that common Markdown or something. Right?
[02:04:26.280 --> 02:04:35.880]  Yes. Yes. Right. Yes. It was like, I think of a joke where I'm going to be a Dick to you.
[02:04:35.880 --> 02:04:39.560]  And then I just, I don't, it's like, oh, that's work and I don't care.
[02:04:42.760 --> 02:04:45.400]  Uh, anything else, anything else you wanted to ask me about Vesper?
[02:04:45.960 --> 02:04:53.080]  Um, I mean, I think we covered it all. I mean, yeah, you covered a lot. Uh,
[02:04:53.080 --> 02:04:58.760]  people, I will say this, let me just say this. I will say that we have received an awful lot of
[02:04:58.760 --> 02:05:03.720]  both on Twitter and by email, an awful lot of very, very, very, very nice things that people
[02:05:03.720 --> 02:05:07.560]  said after we said this about Vesper. And I want to thank everybody who took the time to write.
[02:05:08.680 --> 02:05:14.040]  I do appreciate that. Do you have a question? That was going to be my question is, do you
[02:05:14.040 --> 02:05:20.920]  feel a responsibility to your users? Uh, I do. You've kind of covered a bit with the sync issue.
[02:05:20.920 --> 02:05:28.600]  Right. But, um, I do, but on the other hand, even at its most expensive, it was 10 bucks. And I,
[02:05:28.600 --> 02:05:33.160]  you know, I feel like an app will keep working, you know, if you've bought it and, and you know,
[02:05:33.160 --> 02:05:38.120]  you have it on your phone, it should keep working for a long time. I mean, it definitely still works
[02:05:38.120 --> 02:05:43.160]  on iOS 10 or at least on the betas. There's nothing in iOS 10 that breaks it eventually
[02:05:43.160 --> 02:05:49.880]  something in iOS, I guess we'll break it, but it might be many years. So yeah, we, I mean,
[02:05:49.880 --> 02:05:55.640]  we talked about that privately, but I think you're good for at least two more releases. So
[02:05:55.640 --> 02:05:59.880]  that's at least two years, you know? Cause you're, I mean, you don't do anything crazy.
[02:05:59.880 --> 02:06:07.720]  Right. And it would be something like, uh, like when apps went from 32 bit to 64 bit and
[02:06:07.720 --> 02:06:13.800]  now six 32 bit apps launch and you get like a warning, um, for various reasons. We don't have
[02:06:13.800 --> 02:06:18.840]  to say why, but, uh, I think it's presaging the fact that eventually maybe next year,
[02:06:18.840 --> 02:06:23.400]  32 bit apps are just not going to launch on iOS anymore. I think that's eventually going to happen.
[02:06:24.040 --> 02:06:28.120]  Some change like that will eventually happen and Vesper will break, but it might be many,
[02:06:28.120 --> 02:06:31.880]  many years away. Cause I don't think there's any kind of change that big coming soon.
[02:06:33.320 --> 02:06:38.600]  Yeah. Who knows? But yeah, it doesn't seem like it, but yeah. Yeah. I think you'll be fine for
[02:06:38.600 --> 02:06:43.800]  years. Yeah. And there could be, can you take an app off the store and still have people
[02:06:43.800 --> 02:06:49.960]  upgrade to it? I don't know. I actually don't know. Like, so that it's there so that if you already,
[02:06:50.600 --> 02:06:54.600]  I think you've got like an old one and you want to upgrade to the one with export,
[02:06:54.600 --> 02:06:59.880]  right? You can get it despite the fact that it's not actually available for purchase. Well,
[02:06:59.880 --> 02:07:06.920]  yeah. Free download on the store. Yeah. The current plan is to take it off the store. I think we can
[02:07:06.920 --> 02:07:10.440]  do it in a way where if you want to restore, you'll still be able to download. It'll be there,
[02:07:10.440 --> 02:07:15.400]  but it will be hidden from new users. But since we've made it free, I don't know. Maybe I don't,
[02:07:15.400 --> 02:07:19.000]  I'm not quite sure. Maybe we could reconsider that. Maybe who cares? Just keep it. Yeah.
[02:07:19.000 --> 02:07:23.240]  And you got a bunch of new downloads, more downloads since we made it free,
[02:07:23.240 --> 02:07:26.200]  more downloads than we had in the entire three year history of it being,
[02:07:27.400 --> 02:07:32.520]  which I'm not surprised about. And again, I'm not complaining. I understand how this works, but
[02:07:32.520 --> 02:07:38.120]  there were times where we were selling it for as low as like $2. Yeah. You guys messed with the
[02:07:38.120 --> 02:07:43.640]  price a bit. Yeah. Right. Cause it was 10 originally? No, $4.99 I think originally.
[02:07:43.640 --> 02:07:48.680]  And that was when it was most, like it was far more successful in the first year. I mean,
[02:07:48.680 --> 02:07:52.760]  it corresponds to when it was most actively developed. The first year it was most successful
[02:07:52.760 --> 02:07:57.720]  was mostly for most of that time $4.99. I think we were in like a Christmas promotion where we
[02:07:57.720 --> 02:08:05.080]  lowered the price. And then once we realized we were running out of steam financially,
[02:08:05.080 --> 02:08:09.000]  we'd, you know, well, we have nothing to lose. Let's see what happens if we make it cheaper.
[02:08:09.000 --> 02:08:12.840]  Let's see what happens if we make it more expensive. And yeah, neither really made any
[02:08:12.840 --> 02:08:35.640]  difference. Well, that's what you get for making a shitty app, man. Thanks guy.
