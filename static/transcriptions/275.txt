[00:00.000 --> 00:04.040]  Oh man, Glenn Fleishman you're back on the show. We have so much to talk about
[00:05.240 --> 00:07.360]  We'll never get to all of it, but we can try
[00:10.160 --> 00:14.340]  It's a good problem to have thanks for having me back. Oh what week
[00:15.920 --> 00:21.800]  Why do you want to start with I say we start let's start with jeopardy so number one I knew this
[00:21.800 --> 00:30.460]  I don't know that we've ever really spoken about it at length, and if we have I've forgotten about it, but you were on jeopardy
[00:30.460 --> 00:32.460]  When when were you on?
[00:32.680 --> 00:35.400]  2000 I taped in August 2012 my episodes went up
[00:36.040 --> 00:42.080]  October 2012 and I won I won two episodes by the skin of my teeth is how I describe it
[00:42.080 --> 00:46.800]  I still had my now. I'm too old. It's a young man's game young person's game
[00:47.680 --> 00:50.600]  But I won two episodes and over $30,000
[00:50.600 --> 00:54.000]  Which is kind of neat because my whole life people had said you should go in jeopardy
[00:54.000 --> 00:57.020]  You seem to remember a lot of trivia and things that aren't important
[00:57.720 --> 00:59.120]  Yes, I do
[00:59.120 --> 01:05.640]  And it's well you got it both. It's at least two skills. It's more. You know. It's like an it
[01:05.640 --> 01:08.240]  It's like any kind of athletic competition. It's multi
[01:09.040 --> 01:13.120]  Variate you need you obviously need to know the trivia, but you've also got to be fast
[01:13.120 --> 01:15.840]  I don't I don't have the eye
[01:15.840 --> 01:21.040]  There's no way even if I got like an exception and and got to buzz in ten seconds late
[01:21.640 --> 01:26.400]  I I wouldn't get shut out on jeopardy. I would I would get a couple in
[01:27.120 --> 01:29.920]  But I'm too slow, and I've always been too slow my mind
[01:30.760 --> 01:37.040]  It's you saw that thing there's an article a few months ago about how they've finally done the metabolic testing on grandmaster chess players
[01:37.240 --> 01:41.020]  Mm-hmm. Yes folks. They burn like thousands of calories today
[01:41.020 --> 01:46.640]  Yeah, we said it people in the chess world said you know this may seem not that demanding, but in fact
[01:46.640 --> 01:50.640]  We are we you know we can lose 15 pounds over a term and everyone's like yeah
[01:50.640 --> 01:52.640]  Yeah, you little nerds or whatever
[01:52.780 --> 01:59.040]  They finally started doing some of the real lab testing and these guys are burning like they're like they're doing the Tour de France
[01:59.200 --> 02:04.520]  Practically and so they now the best chess grandmasters now have nutritionists
[02:04.520 --> 02:09.960]  They have a plan for like you know carbo loading or protein loading they work out like athletes
[02:09.960 --> 02:15.920]  Between all the chess practice they do with their coaches and themselves and it makes a huge
[02:15.920 --> 02:19.360]  I mean, it's like you need the physical edge to play that game
[02:19.360 --> 02:24.920]  And I think that's like wonderful hilarious that it took this long for anyone to actually believe them
[02:24.920 --> 02:30.560]  I totally saw that and and the basic explanation. I did see that story. I'll put it in the show notes
[02:30.560 --> 02:36.820]  I swear to God. I just wrote it down, but it's it the basic idea. Is that the human brain is
[02:36.820 --> 02:40.900]  Comparisons between the human brain and
[02:41.660 --> 02:48.060]  Our computers today and the idea of you know how do we get AI to work like a human brain blah blah blah blah blah?
[02:48.060 --> 02:51.660]  It's you know. It's a decades old thing and part of science fiction
[02:52.100 --> 03:00.780]  But at some fundamental level the brain is like a computer and the harder it works the more energy it consumes it totally consumes
[03:00.780 --> 03:07.380]  calories to do to intensely concentrate on something such as for example
[03:08.580 --> 03:10.420]  Grandmaster level chess
[03:10.420 --> 03:13.020]  Which it you know I think everybody
[03:13.020 --> 03:18.380]  I don't see how anybody could dispute that that a game like chess or go or something like that
[03:18.700 --> 03:21.860]  It takes intense competition intense concentration
[03:22.700 --> 03:27.900]  and it consumes large amounts of way more serious amounts of
[03:27.900 --> 03:31.100]  of calories like you said like over the course of like a
[03:32.020 --> 03:35.660]  Week long or a 10-day match it they could lose 15 pounds
[03:36.100 --> 03:39.940]  Yeah, they need they need guys with panniers coming up and like handing them energy bars
[03:39.940 --> 03:43.380]  Yeah, and can't I mean, but it is really I think it was like five
[03:43.380 --> 03:47.860]  I want to say was five or six thousand calories a day. You know a normal human
[03:48.380 --> 03:53.600]  Adult person is somewhere in the two to three thousand calories what you consume with you know normal activity
[03:53.600 --> 03:55.600]  so it is getting into this like
[03:55.740 --> 03:56.820]  high
[03:56.820 --> 04:01.180]  athletic thing so I think about that with Jeopardy like Jeopardy is a very funny game right because
[04:01.860 --> 04:04.100]  At its face value when you play it at home
[04:04.260 --> 04:09.180]  It looks like a trivia game with some timing and then when you play it in reality
[04:09.380 --> 04:13.840]  And I kind of prepped for it when I went in I'd read a bunch of books by people
[04:13.840 --> 04:16.560]  I always cite Bob Harris is the prisoner of
[04:17.300 --> 04:23.120]  Trebekistan is a wonderful book because it's half memoir and Bob is a very interesting and lovely fellow
[04:23.120 --> 04:25.120]  And he's done a lot of interesting things in his life
[04:25.120 --> 04:29.240]  Including you know writing for TV and being involved in microloans or whatever
[04:29.240 --> 04:31.280]  But this book is like it looks like it's a story about
[04:31.880 --> 04:37.040]  Winning on Jeopardy and a strategy guide and then it becomes sort of memoir and so anyway from that book
[04:37.040 --> 04:43.720]  I only I say a big chunk of why I won two games as strategies that he described in the book that I wouldn't have
[04:43.720 --> 04:45.560]  known otherwise and it's um
[04:45.560 --> 04:49.080]  He understood how to bet and that was I remember Arthur Chu who had a good run
[04:49.080 --> 04:51.520]  I think 15-day run a few years ago
[04:51.520 --> 04:57.900]  Arthur Chu drove people nuts because he jumped all over the board which you know has now become more of a standard playing style
[04:58.080 --> 05:05.420]  It had been a style occasionally before him, but he really understood how to bet and James Holzhauer was a demon
[05:06.080 --> 05:11.960]  Embedding and I had no idea so I went in there from that book having us so you need to know how to wager
[05:12.160 --> 05:17.200]  You'd have fast reflexes to buzz in on time. You need to be able to have that fast memory recall
[05:17.200 --> 05:21.680]  So you see it, you know, you know it you buzz it in and you can produce the sounds from your mouth
[05:22.240 --> 05:27.120]  and do it in this incredibly, you know in front of an audience, an audience is a live studio audience and
[05:29.000 --> 05:31.760]  And it's like anyway, here's the funny thing
[05:31.760 --> 05:38.060]  I described the experience as being like the you know, in the Willy Wonka movie the original one with Mike TV
[05:39.360 --> 05:45.120]  And he gets onto the TV set and he like stands in the TV and he's beamed into the TV and he's tiny
[05:45.120 --> 05:50.400]  when you walk out of the Jeopardy set it is exactly I mean not like I thought there was CG or something but
[05:50.720 --> 05:55.840]  It is exactly like you see so it is weirdly like walking into a TV set
[05:55.840 --> 06:02.120]  Well, here's the funny part last year Paris Lemon the guy you played Mike TV in the movie was on Jeopardy
[06:02.800 --> 06:07.820]  Really? I didn't know that. Yeah, he didn't win. Alex did not ask him about the movie
[06:08.280 --> 06:13.660]  But everyone's like wait a minute. That's Mike TV up there and his wife had actually played
[06:13.660 --> 06:16.140]  Previously on Jeopardy and I believe won a little bit
[06:16.780 --> 06:18.780]  Huh?
[06:18.900 --> 06:25.700]  One of the things that I've always enjoyed and these two shows have been on man as almost as long as I can remember
[06:27.100 --> 06:33.420]  Jeopardy and Wheel of Fortune and they're paired. I think they're paired in syndication markets
[06:33.420 --> 06:36.820]  Yeah, I don't know if there's any I've never been aware of a market where they're not
[06:36.820 --> 06:44.620]  Where I live here in the Philadelphia market, they've always been on Jeopardy at Seven Wheel of Fortune 730
[06:45.260 --> 06:50.020]  Oh, we're backwards. Oh, are you really? Yeah, we get wheel first and jeopardy. Isn't that weird? Oh
[06:50.740 --> 06:57.020]  Well, I've always thought that that order made sense because Jeff you watch Jeopardy first and then you feel dumb
[06:57.020 --> 07:01.180]  And then you watch Wheel of Fortune and you feel really smart. You're like
[07:01.180 --> 07:05.460]  Because you can shout all that, you know you it's easy to shout out the answer
[07:05.460 --> 07:11.700]  You know before the contestants can because they they you know, they don't have to buzz in there's no reflexes
[07:11.700 --> 07:17.460]  They can they just say I would like to solve the puzzle right and then they give the guests so it you know
[07:17.460 --> 07:21.300]  As soon as it's pretty obvious and you can you know, you're good at that sort of
[07:22.900 --> 07:27.420]  Puzzle solving, you know, it's a lot easier to feel smart watching Wheel of Fortune
[07:27.420 --> 07:31.940]  Then watching Jeopardy, so I always felt I always felt that the Jeopardy then Wheel of Fortune order
[07:32.940 --> 07:37.660]  Is the right order? Yeah, and you got to kind of calm down as opposed to key yourself up
[07:38.220 --> 07:43.220]  So the other thing so some of the things I've read about and I've watched for years never was tempted to go on
[07:43.220 --> 07:46.460]  Like I said, I know I don't you know, like I was on the quiz bowl team or whatever
[07:46.460 --> 07:49.700]  They called it in high school and did okay at that level
[07:49.700 --> 07:53.540]  But you know Jeopardy is obviously, you know, it's like saying you played high school basketball
[07:53.540 --> 07:58.060]  Versus, you know, you played in the pros or played even even in college, you know
[08:00.020 --> 08:06.580]  You know, there's a definite difference between being a recreational high school quiz bowl player and and you know
[08:06.580 --> 08:13.420]  the a-league but the one thing I didn't know and to and I still I'm not clear about it is when you're allowed to buzz in oh
[08:14.420 --> 08:17.660]  Yeah, yeah. Yeah. Yeah, so it's uh, and this is the funny thing
[08:17.660 --> 08:23.020]  So I read this story a couple of years ago and it's a little bit different than the one that I've read
[08:23.020 --> 08:26.980]  This story recently. I think it was while the this greatest of all time tournament was going on
[08:27.460 --> 08:28.780]  Someone wrote a clever story
[08:28.780 --> 08:32.260]  I think it was a might have been a Jeopardy for a contestant that
[08:32.620 --> 08:37.620]  Jeopardy is the quietest show of any game show you can think of I never thought of it
[08:37.620 --> 08:38.700]  I've watched the show my whole life
[08:38.700 --> 08:43.420]  I was on the show and I never thought of it and they said really the the buzzing device
[08:43.420 --> 08:48.660]  It's that we caught you know, Jeopardy calls it a signaling device. It doesn't buzz. There's no sound when you click in
[08:48.660 --> 08:54.820]  There's a little plate sound if your time runs out for a question, right and the Daily Double thing does that?
[08:55.380 --> 09:00.560]  You know kind of like special TV thing, but otherwise, it's really a pretty in the in the Jeopardy music
[09:00.560 --> 09:05.920]  I was like, wow, that's wild. So so you don't have a lot of there. There's very little oral cues or timing
[09:06.020 --> 09:11.960]  So when you're standing at behind the podium, you're looking at the game board and when they show the game board at home
[09:11.980 --> 09:16.440]  they frame it so you can't see that on the left and right are a set of lights and
[09:16.440 --> 09:18.000]  And
[09:18.000 --> 09:20.000]  Alex reads the clue and
[09:20.960 --> 09:23.760]  The moment he stops he reaches the end of the clue
[09:23.760 --> 09:29.560]  There's one of the producers of the show is sitting at the stage watching and listening to him and hits an unlock button
[09:30.120 --> 09:35.800]  When that producer hits the unlock button and it is the same person typically over a season
[09:35.800 --> 09:40.900]  I think I made me one person for many years now the lights on both sides of the board go out
[09:41.240 --> 09:44.580]  So that you know, you can or they light up in that funny. I think they go
[09:44.580 --> 09:47.160]  I can't remember they light up. I think they light up. Sorry
[09:47.160 --> 09:52.040]  They light up to indicate that you can ring in and at that point you can buzz in if you buzz in before
[09:52.600 --> 09:58.980]  The but the signals are unlocked then you are locked out for something like I think it's a half a second
[09:58.980 --> 10:02.900]  But you know, it's substantial in that world. So some jeopardy players
[10:03.480 --> 10:05.480]  listen to Alex's cadence and
[10:06.000 --> 10:13.280]  Time themselves to figure out when he's done and the producer is gonna click the button and they time it to that other people watch
[10:13.280 --> 10:15.600]  for the lights so like
[10:16.800 --> 10:19.900]  Ken Jennings is a Alex's cadence person
[10:20.720 --> 10:24.240]  James Holzhauer said he follows the looking at the lights thing
[10:24.240 --> 10:27.200]  So you can't say like one of the other gives you the championship skills
[10:27.660 --> 10:34.060]  Clearly because the two best players in Jeopardy's history basically or two of the very best players have different strategies
[10:34.060 --> 10:37.400]  But it's that's the thing is because you get locked out now
[10:38.400 --> 10:40.840]  Apparently I think in the very early Jeopardy games maybe
[10:40.840 --> 10:44.260]  In the first season because it started in the 60s
[10:44.600 --> 10:48.960]  You could ring in at any time and apparently was very frustrating like the host didn't like it
[10:49.320 --> 10:52.980]  it was art Fleming in those days and I think it did not test that well because
[10:53.320 --> 10:56.680]  People wanted to hear the whole question because it's meant for home viewers, right?
[10:56.680 --> 10:58.280]  And if you don't hear the whole question
[10:58.280 --> 11:02.280]  Then you don't have time to think of an answer if someone's it's like what is that?
[11:02.280 --> 11:09.520]  Well, you know, you know, that's it. Then the show is too fast and weird. Yeah, I always assumed because it doesn't make a
[11:09.520 --> 11:13.840]  a buzz or a bleep or anything when somebody buzzes in and it
[11:14.280 --> 11:19.420]  It's interesting because most game shows throughout history with some kind of buzzer clicker thing
[11:19.420 --> 11:22.560]  did it, you know make some kind of noise I think of the
[11:23.380 --> 11:27.760]  The Family Feud, you know has the the big red thing that you slap your hand on
[11:28.840 --> 11:30.520]  but it but
[11:30.520 --> 11:37.400]  The gist of those games make sense that there's a sound effect or as Jeopardy
[11:37.400 --> 11:38.880]  I
[11:38.880 --> 11:40.680]  would guess
[11:40.680 --> 11:42.440]  easily
[11:42.440 --> 11:45.400]  95% of questions get at least one
[11:46.280 --> 11:49.840]  Guess. Oh, yeah. There's another sound effect. There's a sound effect when nobody
[11:50.960 --> 11:53.820]  When nobody takes a guess at a question. Oh, yeah
[11:56.760 --> 11:58.760]  Yeah, yeah, it's but
[11:59.740 --> 12:02.680]  Because every question does get at least one answer
[12:02.680 --> 12:07.240]  It doesn't even make it makes sense that there's no buzz because it would be a non-stop string of buzzes
[12:07.240 --> 12:11.600]  You know the buzz isn't helpful if it's every single thing, you know, it's almost like
[12:13.880 --> 12:21.000]  The way that in movies when people are typing on computers every time they click the mouse or type a key it beeps
[12:21.480 --> 12:24.460]  Right like people. I'm hacking your computer
[12:26.240 --> 12:30.440]  It doesn't make any sense it would drive you crazy if your computer beat every time you typed a key
[12:30.560 --> 12:36.720]  Yeah, I think it would be very distracting if every time you you buzzed in on Jeopardy it made a noise or something
[12:36.720 --> 12:40.520]  But I as a viewer it on TV. I have assumed for decades
[12:41.280 --> 12:43.280]  that you were allowed to
[12:43.920 --> 12:46.560]  buzz in whenever you wanted to but
[12:47.640 --> 12:53.640]  Alex Trebek would continue reading the question regardless and then when he's done reading they cut to
[12:54.160 --> 12:56.880]  The podium and whoever buzzed in first
[12:57.440 --> 13:03.720]  At whatever point theirs is the podium that's lit up and they get to answer. I did not realize that you can't
[13:03.720 --> 13:08.720]  You can't click in you can't buzz in whatever you want to I guess buzz is the wrong word
[13:08.720 --> 13:13.000]  You can't click in until Trebek is done reading. I really didn't realize that
[13:13.720 --> 13:17.840]  But that's interesting because it it gives you more time
[13:17.840 --> 13:21.660]  I always thought that there must be a tremendous advantage to
[13:22.160 --> 13:29.120]  people who could read fast because they could buzz in but there's not you you you have at least as long as it takes Trebek to
[13:29.120 --> 13:34.120]  to read the question had no idea and I kind of feel like I
[13:34.720 --> 13:38.040]  Kind of feel like they there should be some indication of that on the show
[13:38.040 --> 13:40.500]  I mean, it's you know, too late now, I guess to change it but
[13:41.600 --> 13:46.740]  Yeah, I don't think I understood. I think you yeah, cuz they never discuss it on the show
[13:47.000 --> 13:49.480]  right, you have to you only know it if you read about it and
[13:50.280 --> 13:52.640]  But you you can tell yeah
[13:52.640 --> 13:57.760]  I guess I never I think they never decided because they could have said at the beginning of every episode Alex could have said
[13:57.760 --> 14:02.960]  Contestants you can't ring in until the question is finished reading and it's possible. I don't remember it's possible
[14:02.960 --> 14:07.880]  They said that in decades past and then they stopped because everyone knew but and you know new reviewers
[14:07.880 --> 14:12.620]  but I don't remember ever hearing that and it but it becomes this wild thing because
[14:13.640 --> 14:17.280]  When Ken Jennings went on his his winning streak in 2004
[14:18.040 --> 14:23.800]  After I forget how long he had been playing how many games he'd won and the producers are like this is a tower
[14:23.800 --> 14:25.720]  I mean, this is great, but it's also terrible
[14:25.720 --> 14:29.760]  No one is ever gonna beat a guy because he has now played more games of jeopardy than anyone like yeah
[14:29.760 --> 14:35.960]  Like remember that until it was just before the season he was on you could only win five games in a row
[14:35.960 --> 14:38.000]  Then you got a car or two cars
[14:38.000 --> 14:41.560]  So it was the end of the season and they didn't have a choice that you give you two cars
[14:41.820 --> 14:44.600]  So Bob Harris got two cars Brad better got two cars
[14:44.960 --> 14:48.900]  You know, and then you could sell him you paid the tax on him and some people sold him
[14:48.900 --> 14:54.380]  But so Ken had you know on game six or seven if you exclude the tournament play
[14:54.380 --> 15:00.500]  He had played the most regular games of jeopardy of anyone ever. So after 20 games he has
[15:01.260 --> 15:07.540]  Massive amounts of experience that nobody else playing him can so the producers started to do more training
[15:07.540 --> 15:12.580]  So and this is well in advance when I got there in 2012 when you get there in the morning
[15:12.580 --> 15:15.820]  There's a bunch. There's like a couple hours of orientation Oh John
[15:15.820 --> 15:20.940]  Can I tell you the funniest thing is, you know, those incredibly awkward stories the little Alex chitchat. Yeah. Yeah
[15:20.940 --> 15:25.740]  Yeah, okay. So this is the most important part of this before before double jeopardy before
[15:26.740 --> 15:27.940]  You spend so long
[15:27.940 --> 15:33.340]  so when you apply to the show you take a test online test anyone could take it everyone should sign up for this if you
[15:33.340 --> 15:39.340]  Have any trivia interest because it's it's totally painless online and they test like a hundred thousand people with each test
[15:39.580 --> 15:44.380]  Then they select a few thousand to do in-person interviews and about 400 people a year
[15:44.380 --> 15:46.860]  I think go on the show if I do the math, right and so
[15:46.860 --> 15:53.700]  Once you get to the audition stage before you even go in in person to audition in your city or wherever they're like
[15:54.060 --> 15:58.220]  Write up three stories of the kind you would hear in jeopardy like an anecdote about your life. Something is interesting
[15:58.220 --> 16:01.820]  Then you do the audition then they make you tell those stories and they ask you for more stories
[16:01.860 --> 16:08.360]  Then when you get to Culver City, California to the Sony Pictures studios you spend so much time
[16:08.360 --> 16:13.860]  It is like the most time you spend at the show is crafting your terrible little anecdote for chitchat
[16:13.860 --> 16:18.080]  Because it's the hardest thing to get people to have a little story
[16:18.080 --> 16:23.900]  So they work on that part and it's distracting too, which is good. But then the other thing is you play several games
[16:23.900 --> 16:27.300]  So they do I think we spent you know an hour or two in orientation
[16:27.580 --> 16:32.420]  Making sure everyone understands all the all the law involved because a lot of games show law since the quiz show scandal
[16:32.700 --> 16:39.220]  And and how you can hit if you feel like something unfair. There's a representative there. You can talk to directly to complain
[16:39.540 --> 16:42.020]  and and that sometimes results in changes and
[16:42.020 --> 16:44.680]  Oh, it's very rare, but it does anyway
[16:44.680 --> 16:51.220]  So then you go on stage and one of the contestant coordinators plays Alex and you run through with the podiums
[16:51.220 --> 16:56.820]  They sweep people through they run through categories and the producer who unlocks the signaling system is
[16:57.300 --> 17:01.120]  Actually there and before Ken Jennings that person wasn't just anyone was there
[17:01.500 --> 17:04.740]  Managing it and they decided it was such an advantage that Ken had learned
[17:05.020 --> 17:11.980]  The timing between question and the producers so well that they had to have that person there or it was not a you know
[17:11.980 --> 17:14.500]  It was a too unfair for other people playing
[17:15.900 --> 17:18.580]  Interesting, but in the end Ken Jennings won on a final jeopardy
[17:18.580 --> 17:22.980]  So I didn't win on he didn't lose on get regular gameplay. Hmm trying to think was oh
[17:22.980 --> 17:26.760]  I have to ask is this sort of thing I care about like is the
[17:27.780 --> 17:33.580]  As they call it the signal indicator. Does it have a good feel in your hand? Is it is it a good feeling device?
[17:33.580 --> 17:35.580]  Does it have a good click to it?
[17:36.180 --> 17:38.180]  Yeah, it's um, it's
[17:38.740 --> 17:40.740]  Trying to think what it feels
[17:40.740 --> 17:46.820]  Like because usually you don't it doesn't click you depress it and you can and some people have the style that you press it a
[17:46.820 --> 17:50.780]  Lot in a row so that if you get in too early you can still
[17:51.780 --> 17:56.300]  Get in past the next person who hasn't signaled if that makes sense, right get in it
[17:56.300 --> 18:00.420]  So quickest possible time after that. Yeah, I'm trying to remember that's so funny when you say that
[18:00.420 --> 18:04.740]  I don't think they tell you to practice with a pen and I did that and actually at the audition
[18:04.740 --> 18:10.380]  They give you a cheapo jeopardy branded pen and I took that home and I sat there and practice with that as the clicker
[18:10.380 --> 18:14.900]  And that's a traditional thing a serious, you know, like super high-level players who go back to tournaments
[18:15.460 --> 18:20.600]  Some of them have actually built training systems. They've had built for them by people often who work in the
[18:21.300 --> 18:24.780]  Building the game show, you know device building industry
[18:24.820 --> 18:29.580]  They will buy a clicking system or a buzzer system to to test or so
[18:29.580 --> 18:32.140]  They're they're you know able to work on their skills
[18:32.220 --> 18:38.580]  But it is athletic in that sense is you know, if you can shave half a millisecond off your timing
[18:38.580 --> 18:42.740]  Then you could come in first. So I mean this is the other thing even when you're not playing at
[18:43.140 --> 18:46.140]  tournament level like the like the goat tournament you have
[18:46.940 --> 18:50.660]  Everybody on stage has been auditioned so that most of the time
[18:51.220 --> 18:56.820]  say two or three people will know the answer to any given question and some of them are a little harder and only one person or
[18:57.060 --> 19:01.740]  Nobody knows or the person knows they don't ring in they're not secure enough, but a lot of the time it's two
[19:02.420 --> 19:06.380]  And and often all three and you're just working on timing to get in there
[19:06.380 --> 19:08.580]  So if your timing is a little bit worse
[19:08.580 --> 19:15.340]  You could know the answer to nearly every question and still easily lose the game. Yeah, I totally understand that that's
[19:16.460 --> 19:17.940]  fascinating
[19:17.940 --> 19:19.940]  also, what about the
[19:20.060 --> 19:25.980]  The touchscreen where you I guess you use it twice first you write your name
[19:25.980 --> 19:30.780]  And so your name is written there on the you know in white white pixels on a blue background
[19:30.780 --> 19:36.820]  And then for Final Jeopardy you use it to to write your answer is is it?
[19:37.620 --> 19:44.300]  What is the user interface for that? Oh, it's it's terrible. It's really low resolution. It's really hard to do it
[19:44.300 --> 19:49.980]  So when you see people with these really horribly written things in Final Jeopardy, they're barely legible
[19:50.220 --> 19:52.820]  they should really I mean, I think the the
[19:53.700 --> 19:59.880]  Technology has come a long way. I mean 2012. Maybe it was still, you know acceptable but in 2020
[19:59.880 --> 20:01.580]  I think they should have
[20:01.580 --> 20:04.980]  Upgraded those to slightly higher resolution and quality perhaps. I
[20:06.020 --> 20:08.940]  Was actually really impressed James Holzhauer would draw a different design
[20:08.940 --> 20:11.780]  I think almost every night after he started winning then I was like man
[20:11.780 --> 20:16.060]  he really he must have worked with some system that used a stylus and
[20:16.540 --> 20:23.460]  You know crummy old input thing because he he really actually got some good legible designs on his name
[20:24.180 --> 20:26.660]  before Final Jeopardy, do you
[20:26.660 --> 20:31.540]  Now for those of you, I mean, I'm assuming there's a big assumption here that people know what Jeopardy is
[20:31.540 --> 20:36.900]  And I guess if you're listening from a outside the u.s. Maybe you don't sorry, but it's a really fun game
[20:38.100 --> 20:44.260]  But there's two rounds where you answer trivia questions and there's three contestants who buzz in and but then in the final round
[20:44.660 --> 20:51.940]  It's just one question. All they tell you in advance is the category which often is some kind of pun and doesn't give you
[20:51.940 --> 20:57.940]  Sometimes you have a good guess what it's going to be about sometimes not and then what you each contestant secretly
[20:58.340 --> 21:01.140]  Wagers some amount of the money they've already won
[21:01.780 --> 21:06.500]  All or nothing on whether they get get the answer correct and they do it in written form
[21:06.500 --> 21:11.700]  Of course because you know and then they reveal them one at a time because otherwise, you know, how else would you do it?
[21:12.420 --> 21:16.740]  Do they give you like pen and paper so you can like work out the math because there's a lot, you know
[21:16.740 --> 21:18.900]  There's a lot of strategy involved
[21:18.900 --> 21:25.860]  Like if you're in first place you want to basically want to bet enough so that if you're right
[21:26.740 --> 21:30.340]  You'll win no matter what the second place contestant bet
[21:30.340 --> 21:36.980]  So if the second place contestant bets every dollar they have you want to make sure that if you're right you still come out ahead
[21:37.380 --> 21:41.140]  But you probably don't want to bet everything because then if everybody's wrong
[21:41.540 --> 21:45.940]  You want to still have the most amount of money because that's that's ultimately all that matters
[21:45.940 --> 21:50.740]  Do they give you a pen and paper to work that out? Yeah, see john. I can tell that you gamble because oh, yeah
[21:52.020 --> 21:57.540]  You you get it you totally get it that is that is the crux of it and i've seen people lose games
[21:57.940 --> 22:04.260]  Because they didn't do all the math and yeah, they do they literally give you a pencil and paper and the thing they don't show you
[22:04.260 --> 22:08.340]  This is the only thing you know, they say jeopardy is not edited for answers
[22:08.340 --> 22:11.860]  They sometimes edit it for or outcomes they edit it for timing
[22:11.860 --> 22:17.060]  So sometimes if it seems like people are playing boom boom boom, it's because the episode went a little long
[22:17.060 --> 22:19.700]  I mean they have a you know time for each round
[22:20.340 --> 22:26.660]  And they'll actually pull out people's like pauses between answering or between buzzing and answer whatever
[22:26.660 --> 22:30.660]  So sometimes you're like god people are playing super fast. It's like no. No, that's that's the edit
[22:30.660 --> 22:35.700]  But here's the thing they don't show you is alex exposes the uh final jeopardy category
[22:36.100 --> 22:41.300]  And we were watching during the the greatest of all time tournament and we're hoping that we're going to get a little bit better
[22:41.300 --> 22:46.900]  We're whole family was watching and the category was something like presidents and bibles and we're like, oh what the
[22:47.780 --> 22:49.060]  How do you what?
[22:49.060 --> 22:51.540]  All right. Okay. Sure something like that. Anyway, so
[22:52.340 --> 22:55.140]  After they said they go to commercial break. So on set
[22:55.860 --> 22:57.860]  Since they're obviously it's not a live show
[22:57.940 --> 23:02.120]  They give you literally as much as time as you need they put in um partitions
[23:02.580 --> 23:08.020]  Between contestants before you start and then they give you as much time as you need to make the wager
[23:08.020 --> 23:12.020]  So sometimes I think it might have been five plus minutes
[23:12.420 --> 23:15.060]  And they kind of push you along if it's taking a bit because the audience is there
[23:15.060 --> 23:16.660]  Yeah, it's restless and they won't give you forever
[23:16.660 --> 23:20.100]  but it's not like you have 10 seconds or 30 seconds to make the wager so on my
[23:20.900 --> 23:22.900]  Uh, was it my second game?
[23:23.140 --> 23:25.140]  I well in other words, basically
[23:26.020 --> 23:29.700]  The basic thing you're trying to say is you have more than the commercial break, which is probably
[23:30.660 --> 23:34.660]  Probably like 90 seconds or two minutes. Yeah, so we could have you could have five minutes
[23:34.660 --> 23:38.500]  Well, they bring out they're so nice the contestant coordinators. They bring out water to you
[23:38.820 --> 23:42.260]  They check on how you're doing the whole show. I don't think i've said this so far
[23:42.660 --> 23:48.980]  The whole show is the most humane experience. They do such good hiring everybody there is such a lovely person
[23:49.060 --> 23:53.140]  I remember having great time with the sound guy with the makeup people
[23:53.620 --> 23:57.060]  Um, you know just I went back to see to a taping a few months later
[23:57.300 --> 24:03.300]  One of the contestant coordinators saw me in the audience. They got me tickets. They give me a vi like friend of jeopardy sticker
[24:03.300 --> 24:08.660]  One of the contestant coordinators sees me comes up gives me a big hug and i'm like, oh, it's such a lovely show
[24:09.220 --> 24:14.420]  And I don't know how much that comes through but they really do everything they can to make the contestants feel good
[24:14.420 --> 24:18.100]  So anyway, so the final jeopardy thing I on my second game
[24:18.660 --> 24:24.020]  I was very unsure about the category and in the end I got the wrong answer. I was not the number one
[24:24.740 --> 24:26.740]  I don't think I had the most cash
[24:26.740 --> 24:30.900]  So I had a bet so that the I would be left with enough money if I was wrong
[24:30.900 --> 24:36.900]  And the person who had the most cash was wrong and the person who had the third most cash
[24:37.460 --> 24:44.500]  Was right and that is what happened the number one and number two person this other woman and myself were both wrong
[24:44.740 --> 24:50.260]  The third person bet everything and was right and I beat him and he was so peeved
[24:50.420 --> 24:55.460]  He kind of kept looking at the screen because he's like he didn't really I mean so I didn't bet the maximum which is what?
[24:55.460 --> 24:58.420]  You'd expect because I only had a bet enough to beat
[24:58.420 --> 25:02.980]  I knew I couldn't beat the number one person if she bet everything. So anyway, or she bet the maximum
[25:02.980 --> 25:08.260]  She needed to beat my maximum. So I bet strategically and that is the only reason I won that game, right?
[25:08.260 --> 25:12.260]  There's a strategy there where you're thinking what's it's not so much. How can I
[25:12.900 --> 25:18.660]  Get the highest dollar amount. It's what is the what can I do here that gives me the most likely?
[25:19.540 --> 25:26.020]  Chance of winning and in some cases if you're behind your most likely chance of winning is what if the
[25:26.020 --> 25:30.580]  Chance of winning is what if the what if the people ahead of me get get it wrong?
[25:31.860 --> 25:36.260]  Yeah, and what if we all get ours or something? Yeah, and james holzheimer's 34th game when he lost
[25:36.820 --> 25:40.020]  People went nuts because he bet at a level
[25:40.580 --> 25:44.020]  Where he's there like he's throwing the game. Why do you throw the game? They get tired of playing?
[25:44.020 --> 25:50.100]  It's like no he bet because he had a bet on the assumption that the woman who ultimately beat him that uh,
[25:50.740 --> 25:53.620]  He needed to have enough money left to beat the number three player
[25:53.620 --> 25:56.740]  Who in the event actual event I think was wrong
[25:57.220 --> 26:00.900]  But if he had the right answer the number two player would have had like 22 000
[26:01.300 --> 26:03.240]  And james needed to wind up with 22,001
[26:03.860 --> 26:05.860]  So he had to be that
[26:06.020 --> 26:12.020]  Conservatively to beat her if she was wrong the number one player anyway, but people went crazy. They were like, oh my god
[26:12.020 --> 26:17.460]  Why did he throw the game like no, no, no, let's do the math here are the but there's like eight possible outcomes
[26:17.540 --> 26:21.220]  And he bet correctly for every outcome in which he could win. Yeah
[26:21.220 --> 26:28.660]  Yeah, and uh, so anyway the greatest of all, I think I think that that wraps up, uh, your first-hand experience on it
[26:28.660 --> 26:32.260]  Oh, yeah, sorry, uh, and that leads us to this greatest of all time
[26:32.900 --> 26:36.360]  Tournament, which is fascinating. So the three contestants
[26:37.540 --> 26:39.060]  um
[26:39.060 --> 26:43.380]  Were I had this on a screenshot somewhere it was ken jennings
[26:44.340 --> 26:45.460]  who
[26:45.460 --> 26:48.100]  won 74 times times in a row
[26:49.220 --> 26:50.900]  um
[26:50.900 --> 26:55.220]  What's the guy's name from philly james, uh, brad rudder brad rudder?
[26:55.780 --> 27:02.580]  Yeah, uh, he's not as well known right not as well known because he originally played back in the
[27:03.140 --> 27:06.100]  five-time champion and you're out but then
[27:06.820 --> 27:10.980]  wound up making his claim to greatest of all time by
[27:11.780 --> 27:15.220]  Coming on their tournaments of champions where they would bring back
[27:15.780 --> 27:18.900]  five-time champions and play in like a tournament and he
[27:18.900 --> 27:24.980]  Uh, according to the jeopardy bio up until now had never lost to a human being before I guess he lost to the ibm
[27:25.140 --> 27:29.380]  Watson one time in another one of these uh, gimmicky special events
[27:30.020 --> 27:30.980]  Yeah, he he won
[27:30.980 --> 27:38.020]  I think it was because there's a tournament champions and jeopardy in the early 2000s was still popular enough that they did some prime
[27:38.020 --> 27:41.060]  Time specials and this one is the first one they've done in many years
[27:41.380 --> 27:46.660]  And so they do like the ultimate tournament the tournament would and then they did some terminal decades the blah blah blah
[27:46.660 --> 27:52.660]  So he won I think either he won four and was on the winning team for the fifth
[27:52.980 --> 27:57.220]  So he won like a million dollars two million dollars a million dollars, you know
[27:57.700 --> 28:04.260]  300 that whatever it was and even got I think it was 200 grand from the ibm watson thing. So he racked up
[28:04.580 --> 28:06.580]  I think it was four point
[28:06.580 --> 28:08.580]  four million dollars in jeopardy
[28:09.300 --> 28:10.260]  play
[28:10.260 --> 28:12.260]  post his appearances
[28:12.260 --> 28:17.540]  Um because he won like 100 grand including the car value on the original appearance and then like 4.3 million
[28:18.260 --> 28:21.300]  After that and can he beat ken jennings?
[28:22.420 --> 28:26.580]  in four of those outings four point seven million dollars total four point
[28:26.660 --> 28:31.060]  That's right. That includes the last tournament. So before that and so brad rudder was
[28:31.540 --> 28:34.980]  Uh for a while the winningest he'd won the most money of any
[28:35.540 --> 28:39.540]  person in game show history american game show history then ken briefly
[28:39.540 --> 28:45.220]  Got ahead of him because ken won some money in some non-jeopardy game shows then brad won another tournament or two
[28:45.620 --> 28:47.540]  And now ken is the most winning
[28:48.180 --> 28:49.460]  uh game show
[28:49.460 --> 28:54.420]  contestant of all time in america, uh, and then this dollar running and then the third is the guy who
[28:55.460 --> 29:02.660]  Shot to fame I think over the summer just the last in the last year late spring james james holzhauer
[29:03.220 --> 29:04.420]  Who?
[29:04.420 --> 29:07.780]  Really shook things up by playing in an unprecedented style
[29:07.780 --> 29:11.380]  And what he's hold his claim to the best of all time is that he has
[29:12.500 --> 29:14.260]  all 15
[29:14.260 --> 29:21.460]  Of the top single game winnings. So in other words, how much can you win on a single in one single 30-minute match?
[29:21.860 --> 29:22.820]  of jeopardy
[29:22.820 --> 29:28.660]  Uh spots one through 15 on the list are all james holzhauer and
[29:29.220 --> 29:31.940]  It really felt for a while like he had broken the game
[29:32.820 --> 29:35.940]  But I always thought while he was on his run
[29:35.940 --> 29:43.460]  I was like, this is genius and it it happens in pro sports all the time where somebody it doesn't really
[29:44.420 --> 29:50.900]  Or I shouldn't say all the time, but occasionally like a coach or a team will come up with a strategy
[29:51.220 --> 29:54.980]  Yeah that nobody had ever seen before like when you and I were young
[29:54.980 --> 29:58.340]  I don't know if you're you're probably not I know you're not a big sports guy, right?
[29:58.980 --> 30:04.340]  But I like the sports math more than that but but there was there in when I was in high school
[30:04.340 --> 30:06.340]  So this is like around 1990-1991
[30:06.820 --> 30:14.180]  There was a typical men's college. Well, actually men's and women's scoring is pretty close but in in college basketball
[30:14.180 --> 30:15.780]  It's a 40-minute game
[30:15.780 --> 30:18.580]  It used to be a 45-minute second shot clock
[30:19.300 --> 30:22.500]  and a typical score of top teams
[30:23.460 --> 30:29.620]  Is somewhere you know, like a winning score is often somewhere around 70 to 80 points, you know
[30:29.620 --> 30:35.220]  And you know that you know, there's a lot of variation. That's just the way it goes. So you might see a 50 to
[30:35.780 --> 30:40.020]  55 game once in a while and sometimes there's high-scoring teams that get
[30:41.060 --> 30:42.660]  close to 90
[30:42.660 --> 30:43.460]  and
[30:43.460 --> 30:50.660]  For a college game a hundred points is a lot. I mean that that means you were really really off the charts. Um,
[30:52.100 --> 30:57.700]  Just because it's only 40 minutes whereas nba plays a 48 minute game and therefore those
[30:57.700 --> 31:03.540]  extra it's you know, it's it that's significantly longer and they have a shorter shot clock and they're
[31:04.020 --> 31:08.340]  Better shooters because it's the nba versus college. So, you know nba typically
[31:09.140 --> 31:14.980]  You don't win games with fewer than 100 points, but in the 90s there was this in right around 1990-91
[31:14.980 --> 31:18.420]  there was this team at uh called loyola merrimount and
[31:19.460 --> 31:21.460]  They were scoring
[31:21.620 --> 31:25.780]  Like 160 170 points a game because they played
[31:25.780 --> 31:27.780]  Like their pants were on fire
[31:28.100 --> 31:30.020]  All 40 minutes
[31:30.020 --> 31:35.060]  So like imagine like the way that you would coach the team you don't have to be you don't have to really know much about basketball
[31:35.060 --> 31:37.780]  You just have to just have a basic idea of the game
[31:37.780 --> 31:43.860]  But imagine you're down by six points with a minute and a half to play the way that you would instruct your team to play
[31:43.860 --> 31:49.620]  Is full court press cover them as from end to end and try to trap them
[31:50.260 --> 31:53.860]  You know don't just sit there and wait for them to shoot like a typical moment
[31:53.860 --> 32:01.380]  At basketball do whatever we can on defense double team whoever has the ball gamble everything gamble everything on every play defensively
[32:01.700 --> 32:04.500]  And as soon as we get the ball no matter what we do
[32:04.900 --> 32:08.660]  Try to get a shot off as quickly as we can don't dribble down the court, right?
[32:08.660 --> 32:13.300]  You if you're not a sports fan, but you know, you know basketball, you know, the other team scores
[32:13.300 --> 32:18.500]  They give it to a guy and he you know dribbles the ball down the court and then they start passing it around until somebody
[32:18.500 --> 32:21.860]  Gets a shot loyola merrimount. There was no dribbling down the court you
[32:21.860 --> 32:26.820]  Always you passed it down the court. Yeah. Yeah, and they would it's super fast
[32:27.460 --> 32:33.540]  Right, but it felt like and they never won the NCAA championship, but they were very good and they did go far
[32:34.100 --> 32:37.860]  They ended up with the trail is a terrible tragedy actually where there was a guy named
[32:37.860 --> 32:41.620]  I mean, I hate to bring it all down, but there was a player on their team who actually
[32:42.260 --> 32:47.780]  In their best season at the peak of their powers. He guy named Hank gathers actually died of a heart attack at practice
[32:47.780 --> 32:54.100]  Oh, I remember that that was one of those those one of those first prominent ones where people with a unknown heart. Yeah, exactly
[32:54.100 --> 32:56.100]  Yeah, I remember that
[32:56.260 --> 33:00.100]  Yeah, there was no for the team, but I remember him. Yeah, and
[33:02.260 --> 33:07.620]  Well, and it was fine I forget his teammate but he had it were two guys on the team who were better than everybody else and
[33:08.100 --> 33:10.580]  His teammate caught off try to get it for the show notes
[33:11.060 --> 33:14.980]  but like in honor they then they had to go to the NCAA tournament and
[33:14.980 --> 33:22.180]  In honor of him, the guy was right-handed, but he did hank gathers was left-handed. So his teammate decided he would shoot all his free throws
[33:22.180 --> 33:23.460]  left-handed
[33:23.460 --> 33:28.420]  Which sounds like a recipe for like hey, that's you know, maybe wear an armband or something instead
[33:28.740 --> 33:34.180]  But but he shot he shot like 85 from the free throws left-handed. He was so good. But anyway
[33:34.980 --> 33:40.660]  Anyway, it's just private. It just looked like you'd be watching espn and it just seemed crazy like
[33:40.660 --> 33:44.580]  175 points or something like that. It it doesn't happen and uh
[33:45.540 --> 33:50.420]  a whole holes hours jeopardy dodles just seemed like that like it just seemed like that
[33:50.980 --> 33:53.700]  You're not supposed to you're not supposed to score 85
[33:54.500 --> 33:58.980]  90 000 in a day in jeopardy or a hundred thirty three
[33:59.620 --> 34:04.020]  Thousand and I remember watching that episode and just you know, my brain is melting
[34:04.660 --> 34:07.940]  Because well, I mean so roger craig had the privilege of doing that
[34:07.940 --> 34:11.700]  Because well, I mean so roger craig had the previous one day total
[34:12.420 --> 34:15.540]  I mean ken jennings had won I think 75 grand in one day, right?
[34:15.620 --> 34:21.300]  And that had been a little bit of an outlier for ken then roger craig who is a is one of us. He's a computer
[34:22.020 --> 34:27.940]  Programmer, I think database specialist and to prep for jeopardy. He sucks down the j archive which is a
[34:28.580 --> 34:30.080]  user created
[34:30.080 --> 34:36.340]  Constantly updated database of every jeopardy clue and game and statistics so I can find all my games there
[34:36.340 --> 34:38.900]  People so he sucked it down with you know, which is fine
[34:39.460 --> 34:45.380]  And he wrote software to to relentlessly train himself on all the common jeopardy
[34:46.020 --> 34:48.420]  clues, so he went through and just was like
[34:49.220 --> 34:53.860]  You know slashing and burning he knew a lot of information and he bet super aggressively
[34:53.860 --> 35:00.100]  But he only won I think nine games because he bet it all lost, you know, he and and james holzauer
[35:00.660 --> 35:02.500]  holzauer had um
[35:02.500 --> 35:04.500]  The knowledge like that guy. I cannot believe
[35:04.500 --> 35:08.420]  How quickly that guy is the answer to every goddamn thing in the world?
[35:08.580 --> 35:13.060]  Yeah, like I don't think i've ever met anybody who just has that much packed in his head. Yeah
[35:14.100 --> 35:20.020]  By the way, uh update here that the producers have told me that uh, hank gather's teammate was beau kimball
[35:20.340 --> 35:23.860]  That was the fellow's name who shot left-handed. Anyway, I put it i'll put it in the show notes
[35:23.860 --> 35:28.900]  There's an article speculating how they would play the game. Yeah, so so so while holzauer's playing by the way
[35:28.980 --> 35:30.980]  I don't know anything about him yet and uh
[35:30.980 --> 35:35.140]  And uh, there are some secret corners of the internet in which jeopardy contestants talk to each other
[35:36.100 --> 35:39.540]  There's secret corners for every everything and so a friend of mine tells me
[35:39.540 --> 35:41.700]  Hey, I got cast on the show a guy, you know in seattle
[35:41.700 --> 35:46.020]  So i'm going down to tape and uh, he comes back and i'm like, I know i'm not gonna ask you how to go
[35:46.100 --> 35:48.900]  He said he said I had a great time or whatever. I'm like, oh, okay
[35:49.540 --> 35:54.100]  So the show airs it turns out he was playing on the third game that holzauer played
[35:54.100 --> 36:01.000]  And and he made an incredibly strong showing and holzauer what he and holzauer were contending
[36:01.380 --> 36:06.740]  Neck and neck and my friend wound up with like 17 000 bucks at the end of double jeopardy
[36:07.140 --> 36:10.980]  But holzauer had gotten like I think two double jeopardy or two daily doubles
[36:11.300 --> 36:13.620]  So holzauer finishes up with like 42 000 dollars
[36:13.620 --> 36:17.940]  But you know my friend had like they they were neck and neck and in any other game
[36:17.940 --> 36:21.940]  My friend was playing at like a master level and you're playing against the grand master
[36:21.940 --> 36:25.620]  And my friend would have won, you know, five or ten or fifteen shows
[36:25.700 --> 36:30.100]  I think if he hadn't been playing against the whole that's unbelievable, but what about bad luck?
[36:30.340 --> 36:34.180]  well, the other weird thing about holzauer is is that um
[36:35.140 --> 36:39.620]  he apparently a part of his uh preparation was that he
[36:41.780 --> 36:47.940]  He apparently really studied where they put the daily doubles because they're not they're not completely random
[36:48.580 --> 36:49.780]  and
[36:49.780 --> 36:51.780]  He strategically
[36:52.260 --> 36:56.740]  Would play for them and I guess what he would do is avoid them at first to build up
[36:56.980 --> 36:59.700]  A bit of money so that he'd have something to wager
[37:00.580 --> 37:04.580]  And then strategically hunt for the daily doubles by jumping all over the board
[37:05.300 --> 37:06.580]  and
[37:06.580 --> 37:08.660]  it just and would just tend to
[37:09.300 --> 37:13.860]  Push it all in and just try to double his money and build these insurmountable leads, you know
[37:14.100 --> 37:16.980]  And there were times when the matches they were obviously over
[37:16.980 --> 37:23.380]  You know 20 minutes into the show. Yeah, because he he'd already hit two of the daily doubles doubled his money both times
[37:23.460 --> 37:26.100]  And there wasn't enough money on the board for anybody to get
[37:28.500 --> 37:33.860]  I mean cry and watching some of those right these poor people the basic math is that to have a chance to win
[37:33.940 --> 37:37.460]  You have to be at least within half of whoever's in first place
[37:37.700 --> 37:44.340]  So who if the person's in first place has already has thirty thousand dollars you need at least fifteen thousand to
[37:44.340 --> 37:49.300]  Have a chance because otherwise, you know, you're the person in front is not going to bet
[37:49.860 --> 37:55.380]  Enough, you know unless they're a maniac. They're not going to bet enough to risk losing on on the final jeopardy
[37:55.460 --> 37:55.780]  Yeah
[37:55.780 --> 37:56.020]  Yeah
[37:56.020 --> 38:01.380]  so that's the amazing part is whole tower we're going to final jeopardy with so much money that he could bet and
[38:01.540 --> 38:07.140]  Still win if he was wrong and he still would get all day, you know, these hundred and thirty-three thousand total
[38:07.140 --> 38:13.460]  I mean a typical game of jeopardy finishes with the winner getting somewhere between I don't know like twelve and thirteen
[38:13.460 --> 38:17.460]  Twelve and thirty thousand dollars, uh, jeff duncan longtime, uh, uh
[38:18.020 --> 38:24.900]  Technology writer musician another seattle guy. He was also on he did not play james holzauer. He won over thirty thousand dollars
[38:24.980 --> 38:26.980]  he only won one game, but he
[38:28.020 --> 38:33.060]  Blew through that and won like 31 grand in one day and we're all like wow, it was great
[38:33.220 --> 38:39.620]  What is up with tidbits contributors and winning on jeopardy? I know we now have the highest highest percentage of
[38:40.580 --> 38:42.260]  any publications
[38:42.260 --> 38:46.420]  Members, it is funny though. I um, I if you go if I go to certain kinds of events
[38:46.820 --> 38:50.660]  Uh that are for like quirky or artistic people or certain kinds of tech things
[38:50.980 --> 38:56.900]  There are always uh, I went to a kickstarter thing and I think there were two other jeopardy contestants including another winner
[38:57.380 --> 38:59.380]  Uh who were among the attendees?
[38:59.620 --> 39:01.620]  It was just a kind of personality
[39:02.020 --> 39:09.620]  So anyway, they held this tournament the greatest of all time with those three fellows ken jennings who won the most episodes brad rudder who had
[39:09.620 --> 39:15.940]  Won the most total money over the years and holzauer who had the single single record things
[39:17.220 --> 39:22.340]  And they created a prime time special and the the rules I thought the rules were very well designed
[39:22.500 --> 39:27.140]  The idea was that each each episode would be two jeopardy matches
[39:27.220 --> 39:31.940]  So it was instead of a 30 minute, you know one one time through jeopardy. It was two
[39:33.060 --> 39:34.180]  and
[39:34.180 --> 39:37.140]  those two jeopardy matches combined
[39:37.140 --> 39:44.580]  You know, whatever you finished with would it would give you the winner of the day and the first person who won three days
[39:45.380 --> 39:51.460]  Would be crowned the greatest of all time. And so it was indeterminate how long the tournament would last in theory
[39:52.020 --> 39:57.300]  It could have lasted nine matches if they'd all won twice and then the last one would be you know
[39:58.020 --> 40:02.820]  Would be the whoever one would would hit three or it could have only lasted three, you know, and I
[40:02.820 --> 40:09.060]  My fear was that and you asked me before it started or maybe I had started but I told you I hadn't started watching it
[40:09.060 --> 40:10.820]  and by the way
[40:10.820 --> 40:14.420]  If you want to watch you could pause the podcast now
[40:15.780 --> 40:17.780]  Because we haven't spoiled who won yet
[40:17.940 --> 40:22.900]  It is totally worth watching if you really want to you could pause this show right now
[40:23.060 --> 40:28.260]  It'll it'll sit there in your podcast player and you could take a couple of nights and watch it
[40:28.260 --> 40:32.740]  They're on hulu. It's on hulu. It is on hulu. So anybody who has hulu
[40:33.380 --> 40:39.540]  Can get those episodes it is really good. And so if if you've been listening to me and glenn and you think this sounds great
[40:40.260 --> 40:42.100]  I would like to watch it
[40:42.100 --> 40:44.100]  Before we tell you who won
[40:44.100 --> 40:48.500]  You could pause this podcast right now and go watch on hulu over the next
[40:49.300 --> 40:53.300]  A couple of nights or whenever you have time to watch hulu. It's a lot of fun
[40:54.500 --> 40:55.620]  but
[40:55.620 --> 41:03.140]  from now forward we're we'll reveal spoilers as we say in the incomparable fire off the spoiler horn right you asked me who I was rooting for
[41:03.140 --> 41:08.900]  And I and I was rooting for ken jennings because I i've never seen i'm not a daily jeopardy watcher
[41:08.900 --> 41:12.900]  I don't watch all the time. I watched a lot more when I was younger and when I lived it, you know
[41:12.900 --> 41:17.140]  I mean really young I mean, I mean like jeez like, you know living at home
[41:17.140 --> 41:20.260]  So, you know, we're talking like 30 30 years ago
[41:20.260 --> 41:26.580]  I but I did watch jennings during his streak and and then once holzhauer started I started watching and I was
[41:26.980 --> 41:33.540]  Fascinated and it makes sense to me that holzhauer is you know, his profession is that he's apparently a professional gambler. Yeah exactly
[41:34.420 --> 41:39.780]  Which I know a lot of people think is like a myth that there are people who could like live in vegas and be
[41:40.080 --> 41:42.080]  Professional gamblers. I don't know. It's a
[41:43.220 --> 41:47.220]  Well the bloke is a very professional gambler
[41:47.220 --> 41:53.220]  Well, the blackjack angle is probably, it's really tough.
[41:53.220 --> 41:56.220]  I mean, I don't have a big stake is the thing.
[41:56.220 --> 41:59.220]  You have a big stake and you get marginal returns if you know how to play it right.
[41:59.220 --> 42:00.220]  So you don't make a ton of money.
[42:00.220 --> 42:02.220]  But poker is real.
[42:02.220 --> 42:05.220]  I forget, does Holzhauer play poker or is he only bets sports?
[42:05.220 --> 42:08.220]  I know he says he bets sports and sports is tough.
[42:08.220 --> 42:10.220]  I think he does mostly sports.
[42:10.220 --> 42:13.220]  I think he's been, I think he's generally pretty good at it.
[42:13.220 --> 42:15.220]  As you can tell, he's got undeterred.
[42:15.220 --> 42:19.220]  I mean, I think you have to be, I think you have to pursue a strategy if you're a professional, right?
[42:19.220 --> 42:22.220]  You pursue a strategy and you don't second guess yourself all the time
[42:22.220 --> 42:26.220]  because you're trying to get a certain level of consistent return.
[42:26.220 --> 42:28.220]  And it might only be like 3%, right?
[42:28.220 --> 42:30.220]  Like a grocery store or something.
[42:30.220 --> 42:34.220]  But you get comped rooms, you get other kinds of free things along the way besides money.
[42:34.220 --> 42:42.220]  Yeah. The basic idea and when you bet pro sports is you have to bet $110 to win $100.
[42:42.220 --> 42:45.220]  And that 10% difference is the big.
[42:45.220 --> 42:51.220]  So if you bet 100 times and you bet $100 each time, you win $100.
[42:51.220 --> 43:00.220]  Or if you win 50-50, you just lose 110 every time you lose and you win 100 every time you win.
[43:00.220 --> 43:02.220]  And that 10% eventually kills you.
[43:02.220 --> 43:06.220]  You have to win, that's if you win 50% of the time.
[43:06.220 --> 43:11.220]  You have to win, I think it's 54.3% of the time to break through.
[43:11.220 --> 43:21.220]  It's not that, it doesn't sound that much higher than 50%, which is why people like me love to bet on sports.
[43:21.220 --> 43:27.220]  But in practice, they're dastardly good, the people who set the betting lines,
[43:27.220 --> 43:34.220]  they're dastardly good at setting them in a way that more or less makes it 50-50.
[43:34.220 --> 43:39.220]  They're not trying to, Vegas isn't trying to beat you, beat everybody all the time, that's impossible.
[43:39.220 --> 43:45.220]  All they want is for half the people to win and half the people to lose and they just collect that 10% and it's a lot of money.
[43:45.220 --> 43:54.220]  But if you're good enough to pick the games where the line is mathematically off,
[43:54.220 --> 44:00.220]  where you see that for the Super Bowl, the Kansas City Chiefs are,
[44:00.220 --> 44:06.220]  last I checked, are currently favored by 1.5 points over the San Francisco 49ers.
[44:06.220 --> 44:12.220]  If you've got a mathematical model based on the season stats,
[44:12.220 --> 44:18.220]  maybe probably geared towards the more recent games and the more recent results,
[44:18.220 --> 44:22.220]  and you also follow along and you know who's injured, etc.
[44:22.220 --> 44:31.220]  And you can figure out that the line really ought to be that San Francisco should be favored by 1 point.
[44:31.220 --> 44:35.220]  Well then you realize it's a really good bet mathematically to bet on San Francisco.
[44:35.220 --> 44:41.220]  That doesn't mean your bet is going to win, it just means that if you do that more often than not,
[44:41.220 --> 44:47.220]  maybe you can win 57% of the time and stay ahead of the big, something like that.
[44:47.220 --> 44:51.220]  Definitely possible and you watch Holds Hour play Jeopardy and I believe it.
[44:51.220 --> 44:56.220]  But poker is the other game where you can easily be a professional gambler
[44:56.220 --> 45:00.220]  because you're not playing against the house, you're playing against other players.
[45:00.220 --> 45:06.220]  Yeah, they just take a small cut out of the pot out of every pot and that's it.
[45:06.220 --> 45:12.220]  And you just have to be both better than other players and better enough than the typical other players
[45:12.220 --> 45:19.220]  to compensate for the 3 or 4% that the house takes out of every pot.
[45:19.220 --> 45:22.220]  Definitely a lot of professional poker players.
[45:22.220 --> 45:29.220]  Anyway, he definitely played like a gambler, not like a quiz show contestant.
[45:29.220 --> 45:35.220]  Yeah, he was just incredible. Basically he was like a machine too.
[45:35.220 --> 45:41.220]  He was relentless. He's not very emotional because he's in work mode, right?
[45:41.220 --> 45:43.220]  So people gave him, there was some criticism about like,
[45:43.220 --> 45:47.220]  boy, he seems like an uncaring person or whatever.
[45:47.220 --> 45:51.220]  And he'd be like, well, no, he's got a game face and this is a job.
[45:51.220 --> 45:54.220]  He's come in here thinking about this and he kind of talked about it that way.
[45:54.220 --> 45:57.220]  His plan was to win as much money as he could and he did.
[45:57.220 --> 46:00.220]  And not that he didn't have a good time, I don't think,
[46:00.220 --> 46:05.220]  but the way he talks about his family, he kept putting in birth dates as the wagers,
[46:05.220 --> 46:09.220]  he was writing in messages, talking about his grandmother,
[46:09.220 --> 46:12.220]  he was a Japanese immigrant who didn't speak much English
[46:12.220 --> 46:17.220]  and how he promised to go on the show and they watched it together.
[46:17.220 --> 46:24.220]  He's actually, I think, a very sweet guy who comes across as many people like us in this technology world.
[46:24.220 --> 46:30.220]  Sometimes we come across as a little in our heads and so I was very sympathetic with the way he came off.
[46:30.220 --> 46:35.220]  But he really, it was a job and he came in every day and he just went bam, bam, bam, bam, bam.
[46:35.220 --> 46:41.220]  And if he lost, it would be like, whatever, because he just was so good at racking up the money.
[46:41.220 --> 46:44.220]  He'd already won all the money you could possibly want.
[46:44.220 --> 46:46.220]  So at that point, I mean, I think he talked about that a little bit.
[46:46.220 --> 46:49.220]  It's like, how do you go all in when you can lose everything?
[46:49.220 --> 46:53.220]  It's like, well, if you no longer care, if it's a wager and you're not looking at it as dollars,
[46:53.220 --> 46:58.220]  it's like a one or zero. It's not a $50,000 because it's fake money.
[46:58.220 --> 47:00.220]  It's not real money until you take it home.
[47:00.220 --> 47:05.220]  And I think he had played that strategy better than anyone has ever been able to play it.
[47:05.220 --> 47:08.220]  So my fear, I was rooting for Ken Jennings.
[47:08.220 --> 47:13.220]  Not strongly because they're all interesting people and they all seem very likable.
[47:13.220 --> 47:15.220]  It's just such an interesting premise.
[47:15.220 --> 47:18.220]  But if I had to say I was rooting for someone in advance, it was Ken Jennings.
[47:18.220 --> 47:26.220]  But my fear was that Holzhauer was just going to win, you know, just clean the plate.
[47:26.220 --> 47:32.220]  It just seemed like there was a chance there that he's just unstoppable and that he's too good on the buzzer,
[47:32.220 --> 47:40.220]  even against someone like Ken Jennings, who, you know, obviously, like you said, has tremendous buzzer experience.
[47:40.220 --> 47:42.220]  But I think what did it go?
[47:42.220 --> 47:49.220]  So it was Ken Jennings won first. Yeah, by like 200 points for the first two games.
[47:49.220 --> 47:56.220]  And it was like, oh, it's going to be like that. And then James won the second game by a pretty good margin.
[47:56.220 --> 48:01.220]  And then Ken kind of demolished James in the third episode.
[48:01.220 --> 48:03.220]  And then the fourth, it was kind of the same thing.
[48:03.220 --> 48:09.220]  Like there were a couple tricky questions in the fourth where Ken could have lost practically everything and really tanked.
[48:09.220 --> 48:14.220]  And James would have won by a huge amount. But Ken got the answer correctly for some big bets.
[48:14.220 --> 48:20.220]  Yeah. And he said later, he said, if I'm playing against James Holzhauer, I have to play James Holzhauer style.
[48:20.220 --> 48:26.220]  So he would go in all in in a way that Ken typically had in another play. Right. And it worked for him.
[48:26.220 --> 48:34.220]  Yeah. And and Ken didn't seem to have as much success in previous tournament of champion things compared to Brad Rudder.
[48:34.220 --> 48:40.220]  And Rudder got more or less swept out. He was really not competitive in any of the four days.
[48:40.220 --> 48:45.220]  So anyway, Ken Jennings was the winner. He won the first, third and fourth.
[48:45.220 --> 48:49.220]  But on the second, Holzhauer creamed everybody.
[48:49.220 --> 48:57.220]  And a couple of Jennings wins really came down to like getting one answer correct on a push.
[48:57.220 --> 49:07.220]  And Alex even Alex Trebek even called him on it, where on a lot of his answers, he was really answering like a question like in.
[49:07.220 --> 49:17.220]  And, you know, Ken Jennings has been on the show enough times that Trebek knows that he's not like doing it for dramatic, dramatic effect.
[49:17.220 --> 49:22.220]  Like he was making his best guess on a lot and got them right.
[49:22.220 --> 49:27.220]  Yeah, like the nullification one about states rights. And I was like, we're all you know,
[49:27.220 --> 49:31.220]  I think that all four of us in the family are watching and, you know, the kids are actively studying some of this stuff.
[49:31.220 --> 49:37.220]  So it's a little fresher to them than my wife and I. And we're all like, is it was that this or that was it?
[49:37.220 --> 49:42.220]  We're like, I think maybe my older said nullification. I forget somebody in the house, I think, said it.
[49:42.220 --> 49:46.220]  And Jennings said nullification. We're all like, oh, it doesn't sound right. And it's like, yep, that was it.
[49:46.220 --> 49:54.220]  Like, oh, my God. But it was great TV and it had a huge ratings, too. It was one of the I think the top rated show in its slot.
[49:54.220 --> 49:56.220]  It did very well all four nights.
[49:56.220 --> 49:58.220]  It was a great idea.
[49:58.220 --> 50:00.220]  It was fun. It was fun.
[50:00.220 --> 50:05.220]  No, I wrote a piece, Motherboard asked me if I'd write something up after game three before game four.
[50:05.220 --> 50:10.220]  And I did some statistical analysis. And Brad Rutter was only answering.
[50:10.220 --> 50:15.220]  He was only only buzzed in half as frequently as the other two to start with.
[50:15.220 --> 50:23.220]  He was wrong about 11 percent of the time. And Ken was wrong slightly more than I'm sorry, James is wrong slightly more than Ken.
[50:23.220 --> 50:28.220]  And Ken was right on every daily double he got the first three games.
[50:28.220 --> 50:37.220]  So you could see just from the standpoint of play over three games, it looked like Ken was playing just I mean, this is kind of the or the the gambling thing.
[50:37.220 --> 50:41.220]  Ken was playing just slightly better, not crazily better, but just enough.
[50:41.220 --> 50:46.220]  And that edge meant that every time he won on a daily double, he was able to leverage it ahead.
[50:46.220 --> 50:48.220]  I don't know how old they all are.
[50:48.220 --> 50:55.220]  Oh, oh, I forgot the exact range. We're about 10 years in age part.
[50:55.220 --> 51:01.220]  Holzhauer was the youngest in his 30s. Brad Rutter is about five years older and Ken's about five years old.
[51:01.220 --> 51:08.220]  And I think I think there's about a 10 year age. Ken is the oldest by and he was talking about, you know, kind of hanging up his spurs.
[51:08.220 --> 51:13.220]  Like I'm an old man. I don't know. I'm being 43 or something. Forty five. I don't know.
[51:13.220 --> 51:15.220]  He said I don't know if I'll do it. And he's now he said he's not going to play anymore.
[51:15.220 --> 51:20.220]  Like he said, this was I can't top this. I'm going out, you know, handed over to the next.
[51:20.220 --> 51:32.220]  Thanks. Roll. Rutter even said during one of the hey, let's talk about the champions things that he he he could tell that he's lost his step since his, you know, Jeopardy Prime 15 years ago or I guess close.
[51:32.220 --> 51:37.220]  I don't know, 20 years ago, whenever it was in the tournaments. I mean, he's played tournaments more recently.
[51:37.220 --> 51:44.220]  But the tournament play is different because you're you're beating. I mean, even though you're going head to head against someone like Ken Jennings, you kind of work your way up.
[51:44.220 --> 51:48.220]  So you're not playing every game against the best people in the world or the two other best.
[51:48.220 --> 51:53.220]  I mean, the way I look at it is Brad Rutter had never played against the two best players in Jeopardy history.
[51:53.220 --> 51:59.220]  Only one and against two of them. And, you know, I couldn't win a single game today.
[51:59.220 --> 52:07.220]  I mean, I was stumped like the entire first game board of the first game this run. I was like, what? Oh, my God.
[52:07.220 --> 52:12.220]  And the second I was better, like I couldn't I couldn't win a game today. I just don't I don't have the speed.
[52:12.220 --> 52:15.220]  Yeah. Or necessarily the recall. Yeah.
[52:15.220 --> 52:18.220]  And the one that really was shows how smart these guys are and how good they are.
[52:18.220 --> 52:27.220]  Were there a couple of days they had the categories where it's like some kind of like two different things and you have to put them together into a pun.
[52:27.220 --> 52:30.220]  Oh, my God. That one. Yeah, that was hilarious.
[52:30.220 --> 52:35.220]  I think I could get some of those if you gave me a half an hour and they were just like, boom.
[52:35.220 --> 52:42.220]  They're like, Buzz, is it like, Jesus? How does your brain work? Anyway, I had a great time watching.
[52:42.220 --> 52:48.220]  All right. Let me take a break here and tell everybody about clear.
[52:48.220 --> 52:59.220]  Clear makes your life safer, simpler and more secure with clear your eyes and your fingertips get you through security faster at airport stadiums and other venues.
[52:59.220 --> 53:09.220]  Never run to your gate again. Clear helps you get through security with the tap of a finger so you can get to your gate faster and reduce preflight stress.
[53:09.220 --> 53:26.220]  You are your ID. Start getting through security with a tap. Clear replaces the need for physical ID cards using your eyes and fingertips to get you through security because you your biometrics are the best ID out there.
[53:26.220 --> 53:32.220]  Reminds me a lot of 2001. I just went to see it again last year when it was released into theaters.
[53:32.220 --> 53:39.220]  I had forced my son to wait. He'd never seen the movie before. And Heywood Floyd, top security expert for the US government.
[53:39.220 --> 53:45.220]  When he gets to the moon base, Clavius, how does he get through security with his biometrics?
[53:45.220 --> 53:49.220]  A little retinal scan looks through his eyes. Well, that's what clear is like.
[53:49.220 --> 53:56.220]  It's just like 2001 has finally caught up with us. You go to the airport, you sail right through security.
[53:56.220 --> 54:08.220]  What you do, here's how you do it. You create your account online before you go to the airport. Once you get to the airport, go to the line for clear and a clear ambassador will be there to help you finish the process of signing up.
[54:08.220 --> 54:15.220]  And then you can immediately use clear. Clear helps you get through security faster and 65 plus airports.
[54:15.220 --> 54:20.220]  But it's not just airports up stadiums and other venues to a whole bunch of stadiums.
[54:20.220 --> 54:29.220]  Major League Baseball, NFL Football. These leagues now have policies that implement airport style security before you get in the stadium.
[54:29.220 --> 54:40.220]  It's a big pain in the butt. But guess what? If they have clear, you sail right through just like you did in the old days before there was onerous security like that at stadiums.
[54:40.220 --> 54:52.220]  And they have family plans. If you're traveling with your family, up to three family members can be added at a discounted rate. And kids under 18 are free when traveling with just one clear member.
[54:52.220 --> 55:07.220]  Totally free if you have kids under 18. Clear is the absolute best way to get through airport security. And it works great with TSA pre check to right now listeners of the talk show can get their first two months of clear.
[55:07.220 --> 55:29.220]  Absolutely free. Go to clearme.com clearme.com clearme.com slash talk show and use that code talk show that's clearme.com slash talk show with code talk show and you will get free two months of clear.
[55:29.220 --> 55:35.220]  Go sign up sail through the airport like you never have before. My thanks to clear for sponsoring the talk show.
[55:35.220 --> 55:49.220]  Next topic. What do you think iPhone encryption never never gets old does it? I've been writing about it a lot. I really really feel like it's the sort of thing that needs to be nipped in the bud.
[55:49.220 --> 56:05.220]  It's not worth waiting until it if, to me, the DOJ gets its way and gets legislation proposed to limit it like it really needs to be nipped in the bud as a bad idea.
[56:05.220 --> 56:24.220]  I think people who listen to the show and follow my site know the basic story but basically there's this Pensacola shooter this guy who shot up a navy base and he had two iPhones and he and shot a couple of people, and he's dead now.
[56:24.220 --> 56:40.220]  But the federal government would like to get access to his phones and Apple has provided as much information from his iCloud accounts as they could apparently measuring in the gigabytes.
[56:40.220 --> 56:55.220]  But Attorney General William Barr is is raising hey that it's not it's not right or according to him that the FBI that law enforcement officials can't just quote unquote get into iPhones.
[56:55.220 --> 57:02.220]  You know when they have a court order, etc etc and Apple is answer is more or less we can't, we can't help you.
[57:02.220 --> 57:08.220]  Although they haven't definitively said can't, I guess, you know.
[57:08.220 --> 57:20.220]  And and there's some ambiguity over that and I feel like I've, I've over the years I've lost track of exactly how this works and what literally what we know can and can't be done.
[57:20.220 --> 57:22.220]  You know what I mean.
[57:22.220 --> 57:42.220]  Well, yeah, because they're right. The fundamental thing is that starting with. I've lost track of the five s is starting with when Apple built secure enclave and as a separate chip into the iPhone architecture, they effectively abrogated their ability to extract
[57:42.220 --> 57:58.220]  information that like the passcode right that would decrypt the phone. And because they designed the system around pushing all of the generation of key material that would allow decryption or access to each device.
[57:58.220 --> 58:12.220]  So, the issue is, and I think this came up with the San Bernardino shooters a few years ago and this previously came up is Apple had said, we'd have to create what they would call a government OS we have to create a special OS be able to load it on the machine
[58:12.220 --> 58:33.220]  and this OS would allow more rapid calculation, it would bypass the, the limits on lockouts that be that Apple started to add, you know, alongside secure enclave. So, the issue even isn't so there's like multiple issues one is the current iOS and iPad OS is
[58:33.220 --> 58:51.220]  the hardware architecture is designed to prevent rapid fire brute force cracking. So you can't just enter a bunch of different passcodes. So there was a gray not gray bar gray gray lock. Yeah, it's the one right they they and maybe some other folks had ostensibly allegedly developed systems
[58:51.220 --> 59:11.220]  gray shift is a gray gray shift. And their product is gray key gray key is the little sort of like I Mac mini sized that's Thank you device. Yeah, celebrate and gray shift or the companies, at least the two, they claim to be able to break in, and they seem to have been able to bypass
[59:11.220 --> 59:31.220]  hardware and software. Well, this has to be baked into hardware protections, and protections in the in the certified OS that would allow them to then do brute force cracking and crack shorter keys. And as you know, as the audience I'm sure knows, the longer key is or the more complicated it is, you know, four digit key can be solved very quickly.
[59:31.220 --> 59:46.220]  A pin six digit takes quite a bit longer. If you do something like me, a 20 mixed character alpha numeric, the heat death of the universe couldn't come too soon. But you know, really, it's years or something to go through all the iterations as rapidly as the software
[59:46.220 --> 01:00:15.220]  could take them with no throttle in place. So Apple said, Hey, we're not going to make in the San Bernardino case, we're not going to make a government OS, we don't want to be compelled to do this, that would bypass the brute force cracking speed is my recollection, right. And then the other part was, we can't give you the key because we built our system, so that we don't have access to it. It's locked away, you'd have to break open the secure enclave and like a clean lab, and even then the chip would probably self destruct. I mean, that's they didn't say that. But that's the way these chips are built, you know,
[01:00:15.220 --> 01:00:44.940]  the way these chips are built, you wouldn't, you shouldn't be able to extract information from them, even with like scanning electron microscopes, right? The issue today? Well, I think if my understanding is correct, and this is complicated enough where I feel like I'm uncertain, but tell me if you agree, I think the best way to think about it is that there's two, I don't want to say operating systems, let's just say systems on an iPhone, and it just goes for iPad two. There's iOS,
[01:00:44.940 --> 01:01:12.700]  which is what is the traditional operating system that runs the device as a computer. As we know it, I think with the CPU and RAM and storage, and input output and USB support through the lightning connector or the USB C port on an iPad Pro. And it's an operating system that runs on a computer and Apple does its best to keep that secure.
[01:01:12.700 --> 01:01:40.340]  They also have at a hardware level, I believe it is true that that an iOS device will not accept an operating system that has not been signed by Apple. That that's correct. And there was this jailbreak, if you jailbreak a device, you're essentially figuring out a way to bypass to take a modify, take a bug and exploit the bug to run arbitrary code.
[01:01:40.340 --> 01:02:10.100]  And then that code does something to defeat Apple, but, but you can't really create your own version of iOS and get it to install on an iOS device without having it be signed by Apple. And when I say signed by Apple, there was a story I was looking for today and couldn't find it off to see if I can find it. But there was a story a couple of years ago that to sign a release of iOS, it is it really is like
[01:02:10.100 --> 01:02:13.820]  something out of a Mission Impossible movie, you know,
[01:02:13.820 --> 01:02:38.540]  yeah, there was a question about whether people were trying to subvert the engineers at Apple, there's only a few people at Apple, it's a very small number, who have, like the fingerprint and retinal and whatever stuff that allows them to access the thing that allows them to sign the operating system. And so if you subvert those people, could you then conceivably, right, so even who they are, is kept secret. And that was a concern, I think,
[01:02:38.540 --> 01:03:08.420]  you know, and it, you know, you think like, you know, it's nothing really works like that, where there's a secure underground vault with with locked doors and guards. And, you know, like, you know, and people believe it for like a nuclear submarine were to two members of the crew, more than what is possibly arms distance away, you know, like, let's say at least 10 feet away, have to put keys that they can
[01:03:08.420 --> 01:03:36.140]  actually keep with them around their neck 24 hours a day, and simultaneously turn the two keys. So two officers have to turn keys that couldn't possibly be done, you know, just physically by by one person. There's a system like that in place where like two Apple employees have to use physical objects. I don't know if they're keys, they're probably, you know, more complicated than like, you know, a physical key, but
[01:03:36.140 --> 01:04:06.060]  it's like, it's an encrypted, it's a device itself that contains encrypted information that has to be inserted, right. And they both have to do it in in a room and can only be done in a room whose location Apple literally won't won't disclose the the actual location. I mean, presumably, it's somewhere in Cupertino on one of Apple's campuses, you know, but who knows? I mean, just for practicality sake, you know, you would assume it's somewhere in Cupertino, and perhaps they've moved it from the old Infinite One
[01:04:06.060 --> 01:04:35.580]  Campus to the new one. But I honestly believe it's actually underground. Only a handful of Apple employees have access, there's obviously some kind of plan in place for what happens if one of the people involved, you know, it proverbially gets hit by a bus. But it really is that difficult. It is not it, you know, really sounds like something out of Mission Impossible or James Bond movie or something like that. So just to get a version of iOS that that that that these devices will
[01:04:35.580 --> 01:04:39.380]  sign at a hardware level, they really won't sign unless they can check.
[01:04:39.380 --> 01:05:09.340]  This is a real thing in a there's a bunch of there's a bunch of industries, there's a bunch of kinds of things around the world that are like this. I mean, this is one of the most critical because it's device specific. And I assume Google has a very similar thing. I remember a few years ago, I had to look it up while you're talking because I want to remember the detail is there was a ceremony in which to sign the root for DNS. So you know how there's all these root.com and, and whatever different domains, but there's also
[01:05:09.540 --> 01:05:37.420]  root servers that are the root of authority for all of DNS. There's a bunch of them run redundantly around the world. Well, in order to sign the root certificate to start the process to get a secure and encrypted form of DNS underway, they had to get a bunch of people together. They all got together and they all had to be in the same physical place to sign these keys with the specific cryptographic hardware that they owned.
[01:05:37.420 --> 01:06:07.220]  And I was talking to the folks at Let's Encrypt that have they would offer free SSL certificates or HTTPS certificates for websites talking to their CEO last year. And he said one of the most expensive things they own is a device that is designed to protect their root. And, you know, it's tamper resistant, it's it's got various safeguards, it's in a secure facility that has to meet certain international standards. And this is a real it's it's a it's not casual.
[01:06:07.220 --> 01:06:36.540]  Now, I think you also need years ago, it was much more casual. And now it is certainly not now, right, in addition to the fact that the the iOS devices at a hardware level will not accept a, a version of iOS that is cryptographically signed, provably by Apple, it I also believe, and I think you would know, correct me if I'm wrong, that you cannot update, there's no way to update an iOS device offline.
[01:06:37.380 --> 01:07:05.300]  It also must be online to call back to Apple over HTT over SSL secure, and make sure that Apple is still agreeing to sign this OS so that if if there's a known bad version of iOS, if Apple releases a version of iOS, and then after it's out realizes, we know that this version is compromised in some way by a bug,
[01:07:05.300 --> 01:07:23.540]  we're going to revoke the signing certificate for that. And then there's no way to get that version of iOS onto a device, because it still before it'll go, it has to call home to Apple securely. And Apple has to say yes, that is still a valid signed version of iOS.
[01:07:23.540 --> 01:07:36.900]  No, you're totally right. And I don't think I thought about it that way. But it's correct. Mac OS, you can still update offline with the installer that's signed and so forth. But there are revocation processes. But I think if you're Mac, we're not on the internet. I believe it's still
[01:07:36.900 --> 01:07:55.620]  I think so too feasible. But yeah, so whenever you see if you're using iTunes to restore, well, an image, and I think that's because that Apple still acknowledges that there are there are scenarios. Oh, yeah, where people have Macs that are in rooms that, you know, aren't their internet access isn't allowed.
[01:07:55.620 --> 01:08:19.380]  Oh, yeah, no, that makes total. Yeah, that's, that's right. And yeah, but so every iPhone and iPad, when you install an update directly from the device, it has that verifying stage, which may seem mystifying, because didn't it just download it? It's like, yes, it did. But a cracker could conceivably force a device to sideload. I mean, there's, you know, management tools, maybe they could get an update. That's not legit. So I still have to phone home.
[01:08:19.380 --> 01:08:43.300]  All of this is to say is that Apple takes the security of iOS, and the ability to only sign known good versions of iOS as as I don't know what more they can do, other than to continue to hunt bugs and continue to look for better ways. But it literally is to the best of their abilities to keep iOS as secure as possible at every step of the way.
[01:08:43.300 --> 01:09:12.580]  That said, there are known exploits in iOS that allow people and especially older versions. What's the name of that one that came out in the bootloader, which is unfixable? There's there's a low level part of the operating system. It's in this only for older devices. Yeah, it was fixed. And I think the last version affected was the iPhone 10. Checkmate. Checkmate. Yeah, see CHE
[01:09:12.580 --> 01:09:42.500]  c k m, and then the number eight because whoever found it, you know, is a hacker and names things that way. But there's a, there's a bug in the bootloader of every iPhone up to the iPhone 10 generation. So I guess the iPhone eight would be included. Which unfortunately compromises iOS in a way and Apple can't fix it because the bootloader is part of is, is ROM, you know, to go, you know, you don't really think about
[01:09:42.500 --> 01:10:12.340]  exploit physical proximity after physical access to the device, you do have to have physical access to the device. But anyway, that said they take as much they do as much as they can to keep it secure. They fix that bootloader issue in the iPhone 10 s and 11. But people can still get into iOS and Apple fixes those bugs when they as soon as they know about them. But getting into iOS does not get you into the data
[01:10:12.340 --> 01:10:42.100]  on the device because the the encryption of the device is that second system I alluded to earlier. So there's iOS. And it's not like Apple takes iOS security lightly, they take it as seriously as they can. But then there's the secure enclave and the secure enclave isn't just a a secure storage device. It is a it's a system it is in effect its own computer. And it it now like one of the things
[01:10:42.100 --> 01:11:12.060]  that they changed, I believe, is it so like there's an 80 millisecond delay. Anyway, when you type in your passcode, when you type in your password, passcode, whatever you have to unlock your phone. iOS doesn't it takes the input, you tapping 1234 on the keypad on the screen is obviously handled by iOS. But then
[01:11:12.060 --> 01:11:41.900]  iOS takes that passes it to the secure enclave and says, here's a guess at the passcode to the encryption. It's the secure enclave that takes that guess, and computes whether or not it's valid. And Apple has designed it, I don't think originally, I think it's one of the changes since the five s. And I know that the secure enclave your your guess was right, it definitely coincides with the five s, which
[01:11:41.900 --> 01:11:43.700]  is biometric authentication,
[01:11:43.980 --> 01:12:11.540]  because they offer encryption of Yes, because they offered that's it. Before that, you could encrypt your phone, but it was a slow process, right? And that was added in some iOS. But it's with the that's exactly what the fingerprint sensor, they very wisely. And I think this is, you know, not to criticize other smartphone makers, but whatever. I think Apple, from the very start said, we're not going to store any biometric information in a way that is retrievable in any fashion. So it's all one way into secure enclave. And then
[01:12:11.540 --> 01:12:38.860]  over time, they've expanded that to include like, Apple Pay and Face ID and a bunch of other stuff. It's in and third party apps can throw stuff into secure enclave as well have the same advantage. I don't know the inside story of the timing of that. And I you know, I would love to know it if anybody out there does know it. But if it's true, that Apple, Apple, in theory might have had a touch ID fingerprint sensor
[01:12:38.860 --> 01:13:03.140]  ready to go a year, two years before the five s. But there, they were never going to use it until they also had the secure enclave. So in theory, I don't know which took longer to develop. Maybe they had this, I think it's quite possible that they might have had the fingerprint sensor ready to go before the secure enclave. Because I think if the secure enclave was ready to go a year or two years earlier, they might have included a secure enclave.
[01:13:03.140 --> 01:13:33.120]  Because I think if the secure enclave was ready to go a year or two years earlier, they might have included it even before they had biometric authentication, because it still would have been useful. Right? It still would have helped increase it. I suspect that the fingerprint sensor and touch ID that was introduced with the five s was waiting for the secure enclave. It's also true that the five s was the first to go 64 bit on the on the a series chip. And maybe that plays into it, too. I don't know. But there were a couple of things
[01:13:33.120 --> 01:13:51.000]  that all had to come together for that to work. But I do know I do I do know for a fact talking to people at Apple off the record, that there was no way they were ever going to do the fingerprint sensor before they had the the secure enclave, because there's just no way that they would store any biometric information without it.
[01:13:51.000 --> 01:14:20.960]  Right. I think that's exactly right is I would not be surprised the fingerprint sensor was among the more advanced ones at the time. It was more accurate use the you know, the capacitance and so forth. But I don't think anything they did was totally like, so, you know, what's the right word? Such a breakthrough that it wasn't, you know, that they're waiting. I'm sure they perfected they had more time. But the secure enclave that marked a huge change. I mean, I was writing something for about the Yubikey and the first
[01:14:20.960 --> 01:14:50.920]  Fast Company. Yubikey finally was able to release a lightning version of its authentic external authenticating device, because Apple didn't support that until actually pretty recently in Safari for Mac OS. And then they added it to iOS, but it seemed like it was coming to iOS. So they so these guys did it. But so the the Yubikey is part of the it's essentially an external secure enclave at some level, it gives you some of the same protections that you get from a device based secure chip.
[01:14:51.080 --> 01:15:20.840]  In a token, even though the token, you know, conceivably can be moved around. And anyway, the thing is, I think, as I was researching this, I realized there had been this huge sea change is before secure enclave, the you know, encryption was the top bar, and verification and there might have been some hardware steps, but they were, you know, work aroundable. And then secure enclave set the bar that everyone you know, Microsoft now encourages in many, you can buy PCs, a large
[01:15:20.840 --> 01:15:49.960]  number of PCs that have the equivalent of a secure enclave in it, Google had to shift to it ultimately, so they certify devices with it, you know, and this, the web authentication standard that got promoted, the whole Fido two standard is kind of built around having a one way chip that can only produce sort of outputs based on inputs after it's been, you know, set up. So anyway, it's it was a big and important change. And no one should want us to go backwards from that, because it perfects, you know, protects people at every level protects, you know,
[01:15:49.960 --> 01:15:57.480]  vast amounts of personal and commercial information and those people in government who, who rely on it for security as well as part of a security system.
[01:15:57.480 --> 01:16:27.320]  I do believe it is true that the call it firmware firmware seems like an outdated term to me, you know, but let's call it the firmware that runs the secure enclave, I believe that Apple in a software update to iOS can update the firmware on the secure enclave. So there's aspects of the secure enclave that could that could get a bug fix, if necessary, but the 80 sec 80 millisecond and and I always forget
[01:16:27.320 --> 01:16:54.360]  this a millisecond is 1000th of a second. So 80 milliseconds is eight hundredths of a second. So 12 per second, give or take, right? 12 times eight is nine. What is 12 times 886 96 I had to do my I had to do my trick. My trick for 12 times eight is eight times 10 plus eight times two. So that's 96.
[01:16:54.360 --> 01:17:21.560]  So, you know, roughly 12 per second, which doesn't, you know, sounds pretty fast. But that that 80 millisecond computation time for taking iOS saying to the secure enclave, here's a password guess 1234. Secure enclave takes it does the computation that computation runs in hardware, and that 80 mil.
[01:17:21.560 --> 01:17:51.080]  So there's no way that somebody could force a firmware update to the secure enclave to say, Hey, how about you reduce the time to zero? You know, how about you do it as fast as you can? That can't be done. That's actually implemented in hardware. And so 12 per second is the most guesses you can. And so basically, the way these products that we know about work celebrate the gray, I keep forgetting, which is the gray key is the product from gray shift the company.
[01:17:51.760 --> 01:18:02.840]  They jailbreak iOS to get in, so that they can talk to the secure enclave, because there's no way to talk to the secure enclave from outside the iPhone.
[01:18:02.840 --> 01:18:31.840]  And then once they're in, they install, they run software, and the software talks to the secure enclave, and starts running guesses as fast as it can. And then once they find it, then they like there was a story I linked to it a couple days ago on during fireball, where somebody leaked to a security researcher two years ago, how the gray key device works, and they, and they
[01:18:31.840 --> 01:18:49.600]  even had photographs, they even had some pictures of the software running. And it runs. And then it when it finds the right passcode, it displays it on screen. And then you can unplug it from the device. And then I guess restart, start the iPhone and then enter the passcode that the device tells you what to do.
[01:18:49.600 --> 01:19:14.160]  But even that software can only do 12 guesses per second. And like you mentioned, I think, before we started recording that, that doesn't mean that they start 0001000 or you know, if they know it's six, because I guess you know how long the passcode is just by iOS gives up how long it is. Right? Let me double if I turn on my phone.
[01:19:14.160 --> 01:19:42.640]  If you do a pass if you have a four or six digit passcode, I think it disclose that right. Yeah. Because you tell shows you how many circles I because I can alphanumeric passcode, though, if you choose that option, even if you have a short passcode, then it's impossible to know how long it is anymore, which is what I did at some point when a security person like Rich Mogul or someone else said, yeah, six digits is probably not adequate. I was like, Oh, okay, making the change now. Yeah, that's right. So this is more true for a long time.
[01:19:42.640 --> 01:20:12.400]  This is more true for a more useful for breaking into databases that are hijacked online, because, and this is changing as well. But a lot of databases, the ones that were encrypted, we're using a very weak algorithm that was very easy to brute force through SHA-1. And that's been updated to later versions, a lot of databases. And then they've added another technique and a lot of online, you know, good online sites, so that no cracking a password once doesn't help you crack the same password and use by
[01:20:12.840 --> 01:20:41.120]  everyone on the same database. They're all seeded in a slightly different way. Salted is the word. But anyway, so those people, the people who are trying to crack exfiltrated databases, they have these huge, you know, not rainbow tables, we used to call them is right, those still exist that were just, you know, essentially pre cracked versions or pre sorry, pre computed versions of passwords going through certain algorithms like SHA-1.
[01:20:41.120 --> 01:21:10.640]  But what they have now is there are well known passwords, there's passwords that have been extracted, there's like a, I can't remember if you could, I think that's more likely because I think that the SHA-1 computed versions of passwords are probably not that useful, and certainly not useful anymore, right? Because everybody's going to hash them some way. And so they're not going, it's going to be the hash of the password, the hash, and then SHA-1 computed. And if you don't know that hash, there's
[01:21:10.640 --> 01:21:12.960]  there's knowing that list isn't going to help.
[01:21:13.160 --> 01:21:40.560]  Right, but so these, but I think this is still used in the same way is that because of the computational overhead now being higher, people trying to crack those databases, they have like, you know, they know, so it's, have you been pwned, which I recommend everyone to sign up at, they have a list of what is it a billion? I don't know, it's hundreds of millions of passwords that have been leaked in the clear online. They don't associate them with accounts. But researchers and others can see can get access essentially, to a huge
[01:21:40.560 --> 01:22:03.040]  set of passwords people have used. So one of the first passwords that are checked are the shortest ones from that list that are most commonly appeared. And then there's, there's dictionary words, there's all these other things. So when you're brute forcing, you don't start with 0000, 001, whatever, use common letters and numbers. And then at some point, you go into the brute force thing after everything common turns out not to work.
[01:22:03.040 --> 01:22:32.800]  Right. And I'm sure there's a similar, similar list of six digit passcodes, just numeric by frequent frequency. And so instead of starting at zeros, all zeros, you start at some combination. And I forget what I was using recently. It wasn't that recent that I remember, but something where I had to enter, create a numeric passcode. Oh, I entered one. And it said that one is commonly used. And I didn't
[01:22:32.800 --> 01:23:02.400]  enter 1234. And it was something that I didn't really care much about, which is why I don't even know what it was that I guessed. But let's say I just went to the four corners. All right. So I did four corners in order or something like that. And it said that one is frequently used to get, you know, try something else. But anyway, Jack Nikas, I'll put this link in the show notes, I just linked to it on during fireball to had a good story, basically describing what we're trying to
[01:23:02.400 --> 01:23:21.840]  describe here, which is basically how does this actually work? And and in the context of this law enforcement campaign, does the FBI really need Apple's help? Here's some numbers he got from talking to security researchers, and he listed them in his Twitter thread, who helped him out to get this story together.
[01:23:21.840 --> 01:23:50.640]  Average time it would take to guess different passcodes, depending on length, four numbers, seven minutes, six numbers, 11 hours, eight numbers, which I don't think is an option on iPhone 46 days, you could do you could do it, but you wouldn't know you have to do alphanumeric. Right? Yeah, right. 10 numbers would be 12.5 years. Now, if you use alphanumeric pass phrases, a four character alphanumeric passphrase,
[01:23:50.640 --> 01:24:03.280]  if you use letters and numbers, seven days, six characters, 72 years, eight characters, 276,000 years,
[01:24:03.280 --> 01:24:32.960]  yeah, mine is like 20 characters. Yes, probably unnecessary. If these numbers are right, that's unnecessary. Here's the thing, the entropy that he's talking about there the the is if you're choosing actual random alphanumeric. So if you pick the entire set of eight characters, and it's you know, capital Z, lowercase b, eight, exclamation point. Mine isn't that I use the the method that a lot of researchers promote and that you can do in one password. Now, it's the dice where method, I have three words that have never appeared together in any work of literature.
[01:24:34.240 --> 01:25:03.000]  And so they're long enough. So each of them is, is a not a common word. And each of them is easy for me to remember, because I remember three things instead of, you know, eight, right, eight round things, right? So I can type it in. And so it's critical for me for a passphrase that I can remember it pneumonically, because I'm never going to have I don't have it stored anywhere, because it's my passphrase. So I have to be able to remember it. I mean, I got stored in some, some careful ways. But anyway, so mine is not because it's the amount of entropy isn't high enough.
[01:25:03.000 --> 01:25:10.760]  Mine is probably crackable. And oh, I don't know, 100,000 years. Yeah, because it's because it's got real words in it, but still good enough, maybe a million years. Good enough.
[01:25:10.760 --> 01:25:40.520]  Well, and it's a balance between, you know, convenience and security. I mean, and it's how much how much do you really care if somebody who had one of these devices could get your phone? I mean, for an awful lot of people, they don't like my mic, my mom uses just a six digit passcode. She probably use four, really, it honestly, I don't know.
[01:25:40.760 --> 01:25:51.960]  Honestly, if somebody got her phone, honestly, she, the only thing she'd be upset about is that she needs a new phone. I mean, there's literally nothing, you know, somebody could read all of her email, and she just doesn't care much. I mean,
[01:25:52.440 --> 01:26:06.560]  yeah, then the other extreme is like, remember, was it two plus years ago that the that United Arab Emirates, human rights activist that somebody burned three separate zero days again? Yeah, yeah.
[01:26:06.560 --> 01:26:35.120]  And you're like, Oh, my God, the amount of resources a government entity has to throw. So that's one extreme is three zero days, all at once, versus I don't have my recipe, my favorite recipe for ricotta pudding anymore. You know, like we do have there's a range of security, but like, so say your mom could use four, but like six is great, because six deters anyone casual. There's no system out there that is below. There's no casual forensic or personal cracking system
[01:26:35.120 --> 01:26:48.360]  that would allow somebody to get your mom's phone, she would have to piss someone off at a at a federal, national security level, probably or mass murder level. So that's unless she's planning to do that, which I hope she's not. She's good.
[01:26:48.360 --> 01:27:08.880]  All right. But anyway, long story short, if you're listening, and you're paranoid about this, which is reasonable, and just if it bothers you, if it if you just wake up in the middle, you know, three in the morning, and it just bothers you thinking about this idea, that there are devices out there that they can plug your iPhone into and hit a button and 12 hours later, reveal your passcode.
[01:27:08.880 --> 01:27:37.880]  If it just makes you uneasy, switching to the alphanumeric passphrase, and even making it you know, like two words to two words separated by a space or a dash or an underscore or something will literally make your data impregnable at the iPhone level, I mean, unless they, you know, they'd have to hit like a greater than the number of words that you would get if you didn't get it.
[01:27:38.880 --> 01:28:08.880]  Yeah, I mean, quantum computing might put the lie to all this. Well, no, but not with an iOS device, because it wouldn't totally No, right. You're totally right. You need. So you know, there have been experiments in the past at extracting the secure enclave and try to do things like use electron microscopy, right? Other kinds of things. But but I think even that level, I think Apple is obviously they've got an amazing chip, right? They're right, constantly improving the secure enclave. And it is, it is resistive, and it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is
[01:28:08.880 --> 01:28:38.880]  it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, it is, and when somebody develops an attack there, or the theoretical one talking to a lot of people on Twitter recently and and emailing some readers as I write about this. And I wasn't as certain. I think I used to know this better. I'm probably gonna forget it again. If hopefully this whole thing dies down again. The thing you have to remember is that cracking iOS doesn't crack your data at all A, you have to get the secure enclave and to to everybody's public knowledge every public security
[01:28:38.880 --> 01:28:45.040]  experts knowledge the secure enclave on the iPhone has not been cracked and on
[01:28:45.040 --> 01:28:51.160]  recent ones that 80 millisecond computation time for a guess you could
[01:28:51.160 --> 01:28:59.080]  you know your iPhone today could could be found 40 years from now when we have
[01:28:59.080 --> 01:29:05.880]  quantum computers that are as much faster today's than today's computers
[01:29:05.880 --> 01:29:12.920]  were from 40 years ago with the Apollo program and it still wouldn't help them
[01:29:12.920 --> 01:29:17.480]  crack the secure enclave if they still have to go through the secure enclave
[01:29:17.480 --> 01:29:21.120]  because that 80 millisecond per guess thing is still there now there might be
[01:29:21.120 --> 01:29:26.200]  you know who knows there you know does the NSA have a crack for the secure
[01:29:26.200 --> 01:29:32.000]  enclave does does a foreign government have it we don't know but to everybody's
[01:29:32.000 --> 01:29:37.680]  to everybody's knowledge publicly that hasn't happened I think if they have it
[01:29:37.680 --> 01:29:42.880]  if anyone has it it's a nuclear bomb right because they cannot they can't
[01:29:42.880 --> 01:29:48.480]  deploy it because if they deployed it and it was ever discovered and it
[01:29:48.480 --> 01:29:53.600]  renders it you know right it's it's the end and then Apple will fix I mean this
[01:29:53.600 --> 01:29:56.080]  is there's always an arms race about this kind of thing but that was why the
[01:29:56.080 --> 01:30:01.120]  three zero day thing I remember so distinctly is because once you burn
[01:30:01.120 --> 01:30:04.000]  these things are gone forever and the system gets better and it's not like
[01:30:04.000 --> 01:30:07.160]  there's always gonna be flaws and things but it's not like they're always going
[01:30:07.160 --> 01:30:12.240]  to be the same category of flaw there's not always gonna be ones that that allow
[01:30:12.240 --> 01:30:17.640]  I mean at some point iOS could be effectively impenetrable I mean I know
[01:30:17.640 --> 01:30:21.320]  that's like saying the Titanic is unsinkable but but to all intents and
[01:30:21.320 --> 01:30:25.560]  purposes they have figured out enough ways to close down enough avenues that
[01:30:25.560 --> 01:30:30.760]  even the most determined government-funded whatever cannot find you
[01:30:30.760 --> 01:30:33.800]  know a really effective way and they only find little things around the edge
[01:30:33.800 --> 01:30:39.000]  and that's not infeasible and you know it the secure enclave is very very
[01:30:39.000 --> 01:30:44.720]  different and and if you understand it even at the layman's layperson's version
[01:30:44.720 --> 01:30:50.360]  the level that I do it's easy to see how much more defensible it is from Apple's
[01:30:50.360 --> 01:30:57.520]  perspective than iOS because iOS has lightning input which also takes USB
[01:30:57.520 --> 01:31:01.920]  which is obviously some part of the jail breaks that the gray key installed
[01:31:01.920 --> 01:31:05.120]  because what we know about great keys you plug it in via a lightning cable and
[01:31:05.120 --> 01:31:11.680]  it has obviously has networking so there could be bugs in the networking stack
[01:31:11.680 --> 01:31:16.240]  there was there was an exploit recently somebody wrote about where there was an
[01:31:16.240 --> 01:31:23.280]  iMessage exploit where a carefully crafted URL if tapped in iMessage would
[01:31:23.280 --> 01:31:28.560]  exploit it you know there's all sorts of vectors like that because iOS from a
[01:31:28.560 --> 01:31:32.600]  functional level has to take input from so many ways whereas the secure enclave
[01:31:32.600 --> 01:31:37.680]  literally is physically connected to the hardware one way you know there's
[01:31:37.680 --> 01:31:41.860]  there's literally one way in and so there's and there's no other you know
[01:31:41.860 --> 01:31:48.240]  it's like the you know it's like defending a building with doors and
[01:31:48.240 --> 01:31:56.680]  windows and roof access and antennas versus like the underground bunker in
[01:31:56.680 --> 01:32:03.720]  you know the Rocky Mountains where there's one door and and a giant Rocky
[01:32:03.720 --> 01:32:09.360]  Mountain above it and a you know 20-story elevator going under down
[01:32:09.360 --> 01:32:13.000]  underground to get to the you know the secret bunker where the president will
[01:32:13.000 --> 01:32:18.080]  live you know in a nuclear war all right let me take a break here and thank our
[01:32:18.080 --> 01:32:24.600]  next sponsors are good friends at hover hey hover is a jumping-off point for a
[01:32:24.600 --> 01:32:28.040]  ton of entrepreneurs and they want you to start your business with a new domain
[01:32:28.040 --> 01:32:32.800]  name they have over 300 domain name extensions the top-level domains you
[01:32:32.800 --> 01:32:37.680]  know everybody knows calm dotnet org they've got over 300 of those to choose
[01:32:37.680 --> 01:32:41.320]  from when you want to build your brand online no matter what you want to build
[01:32:41.320 --> 01:32:44.680]  there's a domain name waiting for it you'll find excellent excellent tech
[01:32:44.680 --> 01:32:48.280]  support available to answer any questions you may have their support
[01:32:48.280 --> 01:32:52.920]  team doesn't upsell you they only work hard to help you get online they have
[01:32:52.920 --> 01:32:57.480]  free who it free who is privacy protection man the the the domain name
[01:32:57.480 --> 01:33:02.100]  companies that charge you for privacy protection what a racket they have a
[01:33:02.100 --> 01:33:07.400]  super clean well divine well-designed user experience and user interface and
[01:33:07.400 --> 01:33:15.360]  monthly sales on popular top-level domains it's hard to see why anybody
[01:33:15.360 --> 01:33:19.440]  would go somewhere else it's such a popular choice for getting a new domain
[01:33:19.440 --> 01:33:25.560]  name one of my favorite features is the guessing so if you enter your intended
[01:33:25.560 --> 01:33:29.960]  domain name dot whatever and dot whatever isn't available they give you a
[01:33:29.960 --> 01:33:34.600]  tremendous number of options to get something similar they offer like I said
[01:33:34.600 --> 01:33:38.640]  before they offer best in class customer technical support answer any questions
[01:33:38.640 --> 01:33:42.920]  you want super good security like Glenn and I were just talking about all these
[01:33:42.920 --> 01:33:45.840]  security things one of the things you certainly don't want to have hijacked is
[01:33:45.840 --> 01:33:52.320]  a domain name hover has you covered on that regard best in class locked in you
[01:33:52.320 --> 01:33:57.800]  can make changes when you want to but nobody else is going to be able to Jimmy
[01:33:57.800 --> 01:34:02.080]  their way into your account and steal your domain name and like I said over
[01:34:02.080 --> 01:34:08.720]  300 domain name extensions to choose from so grab your next domain name at
[01:34:08.720 --> 01:34:14.120]  hover.com slash talk show the other thing they offer let me just say this
[01:34:14.120 --> 01:34:19.440]  the other thing they offer is a tremendous user experience for
[01:34:19.440 --> 01:34:24.160]  transferring existing domain names from another registrar so if you have a
[01:34:24.160 --> 01:34:27.480]  registrar you already have even if you don't need a new domain name if you just
[01:34:27.480 --> 01:34:32.440]  want to move your existing domain names from some crummy registrar to the best
[01:34:32.440 --> 01:34:36.920]  which is hover they've got you covered on that regard to really really easy if
[01:34:36.920 --> 01:34:40.920]  you're putting it off because you think it's just a huge pain in the butt don't
[01:34:40.920 --> 01:34:45.360]  worry about it really they've got you covered so go to hover.com slash talk
[01:34:45.360 --> 01:34:51.320]  show get a 10% discount with their referral link and that's good for all
[01:34:51.320 --> 01:35:03.720]  new purchases make a name for yourself with hover next on my list was well what
[01:35:03.720 --> 01:35:06.640]  do you want to talk about next let me ask you what would you like to talk
[01:35:06.640 --> 01:35:10.560]  about fake faces I love this time yeah let's do this let's do this is there
[01:35:10.560 --> 01:35:15.120]  going on for a bit so I wrote about this last year and I certainly wasn't the
[01:35:15.120 --> 01:35:19.960]  first by any means but I I got kind of excited about the topic because it's a
[01:35:19.960 --> 01:35:25.200]  little contrarian at one level and now it is blowing up and I have I'm kind of
[01:35:25.200 --> 01:35:28.800]  excited to see people covering it I think it's really important so so what
[01:35:28.800 --> 01:35:32.640]  it was is Nvidia has a research department of course and they're always
[01:35:32.640 --> 01:35:36.120]  working on interesting stuff they can do with their super fast GPUs because
[01:35:36.120 --> 01:35:40.480]  they're all these graphics companies are selling computational power now to
[01:35:40.480 --> 01:35:44.720]  security researchers and and other folks and graphics professionals of course
[01:35:44.720 --> 01:35:48.280]  strangely also graphics professionals and gamers and they came up with this
[01:35:48.280 --> 01:35:54.840]  thing if I'm remembering it's right it's called style GAN and GAN is generative
[01:35:54.840 --> 01:35:59.960]  generative adversarial networks that's what it's called okay so what it is is
[01:35:59.960 --> 01:36:06.360]  you pit machine learning algorithms against each other to get closer and
[01:36:06.360 --> 01:36:10.520]  closer to a desired outcome and what they figured a way to do was to use a
[01:36:10.520 --> 01:36:17.640]  what they call a style based GAN or generator to use adversarial networks to
[01:36:17.640 --> 01:36:23.920]  make fake faces so you feed in human correct human faces in profile and over
[01:36:23.920 --> 01:36:27.400]  time the algorithm evolved enough and improved enough that they released a
[01:36:27.400 --> 01:36:32.080]  version of it and they've improved it since that makes fake static profile
[01:36:32.080 --> 01:36:38.160]  shots that look often exceedingly real they look just like a real person and
[01:36:38.160 --> 01:36:43.280]  they can you can dial in characteristics so I like brown hair red hair different
[01:36:43.280 --> 01:36:46.880]  kind of smile or face so there's not a ton of control but there is some and
[01:36:46.880 --> 01:36:50.440]  every time you run the algorithm what about eight what about age I presume you
[01:36:50.440 --> 01:36:55.360]  can yes to some extent and you can it's I forget if age no I think that is a
[01:36:55.360 --> 01:37:00.520]  factor so age and gender hair color eye color glasses all these things and the
[01:37:00.520 --> 01:37:07.040]  first pass came out in I want to say in 2018 and it made a little bit of a stir
[01:37:07.040 --> 01:37:12.320]  because the video for it was just outrageous it kind of like blew people
[01:37:12.320 --> 01:37:17.400]  away they've done it for one of the big graphics conferences or something and
[01:37:17.400 --> 01:37:21.200]  you were like oh my and they showed in real time like in on real time but they
[01:37:21.200 --> 01:37:25.320]  showed the input faces and then all the output faces and they would zoom in and
[01:37:25.320 --> 01:37:31.040]  show more faces and it was just like oh my god so a lot of the focus in machine
[01:37:31.040 --> 01:37:36.760]  learning based generation of material has been around like deep fakes which
[01:37:36.760 --> 01:37:41.560]  are typically looking at video so you create a video with enough different
[01:37:41.560 --> 01:37:45.600]  pictures of somebody or video of somebody you can merge them with porn or
[01:37:45.600 --> 01:37:53.720]  you can make Obama Barack Obama say he loves Osama bin Laden or whatever and so
[01:37:53.720 --> 01:37:58.240]  that is very disturbing because the video can look very realistic and while
[01:37:58.240 --> 01:38:01.840]  it can be pretty funky and easy to tell for an informed person now it's gonna
[01:38:01.840 --> 01:38:05.160]  get better and better but I thought there wasn't enough attention being paid
[01:38:05.160 --> 01:38:10.880]  to the still face version because it looks so good already right so what
[01:38:10.880 --> 01:38:14.160]  happened is I wrote this piece last year and talked to these researchers at
[01:38:14.160 --> 01:38:17.960]  University of Washington that had built a page you can go to and they made a
[01:38:17.960 --> 01:38:21.480]  little test so they put a real photo next to a generated one and ask you
[01:38:21.480 --> 01:38:27.920]  which one is real and you know you'd be surprised you'd run 20 of them through
[01:38:27.920 --> 01:38:32.480]  or something or and you'd be like man I was wrong like 75% of the time right the
[01:38:32.480 --> 01:38:36.080]  fake ones look more real than these real ones so these algorithms continue to
[01:38:36.080 --> 01:38:40.400]  improve and there's a good article recently there's actually been a series
[01:38:40.400 --> 01:38:47.200]  this year already about two aspects of it one or I guess three right a company
[01:38:47.200 --> 01:38:51.320]  is now offering this as a commercial service so you go to them to get
[01:38:51.320 --> 01:38:57.760]  essentially model release free royalty free images you can use as stock
[01:38:57.760 --> 01:39:01.400]  photography right so there's no real person so you don't have to get a
[01:39:01.400 --> 01:39:05.440]  release you can use the picture any way you want the second is businesses that
[01:39:05.440 --> 01:39:10.800]  are then creating these for or sorry businesses that are using fake images
[01:39:10.800 --> 01:39:15.440]  now from that company and others to populate sites so they look like they
[01:39:15.440 --> 01:39:19.840]  are full of real people and the third is there's a story just recently about
[01:39:19.840 --> 01:39:24.200]  Facebook having two is looking now that was actually an issue it used to be that
[01:39:24.200 --> 01:39:29.320]  you can reverse image search right this ties in another story you're interested
[01:39:29.320 --> 01:39:33.400]  in too but you can reverse image search and find well that fake avatar on
[01:39:33.400 --> 01:39:36.440]  Twitter oh that's been used all over the place it's a thousand sites well these
[01:39:36.440 --> 01:39:39.920]  they can't reverse image search them because they're uniquely generated so
[01:39:39.920 --> 01:39:43.200]  Facebook had to remove a bunch of profiles with fake pics so I'm sort of
[01:39:43.200 --> 01:39:47.400]  fascinated by this because it is so good already that we are already in the
[01:39:47.400 --> 01:39:54.640]  crisis of reality about fake still pictures of people's faces yeah and the
[01:39:54.640 --> 01:40:04.480]  one you know like using them for royalty free stock photography it I don't know
[01:40:04.480 --> 01:40:09.480]  who would be bothered by that other than someone who already owns you know a
[01:40:09.480 --> 01:40:15.360]  legit photography thing and that's their business I mean in terms of morality
[01:40:15.360 --> 01:40:20.920]  that to me strikes me as you know fine like that's using technology to solve a
[01:40:20.920 --> 01:40:25.160]  problem and if you want to create an advertisement that makes it look like
[01:40:25.160 --> 01:40:34.360]  there is a 35 year old woman who's very happy with her banking account you know
[01:40:34.360 --> 01:40:41.440]  for your ad to say sign up for our banks you know low-interest checking whatever
[01:40:41.440 --> 01:40:50.040]  fine right but using it to create the illusion of people who don't even don't
[01:40:50.040 --> 01:40:57.080]  really exist is really bothersome and it really plays into the the the the
[01:40:57.080 --> 01:41:03.560]  flooding flooding the zone to for lack of a better term of misinformation in
[01:41:03.560 --> 01:41:12.040]  the social network age you know to create thousands tens of thousands I
[01:41:12.040 --> 01:41:15.160]  mean what's the limit right once you're talking about a computer you know it's
[01:41:15.160 --> 01:41:19.040]  just like spam right like imagine if you got as much physical mail as you get
[01:41:19.040 --> 01:41:24.680]  spam I want to talk about spam later but let me just let me literally just take a
[01:41:24.680 --> 01:41:28.640]  look here at my junk mailbox my junk mailbox which I go through and empty
[01:41:28.640 --> 01:41:34.280]  right now for my email accounts and I have mail set to throw out the old ones
[01:41:34.280 --> 01:41:42.860]  on a periodic basis I've got 4,000 pieces of spam I mean just one address
[01:41:42.860 --> 01:41:50.200]  alone let me see here from my main address I have 11,000 pieces of spam and
[01:41:50.200 --> 01:41:57.380]  it only goes back to December 21 so yeah because I have mail configured to throw
[01:41:57.380 --> 01:42:02.720]  out all month old spam so in the last month I've gotten eleven hundred and
[01:42:02.720 --> 01:42:07.760]  fifty pieces of spam to one address imagine if you got that much junk mail
[01:42:07.760 --> 01:42:11.080]  you know it'd be crazy I mean I feel like we get so much junk mail and
[01:42:11.080 --> 01:42:16.760]  marketing mail as it is but that's you know six seven pieces a day you know it
[01:42:16.760 --> 01:42:21.320]  because there's an actual cost to actual postage you know what once you're
[01:42:21.320 --> 01:42:26.160]  talking digital there's just no price I mean there there have been astroturf
[01:42:26.160 --> 01:42:32.480]  campaigns it's you know for a long time where you try to create the illusion of
[01:42:32.480 --> 01:42:38.360]  more people supporting some political issue or something then actually exist
[01:42:38.360 --> 01:42:48.200]  but in the digital age it is just it it's just another ballpark you can
[01:42:48.200 --> 01:42:52.960]  create thousands and and the way that like algorithms work and you know that
[01:42:52.960 --> 01:42:56.000]  to promote you know you all of a sudden you get stuff in your newsfeed on
[01:42:56.000 --> 01:43:01.120]  Facebook and Twitter you know does a lot of this now too I don't really see stuff
[01:43:01.120 --> 01:43:05.320]  that seems fake in my Twitter and I don't use Facebook but it's obviously a
[01:43:05.320 --> 01:43:09.600]  problem for a lot of people in terms of pushing a lot of this political
[01:43:09.600 --> 01:43:17.560]  propaganda having an army of fake Facebook accounts is is it's not like a
[01:43:17.560 --> 01:43:20.800]  resource problem for Facebook Facebook isn't trying to get rid of these
[01:43:20.800 --> 01:43:25.200]  accounts because it's using up computing power and you know running up their
[01:43:25.200 --> 01:43:30.200]  electricity bill and their storage bill it's it's ruining the integrity of their
[01:43:30.200 --> 01:43:38.960]  service and I mean as and as down on Facebook and as I am I I do you know I
[01:43:38.960 --> 01:43:45.080]  and I think there's a lot of ethical problems at that company I don't I really
[01:43:45.080 --> 01:43:54.360]  think that they want their algorithms to be as they intend them to be they don't
[01:43:54.360 --> 01:43:58.700]  it's not like they you know they have an interest in not having them be overrun
[01:43:58.700 --> 01:44:06.680]  by fake fake accounts right and having a profile picture that is unique is you
[01:44:06.680 --> 01:44:10.840]  know something that can be done and you know and I've seen it I I've seen it
[01:44:10.840 --> 01:44:16.040]  when when fake accounts have been exposed over the years I don't I can't
[01:44:16.040 --> 01:44:19.000]  think of an example off the top of my head that I could put in the show notes
[01:44:19.000 --> 01:44:21.960]  but maybe I can find one but I've seen it where people have exposed it and
[01:44:21.960 --> 01:44:27.280]  found that the profile picture is from like a stock photography service you
[01:44:27.280 --> 01:44:30.520]  know yeah this this is what led me to this article is I was interested in the
[01:44:30.520 --> 01:44:33.600]  topic but I thought I'd been well covered and then some folks in the
[01:44:33.600 --> 01:44:37.840]  Bitcoin world said they were being contacted by somebody who said she was a
[01:44:37.840 --> 01:44:41.960]  journalist and they looked at the profile photo they were there were very
[01:44:41.960 --> 01:44:47.360]  little traces of who she was they could not and she was contacting people
[01:44:47.360 --> 01:44:50.360]  privately and everyone was getting a little nervous was she pulling a scam
[01:44:50.360 --> 01:44:54.600]  was she working for some you know exchange or whatever and they discovered
[01:44:54.600 --> 01:44:57.720]  someone's like you know this is a fake photo because look at these and they
[01:44:57.720 --> 01:45:00.960]  enlarged it like look at these characteristics this was generated by
[01:45:00.960 --> 01:45:06.120]  the StyleGAN software and it almost certainly was because there's some if in
[01:45:06.120 --> 01:45:10.600]  the older the first version there was some artifacting there's some techniques
[01:45:10.600 --> 01:45:15.360]  you could tell but you couldn't reverse image reverse image search it because
[01:45:15.360 --> 01:45:19.600]  that's such an easy way to tell initially and if it doesn't work you're
[01:45:19.600 --> 01:45:23.200]  like well this is probably a legitimate photo that someone posted like no now
[01:45:23.200 --> 01:45:27.760]  you can't do that what the scientists at the academics University of Washington
[01:45:27.760 --> 01:45:32.240]  told me they said there's two actually really easy tells and this I thought
[01:45:32.240 --> 01:45:36.280]  this is brilliant and it will change over time the fake generated faces you
[01:45:36.280 --> 01:45:40.800]  will never the current states of the algorithms and this may continue
[01:45:40.800 --> 01:45:45.040]  indefinitely because of how the faces are generated they can only produce that
[01:45:45.040 --> 01:45:49.200]  face once so you can use the same inputs and produce exactly the same face a
[01:45:49.200 --> 01:45:54.120]  second time but you can't produce other versions of that face in different
[01:45:54.120 --> 01:45:58.520]  scenarios so you write yes if you want to say send me your left profile because
[01:45:58.520 --> 01:46:02.800]  I'm seeing your right profile they can't they can't they're typically not yet in
[01:46:02.800 --> 01:46:07.520]  scenes so you're not standing with the background in some kind of environment
[01:46:07.520 --> 01:46:10.560]  you can't hold up to me you could hold today's paper but you know that kind of
[01:46:10.560 --> 01:46:14.840]  thing actually what was hilarious about this research too is they've shown
[01:46:14.840 --> 01:46:20.000]  examples of taking like shots from IKEA of rooms full of furniture and they can
[01:46:20.000 --> 01:46:26.040]  train them it just produces random rooms full of very realistic looking sets of
[01:46:26.040 --> 01:46:30.600]  furniture don't exist and it is you can run these algorithms online and you're
[01:46:30.600 --> 01:46:34.040]  just looking through it and it is there's something so weird about seeing
[01:46:34.040 --> 01:46:38.560]  the real world like faces are bad but the real world being like your objects
[01:46:38.560 --> 01:46:44.080]  of material possessions being generated algorithmically from other photos is is
[01:46:44.080 --> 01:46:53.720]  like beyond surreal it's you know and and it's you know it's it's one of my
[01:46:53.720 --> 01:46:57.600]  big fears as we go forward and one of the things that I feel like we're
[01:46:57.600 --> 01:47:04.240]  already inundated with misinformation and I one of the things that makes me so
[01:47:04.240 --> 01:47:10.040]  pessimistic honestly about democracy you know going forward and I don't mean to
[01:47:10.040 --> 01:47:16.680]  be overdramatic but what it's a big frustration for my wife in particular
[01:47:16.680 --> 01:47:26.080]  that that when video of some scandalous thing comes out that it has it resonates
[01:47:26.080 --> 01:47:36.000]  so much more than just somebody's you know what what should what ought to be
[01:47:36.000 --> 01:47:42.880]  taken equally as proof of it and one example that comes to mind would be the
[01:47:42.880 --> 01:47:48.960]  the access Hollywood Trump tape that dropped a month before the election four
[01:47:48.960 --> 01:47:54.680]  years ago you know this is the famous tape where Trump is saying that you know
[01:47:54.680 --> 01:48:00.880]  when you're famous you can do whatever you want you can grab them by the pussy
[01:48:00.880 --> 01:48:08.000]  and that tape came out and you know again and some people will say well who
[01:48:08.000 --> 01:48:13.880]  cares he won anyway but it hurt him it hurt him severely at the you know in you
[01:48:13.880 --> 01:48:18.840]  know polling you know if that tape had never come out he would have won by more
[01:48:18.840 --> 01:48:23.320]  most likely maybe you know maybe half a percent who knows but these elections
[01:48:23.320 --> 01:48:27.120]  have been so close that a half a percent in a few states makes a huge difference
[01:48:27.120 --> 01:48:33.000]  right but the tape matters and my wife was so angry not not after the election
[01:48:33.000 --> 01:48:40.000]  but after that tape dropped when this became this huge huge news cycle
[01:48:40.000 --> 01:48:44.960]  consuming scandal that's you know and had people saying they oh my god this is
[01:48:44.960 --> 01:48:49.040]  so bad he needs to drop out of the race and my wife's response her anger was
[01:48:49.040 --> 01:48:53.800]  there was absolutely nothing on that tape that we did not know or a fact
[01:48:53.800 --> 01:48:58.720]  about Donald Trump and the way he behaves around women and the way he
[01:48:58.720 --> 01:49:02.240]  thinks about them and and you know there were dozens and dozens of stories of
[01:49:02.240 --> 01:49:08.480]  exactly the same sort of thing from over the years did from decades ago and so it
[01:49:08.480 --> 01:49:12.480]  anger and I my take is you just don't understand the psychological effect that
[01:49:12.480 --> 01:49:18.520]  like a videotape has you know and and there are so many stories you know it's
[01:49:18.520 --> 01:49:23.400]  a huge trend of the last decade for the better you know it's for lack of a
[01:49:23.400 --> 01:49:28.200]  better catch-all phrase the whole me to movement but just the whole holding
[01:49:28.200 --> 01:49:37.960]  accountable men mostly but anybody behaving either inappropriately or even
[01:49:37.960 --> 01:49:45.920]  worse illegally mm-hmm but it's when tapes come out and I say tape you know
[01:49:45.920 --> 01:49:50.600]  videos but you know some celebrity who comes out and there's something caught
[01:49:50.600 --> 01:49:59.840]  on tape it is so much worse there was oh man what's his name Ray Lewis was a
[01:49:59.840 --> 01:50:04.920]  football player or no ray rice it's oh oh wait Ray Lewis was the murderer right
[01:50:04.920 --> 01:50:10.720]  great Lewis is the murderer all right well we can leave this in Caleb I just
[01:50:10.720 --> 01:50:16.280]  want to get at least I'm not maligning someone Ray Lewis was the murder is Ray
[01:50:16.280 --> 01:50:22.680]  rice was the running back for the Ravens and he you know it assaulted his wife
[01:50:22.680 --> 01:50:28.760]  badly and you know there were there were you know it was gonna be repercussions
[01:50:28.760 --> 01:50:33.400]  and but then all of a sudden somebody who happened at a hotel somebody in an
[01:50:33.400 --> 01:50:38.160]  elevator and somebody who worked at the hotel that the elevator had a security
[01:50:38.160 --> 01:50:42.840]  camera you know no surprise and they leaked the tape and the tape showed him
[01:50:42.840 --> 01:50:50.040]  more or less cold cocking his wife or his fiance I guess I was absolutely
[01:50:50.040 --> 01:50:54.200]  horrific I don't I honestly if you don't if you don't have the stomach for it I
[01:50:54.200 --> 01:50:58.480]  don't don't even look it up it is truly a horrific video I mean it's it's it's
[01:50:58.480 --> 01:51:04.640]  it's a professional football player in the prime of his athleticism just
[01:51:04.640 --> 01:51:08.320]  hitting a woman as hard as he can and just I mean she just falls like a sack
[01:51:08.320 --> 01:51:12.720]  of potatoes but it was only when the video came out that he really suffered
[01:51:12.720 --> 01:51:16.800]  the consequences he should have whereas it was should have been evident to
[01:51:16.800 --> 01:51:22.720]  anybody paying attention that he was guilty there was no need for a video
[01:51:22.720 --> 01:51:26.160]  there shouldn't have been a need for a videotape for him to be suspended
[01:51:26.160 --> 01:51:29.640]  forever but we're seeing this exactly this is exactly what's going on the
[01:51:29.640 --> 01:51:36.200]  impeachment process right now is that there is a hundred thousand pieces of
[01:51:36.200 --> 01:51:40.480]  circumstantial evidence right now that absolutely paint the picture that Trump
[01:51:40.480 --> 01:51:45.800]  was directing you know that with the withholding of aid from Ukraine and so
[01:51:45.800 --> 01:51:48.640]  forth and actually at this point what I mean there's no there is no direct thing
[01:51:48.640 --> 01:51:54.680]  of Trump sending an email or a horribly sharpie written note or or audio or
[01:51:54.680 --> 01:51:58.880]  whatever of him saying we need to get the Bidens let's withhold aid we're
[01:51:58.880 --> 01:52:03.900]  gonna pressure Ukraine but it is absolutely painted but you know would it
[01:52:03.900 --> 01:52:09.400]  make a difference not to anybody who has a staked-out political opinion that
[01:52:09.400 --> 01:52:14.000]  Trump can do no wrong or that he's being railroaded by the deep state however the
[01:52:14.000 --> 01:52:18.000]  thing that's interesting the only difference here is that weirdly his
[01:52:18.000 --> 01:52:21.780]  party has mostly decided to say well okay that's what happened but it's not
[01:52:21.780 --> 01:52:25.360]  actually impeachable it's not illegal and that's strange usually you need
[01:52:25.360 --> 01:52:28.260]  video to get to that part but I think the amount of circumstantial evidence
[01:52:28.260 --> 01:52:34.360]  finally crossed what is usually a video or even audio tape threshold because I
[01:52:34.360 --> 01:52:38.200]  know I totally agree with you is people won't see something it comes to your
[01:52:38.200 --> 01:52:43.560]  eyes in a very different way than even still photos right so on the one hand
[01:52:43.560 --> 01:52:48.600]  you know when a tape does so it's not right and in an ethical or logical sense
[01:52:48.600 --> 01:52:53.240]  that that that the repercussions are worse when Ray Rice has tape cold
[01:52:53.240 --> 01:52:57.200]  cocking his wife when he actually should have been proven guilty otherwise but at
[01:52:57.200 --> 01:53:03.280]  least when the tape came out the right thing happened we in the world where
[01:53:03.280 --> 01:53:10.280]  these deep fake videos are easily produced and are indistinguishable from
[01:53:10.280 --> 01:53:16.200]  a legit video I worry that we lose that and then of course the flip side is it's
[01:53:16.200 --> 01:53:20.600]  easy to create a fake one right it's easy to create one where some political
[01:53:20.600 --> 01:53:26.080]  candidate is is there on tape looking looking like it's the security camera
[01:53:26.080 --> 01:53:30.080]  from an elevator and they think they're in private so that's you know it would
[01:53:30.080 --> 01:53:33.920]  explain why they're caught talking on tape and you say hey here's somebody
[01:53:33.920 --> 01:53:40.920]  from the you know the Hilton in you know somewhere and they released this tape to
[01:53:40.920 --> 01:53:45.360]  us and it shows a presidential candidate talking about taking bribes from China
[01:53:45.360 --> 01:53:49.320]  or something like that well and there's the tape and it's completely fake you
[01:53:49.320 --> 01:53:52.540]  know the Nancy Pelosi one right up and where it showed her as if she were you
[01:53:52.540 --> 01:53:56.080]  know it slowed it down right and made a strategic yeah it made it seem like she
[01:53:56.080 --> 01:53:59.480]  was drunk you know yeah and Facebook I think wouldn't take that down they
[01:53:59.480 --> 01:54:03.840]  refused to take it down ultimately because it wasn't altered in a way that
[01:54:03.840 --> 01:54:06.920]  they considered substantive although it was obvious right I thought they I
[01:54:06.920 --> 01:54:09.640]  thought they did take it down eventually they did eventually or something could
[01:54:09.640 --> 01:54:12.640]  you use it in your ass if right politically political ads where you
[01:54:12.640 --> 01:54:16.720]  could include it right and it wasn't well done it really you know what they're
[01:54:16.720 --> 01:54:21.560]  there you know you could it was funny as a gag if it had been presented as a gag
[01:54:21.560 --> 01:54:27.920]  in the in the same way like I'm sure you did it did the same thing like when we
[01:54:27.920 --> 01:54:32.440]  were kids you would take a tape recorder and record your voice and if it certain
[01:54:32.440 --> 01:54:36.920]  tape recorders would let you play it back slower slower or faster and then
[01:54:36.920 --> 01:54:39.800]  all of a sudden you sounded like a chipmunk or you sounded you know like
[01:54:39.800 --> 01:54:45.440]  you were talking like this and we would you know as a kid yeah I would play for
[01:54:45.440 --> 01:54:48.800]  hours with that it was it was the craziest thing in the world we I loved
[01:54:48.800 --> 01:54:53.640]  it but it wasn't it didn't really sound realistic the Nancy Pelosi thing was
[01:54:53.640 --> 01:54:57.880]  better than that but it anybody who you know got sucked into thinking it was
[01:54:57.880 --> 01:55:02.600]  real was seeing what they wanted to believe or was naive but enough people
[01:55:02.600 --> 01:55:07.040]  thought it was real and the people who made it didn't make it as a gag they
[01:55:07.040 --> 01:55:14.080]  made it as propaganda and it caught fire enough you know and it was really poorly
[01:55:14.080 --> 01:55:21.520]  done you know it's so easy to imagine a much better done version I remember I
[01:55:21.520 --> 01:55:27.520]  had this great conversation this is like 95 like this it's a long time ago I was
[01:55:27.520 --> 01:55:32.040]  at some conference and we had the oh I think it was a an early like web design
[01:55:32.040 --> 01:55:36.320]  conference that I was working on and we had the webmaster for Netscape that'll
[01:55:36.320 --> 01:55:40.240]  take you back who attended who was a super nice guy blanket on his name super
[01:55:40.240 --> 01:55:43.480]  nice guy great things to say and I was chatting with him at some point and he
[01:55:43.480 --> 01:55:46.960]  said you know we're so obsessed with video and we keep thinking about like
[01:55:46.960 --> 01:55:52.360]  when can we stream videos like 95 right so when can we stream video that's big
[01:55:52.360 --> 01:55:55.960]  enough that people will will accept it and like it and whatever and he said and
[01:55:55.960 --> 01:55:59.360]  then I was on this panel with somebody from penthouse and they said you know we
[01:55:59.360 --> 01:56:04.880]  can stream like 240 by 320 at five frames per second in grayscale our
[01:56:04.880 --> 01:56:09.700]  audience is delighted he said I had to really rethink like that and I was
[01:56:09.700 --> 01:56:13.200]  thinking of that with the Pelosi thing where it's like you know we could be
[01:56:13.200 --> 01:56:18.600]  we're an era of of real deep fakes and they could create you know incredible
[01:56:18.600 --> 01:56:22.400]  simulation they should Hillary Clinton shooting Vince Foster or something
[01:56:22.400 --> 01:56:26.200]  horrific right and and they'll probably do that whoever the leading Democratic
[01:56:26.200 --> 01:56:30.520]  candidate is and probably Republican Trump they'll probably be concocted
[01:56:30.520 --> 01:56:34.320]  videos because they're so easy to do as we get into the the general election but
[01:56:34.320 --> 01:56:37.680]  I was like wow at some level all you need is the fidelity of that like
[01:56:37.680 --> 01:56:41.840]  streaming porn you need the Nancy Pelosi where they just slowed it down and
[01:56:41.840 --> 01:56:46.080]  people like oh my god she must really be drunk like no no how do we get people to
[01:56:46.080 --> 01:56:49.400]  have more credibility but at the same time I think you're absolutely right the
[01:56:49.400 --> 01:56:56.840]  video conveys a kind of truth that bypasses normal you know cognitive
[01:56:56.840 --> 01:57:03.480]  process and I really really think I think I see it it is going to be a huge
[01:57:03.480 --> 01:57:07.960]  problem like I am certain of it I I just cannot I don't know what the
[01:57:07.960 --> 01:57:14.400]  repercussions are going to be I mean I I think the ultimate I think the old the
[01:57:14.400 --> 01:57:22.080]  best case scenario is that video and audio proof of X no longer holds the
[01:57:22.080 --> 01:57:28.400]  cachet it'll take years though for that to happen and that people people will
[01:57:28.400 --> 01:57:35.200]  start to treat with equal skepticism video of you know a political candidate
[01:57:35.200 --> 01:57:40.800]  drunkly groping somebody in an elevator the same way they would if somebody just
[01:57:40.800 --> 01:57:47.720]  said and was quoted as saying hey this this this person drunkly groped somebody
[01:57:47.720 --> 01:57:51.000]  in an elevator right then the video doesn't give it any more credibility
[01:57:51.000 --> 01:57:56.520]  than the quote and that you have to trust the source right it gets back to
[01:57:56.520 --> 01:58:01.480]  you know the older days where you've really got to build trusted sources and
[01:58:01.480 --> 01:58:06.680]  you know Joe random Twitter account or Jane random Facebook doesn't count and
[01:58:06.680 --> 01:58:11.360]  that we that's that's the optimistic view the pessimistic view is that
[01:58:11.360 --> 01:58:14.960]  everybody believes the worst of everything and nobody believes anything
[01:58:14.960 --> 01:58:23.280]  and nobody trusts anything how's that for a light-hearted take can I say we
[01:58:23.280 --> 01:58:26.920]  asked into the and what it feels like is you put this on the list of story
[01:58:26.920 --> 01:58:31.040]  topics I was like this is like exactly the perfect complement to this yeah
[01:58:31.040 --> 01:58:37.520]  yes talking about which is well the Facebook or the face ID the secretive
[01:58:37.520 --> 01:58:41.640]  company yeah that might end privacy as we know it which is a great headline and
[01:58:41.640 --> 01:58:46.560]  Kashmir Hill is an incredible reporter she's now worked across I can't think
[01:58:46.560 --> 01:58:51.720]  how many publication in the modern era so journalists as a side note just a
[01:58:51.720 --> 01:58:56.000]  parenthetical to tie in the last time friend of the show Dan Fromer was on the
[01:58:56.000 --> 01:59:04.240]  show Dan pointed out that because he's doing his own thing now with the the new
[01:59:04.240 --> 01:59:08.320]  consumer I believe it's called yeah sorry sorry Dan but I think it's a new
[01:59:08.320 --> 01:59:12.720]  consumer which is awesome and it's he's doing his own thing but that his
[01:59:12.720 --> 01:59:19.160]  observation was that the trend towards journalists and writer types and pundit
[01:59:19.160 --> 01:59:23.400]  types like me doing their own thing has sort of gone the other way and the New
[01:59:23.400 --> 01:59:27.480]  York Times and Bloomberg and a few other top and and maybe the Washington Post
[01:59:27.480 --> 01:59:32.600]  would throw in are sucking in all the good talent yeah I think I would
[01:59:32.600 --> 01:59:37.800]  absolutely put Kashmir Hill in that list I think her most recent thing that I
[01:59:37.800 --> 01:59:43.640]  remember reading was at gizmodo where she agrees I think she had done a I
[01:59:43.640 --> 01:59:46.520]  forget what it was but she's a series where she did the like I'm gonna get off
[01:59:46.520 --> 01:59:50.740]  Facebook yes I'm gonna get I'm gonna I'm gonna stop using all of the big five
[01:59:50.740 --> 01:59:54.560]  tech company products yeah and what was that like and it was like she was living
[01:59:54.560 --> 01:59:58.920]  in a desert right it was amazing what happens what happens if you don't use
[01:59:58.920 --> 02:00:05.020]  Google Amazon Facebook I forget if Apple was on the list or not rotation but it
[02:00:05.020 --> 02:00:07.600]  was yeah she's worked across I was looking at her because she's worked
[02:00:07.600 --> 02:00:12.000]  across several publications all her pieces are must reads she does
[02:00:12.000 --> 02:00:15.440]  incredible I mean so she does those like I would say like almost consumer style
[02:00:15.440 --> 02:00:18.360]  investigations like what are the companies learning about us and how do
[02:00:18.360 --> 02:00:23.120]  we extract ourselves then she does the others which are like what happens when
[02:00:23.120 --> 02:00:27.080]  you know if I put myself in this situation what do companies find out
[02:00:27.080 --> 02:00:30.320]  about me yeah and that's sort of a little bit of what this this is a little
[02:00:30.320 --> 02:00:34.880]  I think a mix of that we all need so I have been saying and I don't want to
[02:00:34.880 --> 02:00:38.000]  like I don't want to put myself up because I'm not saying things anyone
[02:00:38.000 --> 02:00:41.800]  else hasn't said but a few years ago when I started seeing the effectiveness
[02:00:41.800 --> 02:00:46.440]  of AI based transcription in its early stages so I've been using Trent which is
[02:00:46.440 --> 02:00:50.920]  a very it was very inexpensive they just switch to a more expense well a cheaper
[02:00:50.920 --> 02:00:55.040]  but subscription model that is more expensive for ad hoc use like I used it
[02:00:55.040 --> 02:00:58.080]  and it was pretty good when it started it's gotten better and it's it's not as
[02:00:58.080 --> 02:01:02.080]  good as you know paid transcription services with people who are you know
[02:01:02.080 --> 02:01:05.880]  professionals and looking at everything but it's very good for AI based stuff
[02:01:05.880 --> 02:01:09.940]  and then there were some people throwing together some podcasts like cheap and
[02:01:09.940 --> 02:01:16.160]  dirty AI based or language learning podcast transcription stuff and I was
[02:01:16.160 --> 02:01:19.720]  like wow this is totally amazing and I knew voice recognition of course with
[02:01:19.720 --> 02:01:23.720]  Siri and Google assistant all these other things had gotten really good
[02:01:23.720 --> 02:01:27.720]  right so I'm aware of that and then when I started seeing the really cheap bad
[02:01:27.720 --> 02:01:31.120]  stuff I had that innovators dilemma feeling where you're like oh yeah this
[02:01:31.120 --> 02:01:35.200]  is where you see something really bad and really cheap and it eats a bottom of
[02:01:35.200 --> 02:01:39.040]  a market but then it gets better and it eats from the bottom up and I thought oh
[02:01:39.040 --> 02:01:41.720]  here's the point at which so maybe I don't know three or four years ago I
[02:01:41.720 --> 02:01:47.080]  started tweeting at some point everything every picture of you that's
[02:01:47.080 --> 02:01:51.760]  available publicly online every piece of audio in which you speak every video in
[02:01:51.760 --> 02:01:56.060]  which you appear will be categorized and labeled with you and someone will be
[02:01:56.060 --> 02:02:00.460]  able to search and find every instance of you in any public source that you
[02:02:00.460 --> 02:02:04.160]  have ever posted and it's just a matter of time it's not a when or it's not if
[02:02:04.160 --> 02:02:09.560]  it's a when and over time that's become closer and closer and this story is
[02:02:09.560 --> 02:02:13.200]  basically we're now over that bar we're now in the next level it is now a thing
[02:02:13.200 --> 02:02:16.880]  and it's still images but we're moving you know video is the next right but
[02:02:16.880 --> 02:02:22.240]  that there's so there's a start-up I've never heard of to be true Clearview AI
[02:02:22.240 --> 02:02:29.540]  and they have apparently tried to index every publicly available photo that they
[02:02:29.540 --> 02:02:33.880]  can find on the internet pop I guess billions I don't even know if I think
[02:02:33.880 --> 02:02:37.960]  they're saying three three billion three billion images that yeah that's what the
[02:02:37.960 --> 02:02:44.440]  company claims that they've scraped from Facebook YouTube Venmo millions of other
[02:02:44.440 --> 02:02:48.220]  websites flicker I'm sure you know if you're talking about three billion you
[02:02:48.220 --> 02:02:54.160]  know mm-hmm and so you take a photo of somebody you have no idea who they are
[02:02:54.160 --> 02:02:59.640]  and you throw it at Clearview and Clearview comes back and says here's who
[02:02:59.640 --> 02:03:06.000]  it is and that it's fast and that they have hooks for augmented reality already
[02:03:06.000 --> 02:03:11.120]  so in theory you know you could get that the you know somebody showed Terminator
[02:03:11.120 --> 02:03:15.120]  I'm sure it's been in a bunch of movies but the idea that you could be wearing
[02:03:15.120 --> 02:03:19.320]  some kind of AR goggles or glasses and as you walk down the street I mean
[02:03:19.320 --> 02:03:22.440]  depending on how fast it is but we know how fast Google search has gotten for
[02:03:22.440 --> 02:03:26.120]  searching the index but that you can just look at somebody on the sidewalk
[02:03:26.120 --> 02:03:32.360]  and they'll know who you are you know you could certainly imagine absolutely
[02:03:32.360 --> 02:03:36.360]  imagine how of interest this would be to retailers because as you enter a
[02:03:36.360 --> 02:03:40.360]  physical retail shop there's certainly it's easy to capture a photo of the
[02:03:40.360 --> 02:03:43.800]  people who are coming in most of them already have cameras for security
[02:03:43.800 --> 02:03:51.180]  purposes meanwhile and you could go into a store of and you know pick your type a
[02:03:51.180 --> 02:03:55.600]  bookstore or whatever and I mean bookstore is probably a bad example but
[02:03:55.600 --> 02:04:00.480]  you know some sort of store where you get greeted by a salesperson let's say a
[02:04:00.480 --> 02:04:04.960]  jewelry store or something like that and they could already know you know and get
[02:04:04.960 --> 02:04:09.600]  like some kind of estimate as to you know well this person you know maybe may
[02:04:09.600 --> 02:04:13.520]  is you know it get a guess as to how much money you make or something like
[02:04:13.520 --> 02:04:18.480]  that and start steering you in a direction that you know and you have no
[02:04:18.480 --> 02:04:22.120]  idea that they've done this and that the salesperson already knows something
[02:04:22.120 --> 02:04:27.920]  about you I mean there's just all sorts of ways that this can go bad yeah there's
[02:04:27.920 --> 02:04:31.880]  already so many ways that's happening and it defeats human nature's instinct
[02:04:31.880 --> 02:04:36.440]  that as you're walking down the street that you're anonymous you know mm-hmm
[02:04:36.440 --> 02:04:40.480]  that the only people who recognize you are the people who know you well this
[02:04:40.480 --> 02:04:44.120]  ties in a little bit with my son I forget if he's a security researcher not
[02:04:44.120 --> 02:04:47.600]  somebody tweeting about I was I've got a cold I was just thinking about going
[02:04:47.600 --> 02:04:51.560]  out to get cold medicine and Facebook or Google just showed me cold medicine ads
[02:04:51.560 --> 02:04:55.400]  and I hadn't been searching on it and I'd read recently you know the there's a
[02:04:55.400 --> 02:04:58.640]  myth that Facebook is analyzing audio all the time when you're running wrap
[02:04:58.640 --> 02:05:02.760]  around the background and you know I I don't want to put anything past
[02:05:02.760 --> 02:05:06.800]  Facebook but I don't have the app installed on my on my phone and I was
[02:05:06.800 --> 02:05:10.640]  off chatting with someone at a cocktail party I met someone who knew a late
[02:05:10.640 --> 02:05:13.880]  friend of mine and talked about this person for years we talked about her
[02:05:13.880 --> 02:05:17.280]  about how much we missed her I come home I open up Facebook and there is an ad
[02:05:17.280 --> 02:05:21.440]  for her former business and I'm like what in God's name so I know it wasn't
[02:05:21.440 --> 02:05:24.960]  listening to me right and I know it wasn't fed that way the explanation that
[02:05:24.960 --> 02:05:27.640]  I read recently and I think this wasn't Kashmir Hall it was someone it was a
[02:05:27.640 --> 02:05:34.920]  another New York Times reporter Claire a black-handed lame they'll come to me
[02:05:34.920 --> 02:05:39.240]  but she wrote a piece covered piece recently it was to describe that because
[02:05:39.240 --> 02:05:44.100]  of all this location information that's being gathered it doesn't matter they
[02:05:44.100 --> 02:05:49.120]  don't have to listen to you they know that you just walk to the store and what
[02:05:49.120 --> 02:05:52.720]  you bought at checkout and came home because they can gather from your apps
[02:05:52.720 --> 02:05:55.920]  all your location information they can associate the purchasing with your
[02:05:55.920 --> 02:05:59.640]  unique phone and even if you don't do it if ten people in your apartment building
[02:05:59.640 --> 02:06:03.080]  have just gone and bought cold medicine and come back they're like oh there's a
[02:06:03.080 --> 02:06:06.640]  bunch of colds in that building we're gonna show him cold medicine ads and I
[02:06:06.640 --> 02:06:10.280]  was like oh that makes total sense they've got complete surveillance on us
[02:06:10.280 --> 02:06:14.520]  so of course they don't have to know that I'm having cold they know that a
[02:06:14.520 --> 02:06:17.680]  lot of people around me have bought cold medicine and come back to the same
[02:06:17.680 --> 02:06:22.000]  location and people are so paranoid about it too because people do pattern
[02:06:22.000 --> 02:06:27.000]  matching and rightly so people are so paranoid about this like my phone is
[02:06:27.000 --> 02:06:30.560]  always listening to me and then does things that it could only know if it was
[02:06:30.560 --> 02:06:37.120]  listening to me I was at a big family gathering somebody had a birthday over
[02:06:37.120 --> 02:06:46.560]  the weekend we were a big family gathering over the weekend and one of
[02:06:46.560 --> 02:06:50.640]  Amy's aunt's asked me we I forget how we got talking about iPhones but you know
[02:06:50.640 --> 02:06:54.440]  they know what I do and they don't typically I certainly don't talk Apple
[02:06:54.440 --> 02:07:00.000]  stuff to them but if they have questions you know they asked me you know and she
[02:07:00.000 --> 02:07:04.520]  said to me let me ask you this and it was about this topic of the phone
[02:07:04.520 --> 02:07:10.200]  listening and she has an iPhone and she said that the one day at work her and
[02:07:10.200 --> 02:07:15.920]  her friends were oh it got to the point it was somebody else brought up the fact
[02:07:15.920 --> 02:07:22.640]  that they have the feature on where the his his commute his schedule is very
[02:07:22.640 --> 02:07:26.240]  rigid he does you know takes his kids to school and then goes to work and it says
[02:07:26.240 --> 02:07:30.160]  and he's just amazed by the fact that he gets in and says hey it'll take 17
[02:07:30.160 --> 02:07:34.100]  minutes to drive your kid to school and he goes damn it if it doesn't take 17
[02:07:34.100 --> 02:07:38.160]  minutes and then it says it's gonna take you 23 minutes to get to work and 23
[02:07:38.160 --> 02:07:42.080]  minutes later he's pulling into work and he's like it's awesome but it's a little
[02:07:42.080 --> 02:07:47.680]  spooky and then Amy's aunt said well let me ask you this the one day at work her
[02:07:47.680 --> 02:07:50.920]  and she works with a bunch of other women she said they were just really
[02:07:50.920 --> 02:07:56.520]  having a good time and just not like it did they were doing something that they
[02:07:56.520 --> 02:08:00.300]  get in trouble for but they were I don't know laughing and laughing and they got
[02:08:00.300 --> 02:08:03.600]  just got off you know just goofing around at the end of the day at work and
[02:08:03.600 --> 02:08:08.400]  really really having a good time laughing and then she leaves to go home
[02:08:08.400 --> 02:08:16.000]  and her iPhone gave randomly gave her said directions to like the local comedy
[02:08:16.000 --> 02:08:21.440]  club in town and she said and I've never been there I've never gone there in my
[02:08:21.440 --> 02:08:24.920]  life I didn't ask for directions there and it just said it'll take you you know
[02:08:24.920 --> 02:08:32.140]  18 minutes to drive to the Comedy Store and whatever Pennsylvania and she got
[02:08:32.140 --> 02:08:36.160]  freaked out that it was because her and her colleagues had been laughing it up
[02:08:36.160 --> 02:08:40.600]  the last half hour at work and I was like that's really weird that it would
[02:08:40.600 --> 02:08:44.120]  offer you directions there that you've never never even been there but that
[02:08:44.120 --> 02:08:47.200]  that's not how it happened it wasn't because you and your friends were
[02:08:47.200 --> 02:08:53.800]  laughing but but I I don't blame her she's obviously she's not a technical
[02:08:53.800 --> 02:08:57.920]  person at all she knows these stories she's probably seen other spooky things
[02:08:57.920 --> 02:09:02.800]  have been where you do XY and Z and then all of a sudden Facebook or whoever is
[02:09:02.800 --> 02:09:06.120]  you know showing you ads or giving you suggestions for something that they
[02:09:06.120 --> 02:09:13.000]  seemingly would have to know you know that's obviously not what happened but
[02:09:13.000 --> 02:09:17.320]  it's totally natural that as a human being you would draw those two together
[02:09:17.320 --> 02:09:22.280]  right like that's the way human beings minds work anyway well I think it fits
[02:09:22.280 --> 02:09:27.280]  it fits into that possibility too is that it actually could be that when you
[02:09:27.280 --> 02:09:30.320]  have a bunch of people together and you're staying late and people are
[02:09:30.320 --> 02:09:33.720]  searching for certain things on their phones right the the algorithm of
[02:09:33.720 --> 02:09:36.760]  whatever provides this kind of stuff says hey there's a bunch of people
[02:09:36.760 --> 02:09:42.040]  here's a thing you know these kinds of connections are it what's what's scary
[02:09:42.040 --> 02:09:47.080]  actually is how predictable we are rather than that it's listening to us
[02:09:47.080 --> 02:09:51.200]  hey shocker among shockers guess who's one of the bad financial backers of this
[02:09:51.200 --> 02:09:54.640]  Clearview company that is already working with law enforcement by the way
[02:09:54.640 --> 02:09:57.800]  that's who their customers are at this point with this reverse image I knew
[02:09:57.800 --> 02:10:01.400]  this before I read this story when it said I read the paragraph that said
[02:10:01.400 --> 02:10:08.680]  investors include and I was like Peter Thiel right shocker among shockers but
[02:10:08.680 --> 02:10:13.080]  anyway an unknown number of law enforcement agencies are already using
[02:10:13.080 --> 02:10:17.840]  this I don't know what there is that we can do about it and then that ties into
[02:10:17.840 --> 02:10:23.400]  another story that I just ran into the other day where Nelson Minar who's been
[02:10:23.400 --> 02:10:30.960]  blogging forever great person brought up that this search engine I have never
[02:10:30.960 --> 02:10:40.560]  heard of called Oh Yandex yeah yeah yeah the index is a Russian it's a search
[02:10:40.560 --> 02:10:44.800]  engine in Russia and in fact there's just a story also about them because
[02:10:44.800 --> 02:10:50.400]  they're apparently do not engage in the same behavior or the same restrictions
[02:10:50.400 --> 02:10:54.360]  that other search engines do globally around child pornography and it's become
[02:10:54.360 --> 02:10:58.080]  a huge issue just a big story about that a few days ago well one of the things
[02:10:58.080 --> 02:11:04.680]  what Nelson showed was that they do reverse image search on faces and which
[02:11:04.680 --> 02:11:09.240]  is something that Google obviously has claimed for years could do and that they
[02:11:09.240 --> 02:11:14.360]  chose not to because of the obvious privacy implications and and Nelson's
[02:11:14.360 --> 02:11:19.320]  blog post I'll put it in the in the show notes he took a picture of himself it
[02:11:19.320 --> 02:11:25.640]  works best if you take what I would just offhand I think you know everybody will
[02:11:25.640 --> 02:11:30.040]  know what I mean take like a fake ID picture like the type of picture that
[02:11:30.040 --> 02:11:34.000]  you would take of yourself if you were going to submit your own new picture for
[02:11:34.000 --> 02:11:38.880]  a driver's license or a passport you know mostly your head blank background
[02:11:38.880 --> 02:11:44.920]  that type of selfie take one of those submit it as just you know put it on your
[02:11:44.920 --> 02:11:48.560]  computer and then go to their image search and it says there's like a camera
[02:11:48.560 --> 02:11:52.160]  button for like hey do you want to you know start and instead of searching for
[02:11:52.160 --> 02:11:58.800]  words search based on a starting image click that button upload your selfie and
[02:11:58.800 --> 02:12:03.320]  his came back with I don't know it's like they give you like 12 results but
[02:12:03.320 --> 02:12:07.640]  like the first the first two or three were definitely him yeah and the other
[02:12:07.640 --> 02:12:11.840]  people did look like him I tried it with one I showed you the screenshot I have
[02:12:11.840 --> 02:12:15.840]  to I guess I'll put the screenshot in the show notes if I can I don't think
[02:12:15.840 --> 02:12:21.040]  there's anything revealing it's pretty good there the top four pictures were
[02:12:21.040 --> 02:12:26.760]  from I think my iPhone review from two years ago I think it was two years ago
[02:12:26.760 --> 02:12:31.680]  where I included some pictures of me that my wife had taken with portrait
[02:12:31.680 --> 02:12:36.960]  mode of the iPhone camera so but if you had that picture of me that you started
[02:12:36.960 --> 02:12:41.600]  that I started with and had no idea who I was but just had that picture if you
[02:12:41.600 --> 02:12:48.280]  sent it to Yandex it the first four or five results and most of the first eight
[02:12:48.280 --> 02:12:52.920]  are me and then you could click through to the origin and figure out okay that's
[02:12:52.920 --> 02:12:56.320]  John Gruber the cool thing though is you can see what you'd look like with a lot
[02:12:56.320 --> 02:13:08.360]  of different mustaches the ones that are wrong are close enough not like that you
[02:13:08.360 --> 02:13:12.880]  would think is that John Gruber but they certainly you know you could see why a
[02:13:12.880 --> 02:13:18.680]  distant family resemblance well or at least show me people who look like this guy but it
[02:13:18.680 --> 02:13:24.800]  is absolutely whoa eye-opening I have never seen this before I can send a
[02:13:24.800 --> 02:13:30.160]  totally anonymous photo to this site and half a half a second later find out that
[02:13:30.160 --> 02:13:35.480]  it's John Gruber yeah I did now tested a couple for myself and it's not as great
[02:13:35.480 --> 02:13:39.800]  but it did find oh I don't know like six or seven different ones for two
[02:13:39.800 --> 02:13:44.600]  different shots are any are any of them you yeah they're on me I'm sorry it
[02:13:44.600 --> 02:13:48.960]  found a bunch and I found six seven that were me oh okay yeah so it did so
[02:13:48.960 --> 02:13:52.200]  somebody who started with your starting point would definitely figure out that's
[02:13:52.200 --> 02:13:56.080]  Glenn Fleishman oh yeah I mean in one case I mean you're saying that you're
[02:13:56.080 --> 02:14:02.280]  saying that the misses weren't as Glenn Fleishman II they were I mean that's a
[02:14:02.280 --> 02:14:07.800]  good way to find relatives like they were they're actually a reasonable I
[02:14:07.800 --> 02:14:15.440]  would say in a dark room you might think no it was very it's very funny yeah
[02:14:15.440 --> 02:14:18.800]  because I've been using reverse imagesters for a long time and I never
[02:14:18.800 --> 02:14:22.320]  thought about I never thought about the fact that was actually relatively
[02:14:22.320 --> 02:14:27.120]  difficult to do a full image you know and of course it was actually by intent
[02:14:27.120 --> 02:14:31.440]  so well it's a real eye-opener and I don't know what we can do I mean this
[02:14:31.440 --> 02:14:35.720]  seems like this is toothpaste that can't go back in the tube you know it's a
[02:14:35.720 --> 02:14:39.240]  genie that's out of the bottle I mean we're not gonna what are we gonna do and
[02:14:39.240 --> 02:14:46.000]  and is this going does anybody else outside of Yandex who's been sitting on
[02:14:46.000 --> 02:14:51.040]  this out of fear you know that they don't want to be the first because of
[02:14:51.040 --> 02:14:57.600]  the backlash that might happen you know once this sort of thing is out it's open
[02:14:57.600 --> 02:15:02.080]  game you know how long now until Google it flips the switch that turns it on and
[02:15:02.080 --> 02:15:06.040]  how much how much better will Google's version be although I would actually
[02:15:06.040 --> 02:15:10.960]  argue I am NOT usually let's say how do you say this it's like it's not that I
[02:15:10.960 --> 02:15:14.760]  was opposed to regulation or necessarily in favor of it and I think there's a lot
[02:15:14.760 --> 02:15:19.920]  of things that regulation can't handle like I love regulation as a tool to make
[02:15:19.920 --> 02:15:24.280]  things fairer and level the playing field when money or power distort things
[02:15:24.280 --> 02:15:27.840]  right so I mean that's a I don't know I don't know where that falls on the
[02:15:27.840 --> 02:15:30.720]  political spectrum but like I don't think that you know there's all this
[02:15:30.720 --> 02:15:33.400]  talk about like you know what kind of regulation should you put on tech
[02:15:33.400 --> 02:15:38.240]  companies obviously there should be some more and different than is now but not
[02:15:38.240 --> 02:15:42.400]  necessarily the kind that Congress wants to do but with this particular thing I
[02:15:42.400 --> 02:15:48.040]  actually think because the greatest value of it is going to be in industries
[02:15:48.040 --> 02:15:53.400]  that are working in the US and then evolve US companies that regulating this
[02:15:53.400 --> 02:15:57.880]  as making it illegal for police departments to rely or law enforcement
[02:15:57.880 --> 02:16:02.080]  officers to rely on these kinds of databases and to make it illegal to sell
[02:16:02.080 --> 02:16:05.560]  it as a service or to strictly regulate it in some fashion I think it might have
[02:16:05.560 --> 02:16:08.920]  an impact because even though the toothpaste that are the tube and you can
[02:16:08.920 --> 02:16:12.760]  go to Yandex or other international sites potentially do the same thing it
[02:16:12.760 --> 02:16:16.560]  could not be used legally like if a police officer uses it as the basis or
[02:16:16.560 --> 02:16:21.080]  should say one of the bases of attain a warrant as is discussed in the story
[02:16:21.080 --> 02:16:25.200]  that it can't be the sole basis to go to a judge then if that's illegal then the
[02:16:25.200 --> 02:16:28.880]  case you know and it's determined the case gets thrown out or a judge refuses
[02:16:28.880 --> 02:16:34.160]  to accept it because of the rules of issuing warrants or Google being told
[02:16:34.160 --> 02:16:38.440]  you know maybe they would want to get in the business and then are trying to
[02:16:38.440 --> 02:16:42.840]  comply with the law and wouldn't or this company that's in the article might be
[02:16:42.840 --> 02:16:49.680]  forced to not offer its services anymore so I think regulation might be a tool to
[02:16:49.680 --> 02:16:54.040]  you know you can't put the toothpaste back in but you can make the toothpaste
[02:16:54.040 --> 02:16:59.800]  not as valuable to sell basically all right how we doing on time we have time
[02:16:59.800 --> 02:17:03.680]  for one more segment on email spam and then we're out oh I have just a real
[02:17:03.680 --> 02:17:06.640]  time correction really quickly is the author I was thinking of at the New York
[02:17:06.640 --> 02:17:11.240]  Times is Claire Kane Miller who was a very fine reporter although she's moved
[02:17:11.240 --> 02:17:14.680]  on from technology reporting the person I actually met was Nicole Pearl Roth
[02:17:14.680 --> 02:17:18.560]  another excellent security reporter the New York Times would they seem to have a
[02:17:18.560 --> 02:17:22.280]  ton but the story I think everyone should read and we don't have to cover
[02:17:22.280 --> 02:17:26.720]  this you may have talked about this too is it's the one one nation tract that
[02:17:26.720 --> 02:17:31.160]  was actually produced by the New York Times opinion section as a reported
[02:17:31.160 --> 02:17:34.920]  piece and that's the one that actually had the whole thing about following
[02:17:34.920 --> 02:17:38.800]  people and associating purchases and locations that's by Stuart Thompson and
[02:17:38.800 --> 02:17:44.040]  Charlie Worsell who's also fine people they have a great great venture people
[02:17:44.040 --> 02:17:47.200]  there so anyway that's just my correction you know that was a good
[02:17:47.200 --> 02:17:50.480]  story I did I linked to that the one nation tract we don't have to go into it
[02:17:50.480 --> 02:17:53.880]  in depth that was where they were talking about these shadowy companies
[02:17:53.880 --> 02:17:59.240]  that collect location data that they obtain through means we're not can't
[02:17:59.240 --> 02:18:02.840]  really be sure of but I think it's most I think it's mostly through frameworks
[02:18:02.840 --> 02:18:09.760]  that third-party apps include in in the app that's yeah and then the app asks
[02:18:09.760 --> 02:18:14.200]  you like let's say it's a weather app and the weather app says can can we have
[02:18:14.200 --> 02:18:17.360]  your location data to show you the weather and you say yes because that
[02:18:17.360 --> 02:18:23.400]  makes sense and then they also include this framework to a location collection
[02:18:23.400 --> 02:18:29.360]  company and it the framework you know takes your data and a unique identifier
[02:18:29.360 --> 02:18:36.880]  or some sort or and you know tracks your data as you go about and then they
[02:18:36.880 --> 02:18:40.380]  correlate it to purchases or something else about you and they can build a
[02:18:40.380 --> 02:18:45.040]  profile that shows here's a person who bounces between Brooklyn and Manhattan
[02:18:45.040 --> 02:18:50.320]  and the hours show clearly show that you live in Brooklyn and you work in lower
[02:18:50.320 --> 02:18:54.640]  Manhattan and here's where you go and all this creepy stuff here's here's
[02:18:54.640 --> 02:18:58.720]  somebody going to a building that isn't associated with the CIA right but they
[02:18:58.720 --> 02:19:02.440]  see right traveling overseas and then going between you know you make track
[02:19:02.440 --> 02:19:07.600]  police officers law enforcement and they they identified a celebrity based on a
[02:19:07.600 --> 02:19:12.480]  date they found like like a concert where they're you know a date and a time
[02:19:12.480 --> 02:19:16.880]  and a location of the concert and a phone that was going to a hotel and then
[02:19:16.880 --> 02:19:21.800]  they forget who the artist was but they contacted her you know and asked for her
[02:19:21.800 --> 02:19:24.920]  permission and she's you know she gave them an on-the-record interview and said
[02:19:24.920 --> 02:19:28.360]  yeah that's definitely me you know that that was me that was where I was staying
[02:19:28.360 --> 02:19:34.560]  that was my concert that's creepy AF so so your Apple put that new feature it
[02:19:34.560 --> 02:19:39.560]  says for location it says used to be that an app could request permanent
[02:19:39.560 --> 02:19:44.520]  permission within the app right now you cannot and the reason is this is
[02:19:44.520 --> 02:19:48.640]  obviously this I wondered why Apple had tightened the screws and apparently all
[02:19:48.640 --> 02:19:53.080]  the ad networks and and ad advertising companies at software companies are
[02:19:53.080 --> 02:19:56.920]  peeved about this because it reduces their ability to targeted ads and make
[02:19:56.920 --> 02:20:01.340]  nearly as much money I gather but this is exactly why so you know why does a
[02:20:01.340 --> 02:20:05.160]  weather app do you know my location all the time I'll let it use it now but you
[02:20:05.160 --> 02:20:11.240]  have to go into privacy settings in iOS and iPad OS to change that people to
[02:20:11.240 --> 02:20:16.080]  make it permanent people get indignant when they were able to make money doing
[02:20:16.080 --> 02:20:22.400]  X and then they're no longer to make money doing X they get peeved and in and
[02:20:22.400 --> 02:20:27.560]  not just peeved because you know you get peeved if you made money doing X for any
[02:20:27.560 --> 02:20:32.080]  reason and no longer can make the money but they they get indignant about it and
[02:20:32.080 --> 02:20:38.640]  feel as though they have been wronged in a way that if X had never been allowed
[02:20:38.640 --> 02:20:46.360]  they wouldn't feel wronged and so I wasn't gonna go off on this topic but
[02:20:46.360 --> 02:20:52.800]  there was congressional testimony this week and the people at tile testified
[02:20:52.800 --> 02:20:57.880]  against Apple it was a it was a congressional investigation into is are
[02:20:57.880 --> 02:21:02.360]  the major made you know it's just I guess probably the big five fam Facebook
[02:21:02.360 --> 02:21:10.880]  Amazon Apple Google who am I missing Mac Microsoft are they how are they are
[02:21:10.880 --> 02:21:17.560]  abusing their size and you know in anti-competitive ways and tile testified
[02:21:17.560 --> 02:21:24.560]  that Apple had had anti competitively moved against them by including the fine
[02:21:24.560 --> 02:21:29.400]  my find my feature in iPhones because now it makes its building in the ability
[02:21:29.400 --> 02:21:33.960]  to find your lost phones so you don't need to use a tile product to do it
[02:21:33.960 --> 02:21:39.240]  which to me seems like a nonsense argument not not nonsense but it just
[02:21:39.240 --> 02:21:42.320]  seems like barking up the wrong tree like that's a great feature and you
[02:21:42.320 --> 02:21:45.840]  really can't argue that you should have to buy a third-party physical object to
[02:21:45.840 --> 02:21:52.640]  get it to be fair and they're already preemptively complaining about Apple's
[02:21:52.640 --> 02:21:59.280]  supposed tile tracker dinguses that have been rumored for a year but haven't even
[02:21:59.280 --> 02:22:03.360]  been announced and yet they're already complaining to Congress that they're you
[02:22:03.360 --> 02:22:09.480]  know it's anti-competitive for them to build it into the system and you know
[02:22:09.480 --> 02:22:13.080]  and complaints from other people specifically about the thing you just
[02:22:13.080 --> 02:22:20.400]  said that iOS 13 removed the ability for an app to ask you to grant it always on
[02:22:20.400 --> 02:22:25.480]  location tracking even though the feature is still there you just have to
[02:22:25.480 --> 02:22:31.200]  go to the settings app privacy location and then find the app and there you
[02:22:31.200 --> 02:22:37.760]  could say if if the app does want always on location tracking there's where you
[02:22:37.760 --> 02:22:43.080]  can grant it and I do think that the app is allowed to have a shortcut that jumps
[02:22:43.080 --> 02:22:47.000]  you there like that's for sure because I know I've tapped those it's ready to the
[02:22:47.000 --> 02:22:51.200]  right spot but it does you do have to jump out of the app into the settings
[02:22:51.200 --> 02:22:56.800]  app to do it and so I think the fact that it's more than just telling you
[02:22:56.800 --> 02:23:02.000]  instructions for how to get four levels deep into the setting or three levels
[02:23:02.000 --> 02:23:06.080]  whatever it is into the settings app to do it the fact that they let you tap a
[02:23:06.080 --> 02:23:12.080]  button to jump you there to grant it I think it's a reasonable compromise in my
[02:23:12.080 --> 02:23:17.800]  opinion for what is what has turned out to be a very severely privacy invasive
[02:23:17.800 --> 02:23:23.040]  feature and then the other thing that I think that they are very annoyed about
[02:23:23.040 --> 02:23:26.320]  is the new feature in iOS that I don't think they mentioned it because I don't
[02:23:26.320 --> 02:23:29.360]  think there's any way I don't think there's any way they can mention it
[02:23:29.360 --> 02:23:34.580]  without them looking bad like like the angle that people always take against
[02:23:34.580 --> 02:23:38.560]  Apple and sometimes it's true right like there absolutely there are good
[02:23:38.560 --> 02:23:42.920]  anti-competitive arguments against Apple and a lot of them I think the biggest is
[02:23:42.920 --> 02:23:50.200]  the the insistence upon taking 30 to 15 percent of App Store transactions and
[02:23:50.200 --> 02:23:55.680]  that that an app like an e-book reader I mean I did you know pity poor Mike
[02:23:55.680 --> 02:24:00.120]  Amazon with Kindle but like the fact that the Kindle app can't just have a
[02:24:00.120 --> 02:24:05.400]  button that jumps you to Safari to buy your Kindle books in Safari you can't
[02:24:05.400 --> 02:24:10.960]  even have that button in your ass is to me anti-competitive and I really think
[02:24:10.960 --> 02:24:14.520]  that that's the sort of thing the government could really you know it make
[02:24:14.520 --> 02:24:17.760]  some change you know force Apple to bend on because I don't think it's right I
[02:24:17.760 --> 02:24:21.360]  think it is anti-competitive and you can't even mention it you can't even
[02:24:21.360 --> 02:24:28.260]  have a thing in your app that says go to oh you know my content store or like the
[02:24:28.260 --> 02:24:32.120]  you know net again Netflix is a huge company with billions in revenue but
[02:24:32.120 --> 02:24:37.160]  Netflix can't even tell you go to netflix.com to sign up for Netflix they
[02:24:37.160 --> 02:24:41.640]  can let alone making it a hot link I upload an e-book to the Apple bookstore
[02:24:41.640 --> 02:24:45.760]  a few years ago the magazine that I ran the magazine Marco that when I bought
[02:24:45.760 --> 02:24:50.800]  from Marco I did a complete archive of the entire run of it uploaded as a book
[02:24:50.800 --> 02:24:54.320]  Apple's fine selling it you know not that many copies but it was just want to
[02:24:54.320 --> 02:24:56.680]  make sure it was out there and then I get this thing it's like we have
[02:24:56.680 --> 02:25:00.200]  rejected your book and you need to make this change the change was there was one
[02:25:00.200 --> 02:25:08.280]  embedded link to an Amazon item in a 1200 page ebook that's crazy so I think
[02:25:08.280 --> 02:25:13.440]  that's I think that's anti-competitive so I'm not saying Apple is like I'm not
[02:25:13.440 --> 02:25:16.960]  some kind of blind Apple loyal to list is saying Apple has never abused its
[02:25:16.960 --> 02:25:23.800]  competitive you know position I think the App Store and that 30% 15% cut or we
[02:25:23.800 --> 02:25:26.680]  get some kind of money from everything that goes through and you can't even
[02:25:26.680 --> 02:25:32.600]  link to stuff there that's something but this always on location thing is clearly
[02:25:32.600 --> 02:25:37.960]  a move that they've done for privacy it is not it is not a power move to sell
[02:25:37.960 --> 02:25:42.360]  more of their own locations tracking tiles but I think the other change in
[02:25:42.360 --> 02:25:46.320]  iOS 13 that these people are really peeved about are the periodic reminders
[02:25:46.320 --> 02:25:55.800]  where apps that are using your location in the background it is it is super
[02:25:55.800 --> 02:26:01.760]  great the map and everything yeah and everything it shows you so it shows you
[02:26:01.760 --> 02:26:08.280]  so one app that I am happy to grant always on location access to is dark sky
[02:26:08.280 --> 02:26:12.960]  the weather weather app that gives you warnings for upcoming precipitation or
[02:26:12.960 --> 02:26:20.000]  other weather events I get you know every week or so I think it's somewhat
[02:26:20.000 --> 02:26:24.040]  random or or the algorithm behind it is you can't just time it it's not like
[02:26:24.040 --> 02:26:28.480]  every Tuesday at three o'clock I get this reminder but you know every week or
[02:26:28.480 --> 02:26:34.360]  two I get a reminder that says hey dark sky has been using your location in the
[02:26:34.360 --> 02:26:41.760]  background nine times over the last whatever period of time and then the map
[02:26:41.760 --> 02:26:46.320]  shows with little markers where they are and of course every single one of them
[02:26:46.320 --> 02:26:51.840]  is at my house because I don't go anywhere but but there it is hop saying
[02:26:51.840 --> 02:26:56.720]  come on right exactly but I love that but the people who are you know using
[02:26:56.720 --> 02:27:02.040]  your location data apps that might you know who knows you know like games or
[02:27:02.040 --> 02:27:05.400]  something like that some free game and it just says hey we want to use your
[02:27:05.400 --> 02:27:08.760]  location data for something and maybe you okayed it and then all of a sudden
[02:27:08.760 --> 02:27:11.840]  you find out that this weird game that you haven't played in three months has
[02:27:11.840 --> 02:27:15.120]  been using your location in the background do you want to stop it and
[02:27:15.120 --> 02:27:17.800]  you don't even have to go to the app you just say oh yeah I don't want that and
[02:27:17.800 --> 02:27:21.640]  you click a button and it goes away this this is great it's not there's
[02:27:21.640 --> 02:27:25.360]  it'd be difficult to argue this is anti-competitive unless Apple were
[02:27:25.360 --> 02:27:28.720]  collecting and selling the information in the same way and because of its
[02:27:28.720 --> 02:27:32.760]  privacy stance you know and sometimes it slips up and sometimes they have to
[02:27:32.760 --> 02:27:35.760]  apologize and sometimes they have to change the software sometimes they don't
[02:27:35.760 --> 02:27:40.400]  realize the consequences but Apple is not enforcing this I mean there you know
[02:27:40.400 --> 02:27:44.680]  Google and some others might claim Apple has put this in place to hobble the
[02:27:44.680 --> 02:27:50.920]  advertising market to force app developers to route more money through
[02:27:50.920 --> 02:27:54.880]  with like in-app purchases or higher app prices that Apple gets a cut of that
[02:27:54.880 --> 02:27:58.640]  there is an argument for that but you can take two different apps that have
[02:27:58.640 --> 02:28:02.480]  the same abilities and functions and one is doing horrible tracking that you have
[02:28:02.480 --> 02:28:06.600]  to block and the other is not it's just doing normal advertising that is not
[02:28:06.600 --> 02:28:10.640]  full of horrible trackers and those two exist side by side and Apple isn't doing
[02:28:10.640 --> 02:28:14.200]  anything preferential between them if they both meet the rules what it's saying
[02:28:14.200 --> 02:28:17.360]  is these random apps can't track you all the time in the background without
[02:28:17.360 --> 02:28:23.120]  explicit user intervention and it's not trying to make money off that itself
[02:28:23.120 --> 02:28:27.360]  that would be anti-competitive did you also see though the Bluetooth one is the
[02:28:27.360 --> 02:28:30.800]  one that got me do you get the Bluetooth pop-up this app would like to use your
[02:28:30.800 --> 02:28:36.880]  Bluetooth settings I did for a little bit but I don't think I have many apps
[02:28:36.880 --> 02:28:42.800]  that are trying to do it I've yeah CNN app and some other apps and I was like I
[02:28:42.800 --> 02:28:46.120]  don't know why these would need there's apparently there's an innocent
[02:28:46.120 --> 02:28:50.040]  explanation about oh I don't know there's something it's it's not actually
[02:28:50.040 --> 02:28:53.600]  trying to communicate with your devices but it has to use some library whatever
[02:28:53.600 --> 02:28:58.960]  but I yeah when I first fired up I was 13 I think I had like 20 different apps
[02:28:58.960 --> 02:29:03.800]  were asking for Bluetooth apps access and none of them except one podcast app
[02:29:03.800 --> 02:29:07.400]  needed it I've heard that some of that was for location tracking to those so
[02:29:07.400 --> 02:29:11.000]  like when you'd enter like a retail building or something like that they
[02:29:11.000 --> 02:29:14.840]  might you can yeah yeah they might have the eye beacons and then if the app is
[02:29:14.840 --> 02:29:18.760]  still running in the background because you just checked CNN it would check in
[02:29:18.760 --> 02:29:22.680]  you know that there was some you know I really I do think I don't think Apple I
[02:29:22.680 --> 02:29:27.120]  added that idly you know just out of kicks no I think they were sharing yeah
[02:29:27.120 --> 02:29:31.280]  they think there was a standard library for for iBeacon and similar things that
[02:29:31.280 --> 02:29:34.800]  were being used broadly although iBeacon is kind of I don't know how widely
[02:29:34.800 --> 02:29:39.320]  deploy that was but I wouldn't be surprised if retailers have Bluetooth
[02:29:39.320 --> 02:29:41.960]  beacons that are not for information but for tracking and they get tracked
[02:29:41.960 --> 02:29:46.840]  through that mechanism to provide location information but yeah so I don't
[02:29:46.840 --> 02:29:51.360]  want to run the CNN app and have it be doing Bluetooth tracking of me because
[02:29:51.360 --> 02:29:54.800]  they happen to include that library if that's what was going on it's absolutely
[02:29:54.800 --> 02:29:59.040]  shocking to me Glenn that you're on the show and we're running long but I got to
[02:29:59.040 --> 02:30:01.600]  take a break here and thank our third and final sponsor and I have one more
[02:30:01.600 --> 02:30:07.600]  major topic I wanted to talk about but first I want to thank our friends at
[02:30:07.600 --> 02:30:13.040]  Squarespace hey it's still New Year I know Larry David thinks it's too late to
[02:30:13.040 --> 02:30:20.320]  say Happy New Year but I still say Happy New Year to you and New Year is when
[02:30:20.320 --> 02:30:24.080]  people naturally it's just human instinct you set new goals you make
[02:30:24.080 --> 02:30:29.360]  resolutions might be a time to start a new business start a new side gig
[02:30:29.360 --> 02:30:34.960]  launch a new creative project well anything that needs a website for your
[02:30:34.960 --> 02:30:38.360]  new project your new job your new business whatever it is you're doing
[02:30:38.360 --> 02:30:43.560]  started at Squarespace that's my suggestion make your next move there go
[02:30:43.560 --> 02:30:48.200]  to Squarespace you get a free trial last 30 days you can build your entire
[02:30:48.200 --> 02:30:55.560]  website in their WYSIWYG tools right there in the browser choose from tons of
[02:30:55.560 --> 02:31:01.120]  award-winning professionally designed templates that scale from mobile to
[02:31:01.120 --> 02:31:07.680]  desktop in all sorts of styles you can customize them completely with your own
[02:31:07.680 --> 02:31:13.160]  brand your own style in any way you want you add the features to the site that
[02:31:13.160 --> 02:31:18.120]  you want if you need a store at a store it takes care of all the commerce all
[02:31:18.120 --> 02:31:21.800]  the security stuff for you if you need a gallery because what you're building is
[02:31:21.800 --> 02:31:26.440]  some sort of portfolio for your design work of some sort they've got that for
[02:31:26.440 --> 02:31:29.760]  you you want to have a blog you want to host a podcast right on your site
[02:31:29.760 --> 02:31:35.000]  they've got all of that right there and for the stuff like a blog or a podcast
[02:31:35.000 --> 02:31:39.840]  that gets updated regularly you can post right through the Squarespace interface
[02:31:39.840 --> 02:31:46.680]  as you create new entries in your site everything really soup to nuts right
[02:31:46.680 --> 02:31:53.120]  there in Squarespace including also award-winning technical support so next
[02:31:53.120 --> 02:31:58.440]  time you need to make a new website or somebody you know comes to you and says
[02:31:58.440 --> 02:32:02.760]  hey can you help me make a new website send them to Squarespace it's the
[02:32:02.760 --> 02:32:09.840]  easiest way to get started 30 days free and with special code talk show at
[02:32:09.840 --> 02:32:14.880]  checkout you get 10% off everything is intuitive easy to use start your free
[02:32:14.880 --> 02:32:19.800]  trial today go to squarespace.com slash talk show squarespace.com slash talk
[02:32:19.800 --> 02:32:24.720]  show and remember that code talk show 29 or 30 days later when your free trials
[02:32:24.720 --> 02:32:28.400]  up and you'll get 10% off your first purchase which it could be prepaid
[02:32:28.400 --> 02:32:32.960]  for an entire year you get like tire month free over a
[02:32:32.960 --> 02:32:37.120]  month squarespace.com slash talk show I thank Squarespace for their continuing
[02:32:37.120 --> 02:32:42.040]  support of the talk show all right my last topic of the day and you and I were
[02:32:42.040 --> 02:32:48.100]  talking about this offline because we ran into it which is that is it my
[02:32:48.100 --> 02:32:56.040]  imagination or is spam filtering for email getting worse I missed emails in
[02:32:56.040 --> 02:33:01.360]  the last week from you where you were asking hey do you want to record record
[02:33:01.360 --> 02:33:11.000]  the show which yes I did here we are and Jason Snell I missed all he does the
[02:33:11.000 --> 02:33:14.960]  annual report card on you know the Apple annual report card which I love and I
[02:33:14.960 --> 02:33:20.040]  love to participate in because a I love to hear the answers of everybody but B
[02:33:20.040 --> 02:33:23.800]  it's like a free column idea for daring fireball by just putting my entire
[02:33:23.800 --> 02:33:28.600]  answers in there and of course he sent the original thing out a month ago and I
[02:33:28.600 --> 02:33:32.680]  thought I'll do it after the new year and then all of his reminder emails to
[02:33:32.680 --> 02:33:37.100]  me like last last call for those of you you know I maybe the reason it went to
[02:33:37.100 --> 02:33:42.760]  spam was because it was a message that wasn't just to John Gruber hey Gruber
[02:33:42.760 --> 02:33:48.600]  you know what the fuck send it in it was like to you know the the BCC recipient
[02:33:48.600 --> 02:33:54.000]  list of everybody he had asked to participate who hadn't yet submitted an
[02:33:54.000 --> 02:34:00.240]  answer I guess that's why but there is absolutely no way that emails from you
[02:34:00.240 --> 02:34:05.540]  from an email address you've been using as long as I've known you and Jason
[02:34:05.540 --> 02:34:12.000]  Snell using an email address that I've known for I think 20 years maybe more
[02:34:12.000 --> 02:34:17.600]  to my main email address that I've been using since I registered the daring
[02:34:17.600 --> 02:34:23.720]  fireball dotnet domain in 2002 like this it's not like they're going from or to
[02:34:23.720 --> 02:34:28.640]  new email addresses and it's not like the contents of any of them I mean again
[02:34:28.640 --> 02:34:33.360]  the one thing about Jason's is that it was like two unknown recipients but that
[02:34:33.360 --> 02:34:38.040]  really shouldn't apply to the spam and yours I have no idea no you wanted to
[02:34:38.040 --> 02:34:44.080]  buy some Cialis to know you did not I have noticed this recently but for a
[02:34:44.080 --> 02:34:49.320]  while and my email currently in for years now has been backed by Gmail I
[02:34:49.320 --> 02:34:54.400]  don't I don't use a gmail.com address as my address but my main email accounts
[02:34:54.400 --> 02:34:59.640]  are backed by separate Gmail accounts and the main reason I did was for spam
[02:34:59.640 --> 02:35:04.600]  filtering which I had found originally it was really excellent and I so
[02:35:04.600 --> 02:35:12.120]  excellent that I had fallen out of the habit of eyeballing my spam mailbox but
[02:35:12.120 --> 02:35:16.640]  recently I have found I have found that I absolutely have to do the old-fashioned
[02:35:16.640 --> 02:35:23.200]  thing and visually scan and like I told you it's you know at least that you know
[02:35:23.200 --> 02:35:28.320]  2,000 emails a month total you know comes all my addresses combined and I
[02:35:28.320 --> 02:35:32.280]  have to sit there and visually scan it and I things jump out I have missed I
[02:35:32.280 --> 02:35:37.120]  mean in addition to ones from you and Jason sponsorship inquiries you know
[02:35:37.120 --> 02:35:41.640]  from people you know companies that want to sponsor during fireball you know
[02:35:41.640 --> 02:35:45.960]  actual business opportunities call call back to the start of this episode the
[02:35:45.960 --> 02:35:50.120]  jeopardy introduction or audition notice was in my spam filter and was deleted it
[02:35:50.120 --> 02:35:54.440]  I was like oh spam from somebody claimed to be jeopardy I'm like oh my god wait
[02:35:54.440 --> 02:35:58.240]  and if I deleted that hey that would have been a life experience and 30
[02:35:58.240 --> 02:36:03.440]  something thousand dollars lost so yeah I don't know if it's gotten worse now
[02:36:03.440 --> 02:36:05.640]  that's a good question I don't know how you measure that but you would think
[02:36:05.640 --> 02:36:10.960]  after all these years that Google would have automatically white listed incoming
[02:36:10.960 --> 02:36:14.640]  recipients you corresponded with you know where you hadn't marked it as spam
[02:36:14.640 --> 02:36:18.760]  for that long it's the same addresses even if they're cashing it as they
[02:36:18.760 --> 02:36:23.880]  should be in your own account I use fast mail which I've used for many many years
[02:36:23.880 --> 02:36:30.520]  for to back up my accounts and they have a pretty aggressive anti-spam strategy
[02:36:30.520 --> 02:36:34.160]  in terms of dealing with their own customers and they seem to operate
[02:36:34.160 --> 02:36:38.560]  really good filters like I don't get nearly as much spam as you do and I have
[02:36:38.560 --> 02:36:42.240]  I use they have spam assassin behind that I put some rules in place for the
[02:36:42.240 --> 02:36:45.040]  most egregious stuff but even then you know some stuff winds up in their junk
[02:36:45.040 --> 02:36:51.440]  filters some stuff winds up in I use spam sieve on my Mac but what I find is
[02:36:51.440 --> 02:36:57.280]  that Google in particular Gmail at periods of time is more aggressive so and
[02:36:57.280 --> 02:37:00.920]  I don't know if it's just me it seems like it is often but there's been points
[02:37:00.920 --> 02:37:05.080]  where like for six months every email just about I sent to someone on Gmail I
[02:37:05.080 --> 02:37:08.280]  had to follow up with with like a text because it went straight to their
[02:37:08.280 --> 02:37:12.480]  spam filter and then it stopped and then it was fine for long periods of time and
[02:37:12.480 --> 02:37:16.440]  just recently yours is not the only message I've sent to someone using a
[02:37:16.440 --> 02:37:23.600]  Gmail account where I think it wound up in in the spam filter and I I find that
[02:37:23.600 --> 02:37:29.060]  there are some that I correct them and it doesn't get uncorrected so you should
[02:37:29.060 --> 02:37:32.520]  be white listing why isn't it listening to your white list I don't know I always
[02:37:32.520 --> 02:37:37.040]  was under the impression that all you have to do to tell Gmail that like I'm
[02:37:37.040 --> 02:37:43.080]  using the Apple mail app not Gmail's app but that if you move a message from junk
[02:37:43.080 --> 02:37:48.480]  to your inbox it's saying this is not junk because I don't know how else they
[02:37:48.480 --> 02:37:54.080]  could interpret that but like Dave Weiner started sending out daily eight
[02:37:54.080 --> 02:38:01.600]  summaries of his scripting news and I I guess I should unsubscribe because I
[02:38:01.600 --> 02:38:05.320]  follow scripting news in RSS and that's where I would naturally do it but I'm
[02:38:05.320 --> 02:38:11.320]  just I'm just intrigued by how he's using an email newsletter it's just like
[02:38:11.320 --> 02:38:15.240]  a recurring theme for the last four months and I I'm not gonna say I'm on
[02:38:15.240 --> 02:38:22.160]  the cusp of doing a daring fireball email newsletter but I'm I've noted the
[02:38:22.160 --> 02:38:25.520]  resurgence in email newsletters and I talked to Dan Fromer about it and his
[02:38:25.520 --> 02:38:30.520]  main thing is a newsletter and Ben Thompson's main thing is the newsletter
[02:38:30.520 --> 02:38:35.880]  the daily update at Stratechery and paid versus paid and free there's a
[02:38:35.880 --> 02:38:42.280]  resurgence of interest in newsletters and one of my reasons for for you know
[02:38:42.280 --> 02:38:45.320]  I've I've been saying this over again I have this theory that the reason people
[02:38:45.320 --> 02:38:50.440]  really like reading email newsletters is you click on the newsletter and you read
[02:38:50.440 --> 02:38:54.240]  it and it scroll down and you're done and there's nothing nobody's popping up
[02:38:54.240 --> 02:38:58.600]  anything that covers the email and says will you subscribe to our newsletter or
[02:38:58.600 --> 02:39:04.240]  will you subscribe to this or will you we're collecting cookies okay or no I
[02:39:04.240 --> 02:39:10.480]  mean I've told the goddamn Guardian that I'm okay with their cookies a thousand
[02:39:10.480 --> 02:39:14.680]  freaking times every time I go to their website I have to click three things on
[02:39:14.680 --> 02:39:18.720]  most websites just to read the goddamn article the fact that I can just click
[02:39:18.720 --> 02:39:23.760]  on an email and there it is unobstructed and I scroll down and then I'm done and
[02:39:23.760 --> 02:39:27.640]  that's it I really think that's part of the resurgence but anyway so I want to
[02:39:27.640 --> 02:39:32.160]  keep getting Dave's daily updates and they keep going to junk I don't know
[02:39:32.160 --> 02:39:36.400]  what to do to make it stop no I know this from you know I used to for many
[02:39:36.400 --> 02:39:41.280]  years some weird little software I wrote powered tidbits mailing list and which
[02:39:41.280 --> 02:39:45.680]  has tens of thousands of people on it and as you know tidbits the longest
[02:39:45.680 --> 02:39:50.800]  continuously distributed email newsletter on the internet we're pretty
[02:39:50.800 --> 02:39:54.280]  sure like it seems like there was one that might have been longer and it's
[02:39:54.280 --> 02:39:57.080]  gone so they've got a lot of experience with dealing with spam I mean Adam is
[02:39:57.080 --> 02:40:02.000]  very experienced understanding what makes things go wrong and now is using a
[02:40:02.000 --> 02:40:07.520]  service at long last so it's not running it himself but um I had wrote this thing
[02:40:07.520 --> 02:40:13.360]  that did some sophisticated or I thought spam processing or a bounce processing
[02:40:13.360 --> 02:40:17.320]  and seemed to not trigger spam filters and tributes ran off that for like 10
[02:40:17.320 --> 02:40:21.120]  years I think and even then it would just be a mystery like one week we would
[02:40:21.120 --> 02:40:26.080]  do nothing differently and like all AOL users would be would be unsubscribed or
[02:40:26.080 --> 02:40:30.160]  blocked or we get a thousand bounces from one outfit and I'm still seeing it
[02:40:30.160 --> 02:40:36.440]  so I use fast mail as I said and I and I get tidbits and half the time it winds
[02:40:36.440 --> 02:40:40.560]  up being categorized as sort of light spam so I see it it's in my spam filter
[02:40:40.560 --> 02:40:45.040]  it's not deleted with a high score which I've got set and I'm thinking how is
[02:40:45.040 --> 02:40:50.980]  tidbits I mean I've received a thousand issues of tidbits most of those at my
[02:40:50.980 --> 02:40:55.200]  fast mail address or at fast mail servers and it's absolutely compliant
[02:40:55.200 --> 02:41:00.640]  and Adam sends out huge amounts of email every week so he knows and it's a
[02:41:00.640 --> 02:41:06.360]  mystery I I was telling you in our show notes here our pre-show discussion is I
[02:41:06.360 --> 02:41:11.000]  think it was the late 90s that I wrote an article saying I'm really concerned
[02:41:11.000 --> 02:41:15.160]  about email balkanization because spam filters and other things might prevent
[02:41:15.160 --> 02:41:19.720]  people from sending email from place to another like well it's still going on no
[02:41:19.720 --> 02:41:23.360]  one's figured out a way I mean there were all those proposals some of which
[02:41:23.360 --> 02:41:29.000]  are used that do different ways of validating domains and senders and some
[02:41:29.000 --> 02:41:34.020]  of its public key based and some of its in DNS and this was supposed to be a way
[02:41:34.020 --> 02:41:38.400]  to reduce spam by having some kind of verified path and even if spammers used
[02:41:38.400 --> 02:41:42.580]  it the people who are verified would be able to have an identity that was
[02:41:42.580 --> 02:41:47.180]  cryptographically proven or matched so you could say well this domain is cool
[02:41:47.180 --> 02:41:51.240]  because we can confirm all this email actually was issued by this domain
[02:41:51.240 --> 02:41:54.760]  because they've got the private key and we'll whitelist this whole domain so
[02:41:54.760 --> 02:41:58.200]  another spammer or a spammer might use a domain and have their own private key
[02:41:58.200 --> 02:42:02.800]  and we know it's verified Lee from this spammer but they can't fake being from
[02:42:02.800 --> 02:42:08.320]  this verified domain and they just all you know email is still so disparate
[02:42:08.320 --> 02:42:11.920]  there's no centralized anything or authority which is great because then
[02:42:11.920 --> 02:42:15.800]  you don't get advertising overlays and cookie requests and all that but it also
[02:42:15.800 --> 02:42:21.760]  means that all these proposals to improve the way in which like ham can be
[02:42:21.760 --> 02:42:29.320]  identified as ham ham sees ham does not has not matured this many years into it
[02:42:29.320 --> 02:42:35.280]  right and there's so much of my and what makes going through it manually and just
[02:42:35.280 --> 02:42:44.720]  visually scanning it so tedious is that at least I would guess 98% of it is so
[02:42:44.720 --> 02:42:50.920]  obviously spam you know any human being with a hundred percent certainty would
[02:42:50.920 --> 02:42:55.340]  say this is without ever opening it just just looking at the sender in the
[02:42:55.340 --> 02:43:02.240]  subject I mean it literally I'm looking at it right now here's one from Z Z Y 7 1
[02:43:02.240 --> 02:43:14.480]  2 7 1 2 7 1 2 the next one's from zing Z 66 IX HL V BM at ie KH I mean I don't
[02:43:14.480 --> 02:43:18.280]  even know how they think it's gonna work I don't know who in the world would open
[02:43:18.280 --> 02:43:22.200]  this even if they didn't have any why is machine learning not solve this right
[02:43:22.200 --> 02:43:26.400]  these are all readily identifiable five straight ones that are all just random
[02:43:26.400 --> 02:43:33.000]  random strings of letters and then the next one is from late night peeing I'm
[02:43:33.000 --> 02:43:37.160]  not making this up that's not my favorite late night show no it's
[02:43:37.160 --> 02:43:43.520]  America's least favorite late night show late night and late night peeing it's
[02:43:43.520 --> 02:43:49.480]  below Conan's yeah it's it's like you I
[02:43:51.640 --> 02:43:56.960]  don't know what to do about it I don't know but I I would opt into some sort of
[02:43:56.960 --> 02:44:01.640]  system I don't know it's too late you know what I mean it's like yeah it's
[02:44:01.640 --> 02:44:07.080]  email like in some ways like I said email is is is having a resurgence in
[02:44:07.080 --> 02:44:11.560]  terms of newsletters but as a fundamental level like the the initial
[02:44:11.560 --> 02:44:17.160]  optimism of the early internet of everything being open and you anybody
[02:44:17.160 --> 02:44:21.920]  with yeah you know is just it's email has just suffered under the weight of
[02:44:21.920 --> 02:44:27.960]  that forever you know that anybody with an SMTP server can send email to anybody
[02:44:27.960 --> 02:44:34.240]  with an email address and it just goes there is yeah it's somebody's gonna
[02:44:34.240 --> 02:44:38.480]  solve it I think and not like it's it's but I mean these are the trade-offs
[02:44:38.480 --> 02:44:42.280]  right there's there's always extreme so if you you know Facebook is unreliable
[02:44:42.280 --> 02:44:47.280]  you can't think that anything you post there gets delivered to people unless
[02:44:47.280 --> 02:44:50.920]  you pay for you know boosting it and then even then you don't know so you're
[02:44:50.920 --> 02:44:54.720]  gonna have 200,000 people liking your page and only 500 of them see a post
[02:44:54.720 --> 02:44:58.520]  right that kind of thing goes on and email is great because there's no
[02:44:58.520 --> 02:45:02.640]  intermediation except that the spam is so bad that it mixes your ham and your
[02:45:02.640 --> 02:45:05.880]  spam and you're you're not getting it like these are these are our extremes
[02:45:05.880 --> 02:45:11.120]  but I do think that I think we I don't think we have seen well enough applied
[02:45:11.120 --> 02:45:18.560]  machine learning and training because so much spam is obvious as you say I do not
[02:45:18.560 --> 02:45:24.360]  get why and why this is not more identifiable and I expect that at some
[02:45:24.360 --> 02:45:27.480]  point there will be a breakthrough I mean remember how so before deep
[02:45:27.480 --> 02:45:31.880]  learning came in as a the most effective technique for artificial intelligence a
[02:45:31.880 --> 02:45:37.200]  few years ago and made voice recognition and a lot of other things image
[02:45:37.200 --> 02:45:42.320]  recognition so forth so much better like you know a twenty percent twenty five
[02:45:42.320 --> 02:45:47.320]  percent better got us a lot more closer to the hundred percent score before deep
[02:45:47.320 --> 02:45:49.960]  learning remember how terrible everything was all the all the
[02:45:49.960 --> 02:45:53.640]  recognition was it was statistically based there all these things and you
[02:45:53.640 --> 02:45:57.960]  know you'd speak and it would give you the egg freckles is the yeah the Newton
[02:45:57.960 --> 02:46:01.160]  joke for handwriting recognition or whatever well so deep learning came in
[02:46:01.160 --> 02:46:04.640]  and it made a huge difference but I don't feel like email has made that leap
[02:46:04.640 --> 02:46:07.880]  and I know that Google's machine learning there was the leap there was
[02:46:07.880 --> 02:46:11.440]  the leap with Bayesian filtering whatever that but that was really the
[02:46:11.440 --> 02:46:14.880]  breakthrough was a holy shit this works whatever yes it's a filtering is it's
[02:46:14.880 --> 02:46:19.280]  statistical analysis using certain kinds of like measures of frequency and it and
[02:46:19.280 --> 02:46:23.560]  then what happens the spam makers would run their email through the same Bayesian
[02:46:23.560 --> 02:46:27.240]  filters and tweak them until they found ones that got lower scores because they
[02:46:27.240 --> 02:46:30.160]  introduced you know that's why you see part of Moby Dick at the bottom of email
[02:46:30.160 --> 02:46:34.800]  messages yeah I read and so forth and I remember you know I was at bare-bones
[02:46:34.800 --> 02:46:39.000]  software working there you know recent guest Rich Siegel which was a great
[02:46:39.000 --> 02:46:41.600]  episode I don't know if you listen to but man that was one of my favorite
[02:46:41.600 --> 02:46:47.600]  such but I remember when I was there mail Smith was still in you know an act
[02:46:47.600 --> 02:46:52.440]  a successful product that is still my email client is it really see the one
[02:46:52.440 --> 02:46:58.360]  thing I miss about I and I miss see this man do I miss this is using mail Smith
[02:46:58.360 --> 02:47:03.320]  with spam sieve you'd get a score and then you could sort your spam mailbox
[02:47:03.320 --> 02:47:07.240]  by the score and it made visually double-checking it so much easier
[02:47:07.240 --> 02:47:12.880]  because all of the actual ham that got incorrectly flagged to spam was at the
[02:47:12.880 --> 02:47:16.360]  top and all the obvious stuff was at the bottom and there's no I can't figure out
[02:47:16.360 --> 02:47:20.880]  any way in Apple mail to get anything similar to that and I don't know what to
[02:47:20.880 --> 02:47:27.000]  do about it but anyway but I remember before Bayesian filtering we had like a
[02:47:27.000 --> 02:47:32.400]  like it was like it as a tech support thing like a collection of like filters
[02:47:32.400 --> 02:47:37.800]  like just manually set up like yeah like if the subject matches this pattern or
[02:47:37.800 --> 02:47:42.440]  if the sender you know like a couple of regex patterns and you know based on the
[02:47:42.440 --> 02:47:47.280]  headers and and for a while it really worked well we had like you know you
[02:47:47.280 --> 02:47:52.720]  could just download this filter and add it to mail Smith and all of a sudden you
[02:47:52.720 --> 02:47:57.160]  know your spam problems were mostly solved and it was really just
[02:47:57.160 --> 02:48:04.040]  effectively just like eight eight if the message matches blank statements you
[02:48:04.040 --> 02:48:08.680]  know eventually that fell apart you know they found ways around it and the Bayesian
[02:48:08.680 --> 02:48:11.600]  filtering was a great leap forward but I feel like you're right we need we need
[02:48:11.600 --> 02:48:15.600]  the next one and I guess it has to be machine learning but it's it's not there
[02:48:15.600 --> 02:48:20.620]  I don't know maybe I'm nuts maybe it's just me maybe it's you know now that I've
[02:48:20.620 --> 02:48:24.580]  found a couple I've found a couple of messages recently over the last like two
[02:48:24.580 --> 02:48:29.200]  months in my spam and I'm panicked about it maybe it's just me but I'm gonna slack
[02:48:29.200 --> 02:48:33.000]  with some technically you know some friends on you know that I've asked
[02:48:33.000 --> 02:48:38.560]  other you know similar Lee technically oriented long-term email users have all
[02:48:38.560 --> 02:48:43.000]  all said the same thing either that they think it's getting worse or they're
[02:48:43.000 --> 02:48:48.120]  convinced it's getting worse oh the other I would say the the another factor
[02:48:48.120 --> 02:48:50.880]  could be that spammers are getting better again they're getting better at
[02:48:50.880 --> 02:48:54.600]  filtering through which makes every time spammers get better spam filters get
[02:48:54.600 --> 02:49:00.520]  worse because they produce more false well I will say this that I'm not seeing
[02:49:00.520 --> 02:49:06.680]  an increase of spam getting into my inbox the only the only problem I'm
[02:49:06.680 --> 02:49:11.480]  seeing is good email getting flagged to spam oh but that can happen is you if
[02:49:11.480 --> 02:49:15.640]  you the filters could be improving so they're not passing more through so
[02:49:15.640 --> 02:49:20.880]  they're still good on false negatives but they're bad on false positives which
[02:49:20.880 --> 02:49:24.320]  is not kind of what you want like I think you'd rather have fewer false
[02:49:24.320 --> 02:49:28.800]  positives and more false negatives not like a thousand yeah spams drop in but
[02:49:28.800 --> 02:49:34.600]  I'd rather get one or two yes spams to get a hundred percent of my right better
[02:49:34.600 --> 02:49:41.520]  that a guilty man a hundred guilty men go go free than an innocent man be put
[02:49:41.520 --> 02:49:47.920]  in jail exactly that's it for mail I like it all right so Glenn before I let
[02:49:47.920 --> 02:49:54.560]  you off the hook you are people can if they enjoy your voice on this show they
[02:49:54.560 --> 02:50:02.360]  voice they can hear you and this is odd coincidence and it really is but you've
[02:50:02.360 --> 02:50:08.080]  been guest hosting the election ride home podcast yeah that's right excuse me
[02:50:08.080 --> 02:50:12.920]  Chris Higgins was the founding host of it and he's had to step away for her
[02:50:12.920 --> 02:50:17.960]  family reasons and everything's okay but he needs to focus on family so I am
[02:50:17.960 --> 02:50:23.880]  stepping in for a bit to do this podcast because you know as I can do everything
[02:50:23.880 --> 02:50:31.680]  in my career and the folks that ride home Brian McCullough I was on his he's
[02:50:31.680 --> 02:50:35.280]  got a great internet history podcast is great because no one else is really
[02:50:35.280 --> 02:50:39.440]  doing the oral history of the internet comprehensively I think I mean I don't
[02:50:39.440 --> 02:50:42.800]  want to say he's the only one but I think he's the only one doing it at this
[02:50:42.800 --> 02:50:48.160]  level of detail so he's talking with early people in the internet e-commerce
[02:50:48.160 --> 02:50:52.760]  companies and whatever and so I came on a couple times to to shoot the breeze
[02:50:52.760 --> 02:50:56.200]  about some of my early experiences and things and it's great because then I'm
[02:50:56.200 --> 02:50:59.480]  like oh now I've told him it's there forever so he's been doing the tech meme
[02:50:59.480 --> 02:51:04.000]  ride home podcast for a while and I've substituted on that a few times when he
[02:51:04.000 --> 02:51:09.960]  said vacation or obligations jury duty and the like and so election ride home
[02:51:09.960 --> 02:51:14.160]  is just it's the idea is just a summary you know it's I think and I have this
[02:51:14.160 --> 02:51:18.000]  feeling too it's very easy to get overwhelmed because there's too much
[02:51:18.000 --> 02:51:23.440]  news there's a year's worth of news every day now right about everything and
[02:51:23.440 --> 02:51:27.920]  so the idea is you know it's a 15-minute podcast about everything that happened
[02:51:27.920 --> 02:51:31.040]  in elections today and it's very interesting to wake up in the morning
[02:51:31.040 --> 02:51:35.680]  go okay kind of what's what's happening you know sometimes they'll be like the
[02:51:35.680 --> 02:51:38.640]  presidential debates I was covering that last week and it's like okay how do I
[02:51:38.640 --> 02:51:44.160]  summarize two hours plus of this in a way that's useful for people who didn't
[02:51:44.160 --> 02:51:48.320]  watch it and might be useful for people who did but still make it you know pithy
[02:51:48.320 --> 02:51:51.840]  and bring in some sound bites and and not have it be facile like here's kind
[02:51:51.840 --> 02:51:55.440]  of what you need to know like what is the national discussion ostensibly being
[02:51:55.440 --> 02:51:59.440]  today but some other times I wake up in the morning and it's like you know
[02:51:59.440 --> 02:52:04.000]  there's new impeachment thing Pelosi's sending the articles to the Senate some
[02:52:04.000 --> 02:52:08.800]  you know Booker drops out or whatever and so every day is a new adventure and
[02:52:08.800 --> 02:52:12.640]  mystery but the goal is to like make it approachable so you put on your
[02:52:12.640 --> 02:52:17.760]  headphones on your commute home and in 15 minutes you're done instead of you
[02:52:17.760 --> 02:52:21.200]  know reading a thousand you may still read a thousand stories but I'm trying
[02:52:21.200 --> 02:52:24.960]  to help people I feel like it's a it's a service to keep people from having to
[02:52:24.960 --> 02:52:30.000]  fully immerse themselves in it every day and how long is the gig it's all it's
[02:52:30.000 --> 02:52:33.840]  ongoing I think they're looking for a permanent host for the show you know
[02:52:33.840 --> 02:52:36.560]  because I've got a lot of his you know I got a lot of different things I'm
[02:52:36.560 --> 02:52:40.400]  working on well and this also sounds I know it's like oh it's only 15 minutes
[02:52:40.400 --> 02:52:43.560]  as opposed to the three hours you and I've been talking right now but I I can
[02:52:43.560 --> 02:52:48.480]  only imagine how much work it is on a daily basis to boil all of it down to
[02:52:48.480 --> 02:52:52.800]  15 minutes it would actually be less work to do a three-hour podcast where
[02:52:52.800 --> 02:53:01.000]  you just ramble on about it well it's like a four to six hour cycle to do an
[02:53:01.000 --> 02:53:04.640]  episode and you know and so it's really it's exciting as somebody who's been a
[02:53:04.640 --> 02:53:08.960]  freelance writer for a long time I've never done daily reporting I've only
[02:53:08.960 --> 02:53:13.520]  done stuff for weeklies or sometimes on deadline you overnight or something but
[02:53:13.520 --> 02:53:19.880]  I did a gig for fortune from mid the mid 2018 to early 2019 before they got sold
[02:53:19.880 --> 02:53:23.960]  to a mysterious Thai billionaire no kidding no kidding they just rebooted
[02:53:23.960 --> 02:53:27.960]  with a new design and they it's a great publication some great people great
[02:53:27.960 --> 02:53:32.000]  editors I was working with there but they were running a kind of daily news
[02:53:32.000 --> 02:53:36.720]  room within shifts and so as I was writing kind of breaking news for seven
[02:53:36.720 --> 02:53:40.480]  months for a few hours every day and that was fascinating to me and a little
[02:53:40.480 --> 02:53:44.600]  overwhelming because my pace is you know I'm often I've been describing myself as
[02:53:44.600 --> 02:53:48.160]  breaking news from the 19th century because I'm always like hey you know I
[02:53:48.160 --> 02:53:51.520]  just discovered some printers were poisoned and printing this newspaper in
[02:53:51.520 --> 02:53:56.080]  1838 I must write this story so the election right home is it's a great way
[02:53:56.080 --> 02:53:59.880]  to stretch my muscles and and it's a fun I feel like it's a little bit of a
[02:53:59.880 --> 02:54:05.560]  service thing and giving people you know that that snippet is I think a lot of
[02:54:05.560 --> 02:54:08.960]  the political podcasts tend to be discussion and longer so you have to
[02:54:08.960 --> 02:54:12.840]  commit yourself and there's some of them I really I like like love it or leave it
[02:54:12.840 --> 02:54:17.760]  I listen to every week and a few others but anyway it's a very specific it's a
[02:54:17.760 --> 02:54:23.000]  very specific remit for this podcast I will I have to disclaim it but it's just
[02:54:23.000 --> 02:54:27.360]  an odd coincidence but the sponsor of the previous episode of this show last
[02:54:27.360 --> 02:54:31.700]  week's episode with Merlin Mann was tech memes ride home which is another ride
[02:54:31.700 --> 02:54:35.960]  home podcast I actually purposefully juggled the sponsorship schedule so that
[02:54:35.960 --> 02:54:40.960]  we would wouldn't have tech meme ride home sponsoring the episode where you
[02:54:40.960 --> 02:54:45.880]  Glenn talked about election ride home but I mean it they sponsored last week's
[02:54:45.880 --> 02:54:48.680]  episode they're not sponsoring this week's episode but the ride home
[02:54:48.680 --> 02:54:53.040]  podcasts are really really tight and it's it's like your own little private
[02:54:53.040 --> 02:54:57.400]  NPR for your area of interest so if you would rather hear about election news on
[02:54:57.400 --> 02:55:03.080]  your ride home then tech news on your ride home election ride home is a great
[02:55:03.080 --> 02:55:06.160]  thing and if you're you know if your ride home is 30 minutes you could listen
[02:55:06.160 --> 02:55:12.000]  to both there's a celebrity one also you know they agree not public news they
[02:55:12.000 --> 02:55:14.640]  raise a little money because I want to do the they want to do a bunch of these
[02:55:14.640 --> 02:55:18.720]  because uh you know there are long podcasts like this one they get into
[02:55:18.720 --> 02:55:21.840]  things and they're a short part I think the news one is interesting because I
[02:55:21.840 --> 02:55:25.920]  think that that often I often don't listen to news podcasts because I like
[02:55:25.920 --> 02:55:31.600]  to prefer to read it if I knew you know in some areas like I would love a like a
[02:55:31.600 --> 02:55:35.880]  security news podcast just not enough interest that was just like whatever
[02:55:35.880 --> 02:55:39.400]  security news happened that day just give me the boil it down then I'll go
[02:55:39.400 --> 02:55:44.200]  and drill and find like an index for my ears that's what I want the other thing
[02:55:44.200 --> 02:55:49.360]  I know you wanted to mention was the tiny type museum I I did I want to thank
[02:55:49.360 --> 02:55:53.080]  wash I want to thank during fireball listeners because many of you well I
[02:55:53.080 --> 02:55:55.800]  shouldn't say me and relative proportions not many of you but some of
[02:55:55.800 --> 02:56:00.280]  you have been great supporters of the project and it's it's we're gonna ship
[02:56:00.280 --> 02:56:05.340]  very soon I know this is unheard of a Kickstarter that ships more or less on
[02:56:05.340 --> 02:56:09.640]  time but I've been thanking past Glenn so that we did the Kickstarter in
[02:56:09.640 --> 02:56:14.240]  February last year myself and Anna Robinson has been making the wooden
[02:56:14.240 --> 02:56:20.240]  cases handmade wooden cases for the type artifacts that go into it and she is
[02:56:20.240 --> 02:56:23.920]  nearing where like the very final stage is a final production for that and I've
[02:56:23.920 --> 02:56:29.520]  got my basement is full of like the poor letter carrier I mean I'll just describe
[02:56:29.520 --> 02:56:31.960]  it in one line you know it's the tiny type museum and time capsule it's a
[02:56:31.960 --> 02:56:35.320]  collection of printing artifacts like wood type and molds from which type are
[02:56:35.320 --> 02:56:40.480]  made and little pieces of photo type and I've got a CD-ROM p22 the type foundry
[02:56:40.480 --> 02:56:46.160]  it's been around for 20 plus years they sold me very inexpensively CD-ROM so
[02:56:46.160 --> 02:56:51.700]  every time museum is gonna have a 1990 era CD-ROM with a personal license to
[02:56:51.700 --> 02:56:55.840]  use the font that's on the CD-ROM if you can read it so it's been a it's been a
[02:56:55.840 --> 02:56:59.760]  hoot I did a book along along with it as well and it's being printed this one's
[02:56:59.760 --> 02:57:03.200]  being printed in England right now it's and so that's the one you mentioned that
[02:57:03.200 --> 02:57:07.920]  was actually it is actually being printed in letterpress yeah like it was
[02:57:07.920 --> 02:57:14.840]  set in hot metal in in North Yorkshire and where there's the printer I work
[02:57:14.840 --> 02:57:19.440]  with as a former employee who has all the types of equipment now and it's
[02:57:19.440 --> 02:57:24.040]  being printed in London London proper and then be bound in Germany and
[02:57:24.040 --> 02:57:27.920]  actually when the brexit situation was happening if it had crashed out in
[02:57:27.920 --> 02:57:32.000]  October I was really worried about how my printed pages were gonna get to
[02:57:32.000 --> 02:57:36.440]  Germany for binding you might have to smuggle them out well are you talking
[02:57:36.440 --> 02:57:41.120]  like could I fly there imagine a magic getting busted for smuggling something
[02:57:41.120 --> 02:57:47.520]  is as esoteric as international book smuggler so so the postman this poor
[02:57:47.520 --> 02:57:51.960]  letter carrier post lady sorry postal carrier rather we have a variety of
[02:57:51.960 --> 02:58:01.520]  postal carriers and livers I'm buying lead brass bronze lightweight stuff
[02:58:01.520 --> 02:58:06.360]  it's like a joke it's like the box is one of those tiny USPS like everybody in
[02:58:06.360 --> 02:58:09.720]  the United States who deals in this stuff ships with priority mail because
[02:58:09.720 --> 02:58:14.000]  it's almost unlimited weight for the size so you can see the guy go up the
[02:58:14.000 --> 02:58:18.200]  stairs to hands it off like oh I'm sorry it's like 40 pounds of lead she just
[02:58:18.200 --> 02:58:22.520]  gave me so my basement is full of all the artifacts that are gonna get sorted
[02:58:22.520 --> 02:58:27.560]  into sets but people can people can still get in right there are yes I
[02:58:27.560 --> 02:58:31.960]  addition is about a hundred and 80 of them are now over 80 of them are now
[02:58:31.960 --> 02:58:37.720]  pre-ordered or sold in the Kickstarter see a tiny type museum basically if you
[02:58:37.720 --> 02:58:42.840]  even know how cool it is that Glenn is having the book physically letterpress
[02:58:42.840 --> 02:58:46.280]  if you even know what that means you should absolutely go check out tiny type
[02:58:46.280 --> 02:58:50.480]  museum calm and if not well that's probably not for you it's it's been fun
[02:58:50.480 --> 02:58:53.160]  though because I've had all these great conversations a lot there's a lot of
[02:58:53.160 --> 02:58:56.960]  older folks particular usually men who are working the printing industry or
[02:58:56.960 --> 02:59:01.560]  had grandparents work in the industry and I have these great conversations
[02:59:01.560 --> 02:59:05.360]  people like oh my god my father used to be a typesetter or someone telling me I
[02:59:05.360 --> 02:59:10.280]  had this great you know Chris Finn who used to write for Macworld who now is
[02:59:10.280 --> 02:59:18.160]  that DK DK DC Thomas I'm getting the name it's a major media company in the
[02:59:18.160 --> 02:59:21.760]  UK and you can still see they sold a building on Fleet Street they're like
[02:59:21.760 --> 02:59:25.320]  the only they don't have reporters there but then you walk on a Fleet Street in
[02:59:25.320 --> 02:59:29.840]  London the the home of newspapers in London where there are no newspapers
[02:59:29.840 --> 02:59:35.360]  left they still have a DC Thomas Thompson is there anyway of Chris Finn
[02:59:35.360 --> 02:59:40.640]  got didn't recorded a short podcast for me with a colleague of his who is just
[02:59:40.640 --> 02:59:44.640]  old enough to have worked on old letterpress when newspapers were printed
[02:59:44.640 --> 02:59:48.400]  by letterpress and had this story about how they put the breaking news in with
[02:59:48.400 --> 02:59:52.600]  this special little thing you would like stick into the running press with just
[02:59:52.600 --> 02:59:57.200]  a little bit of copy that's an extra extra breaking news sports court he
[02:59:57.200 --> 03:00:02.200]  recorded is so nice recorded a short podcast put it on YouTube about that so
[03:00:02.200 --> 03:00:04.760]  anyway it's been great just talking to folks about this people have fond
[03:00:04.760 --> 03:00:07.640]  memories and anyway I appreciate everyone's support on it because it's
[03:00:07.640 --> 03:00:11.760]  been a great year to 2019 was incredible to work on this so thank you
[03:00:11.760 --> 03:00:15.640]  all all right my thanks to Squarespace for sponsoring this show go to
[03:00:15.640 --> 03:00:20.560]  squarespace.com slash talk show start your own website clear the absolute best
[03:00:20.560 --> 03:00:30.480]  way to get through airport security and the first sponsor of the episode who I
[03:00:30.480 --> 03:00:35.280]  can't remember hover that sound I it's coming to me Glenn it's coming to me
[03:00:35.280 --> 03:00:41.360]  right hover hover.com slash talk show where you could go and register a domain
[03:00:41.360 --> 03:00:45.040]  name and get a 10% discount with that link thank you Glenn you've been
[03:00:45.040 --> 03:00:49.960]  extraordinarily generous with your time and your personal insight into jeopardy
[03:00:49.960 --> 03:00:54.720]  what a great show thank you very much always a pleasure John thank you very
[03:00:54.720 --> 03:01:20.240]  much
